{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Il7H73VGJ2No"
   },
   "source": [
    "# Classificação de imagens usando MLPs\n",
    "\n",
    "Neste módulo do curso, vamos estudar Redes Neurais Convolucionais (CNNs). Essas redes tornaram-se famosas pela capacidade de realizar tarefas de classificação de imagens. Como vimos nas aulas teóricas, a rede AlexNet revolucionou o concurso ImageNet, desbancando todas as outras soluções por uma grande margem.\n",
    "\n",
    "Antes de adentrarmos e testarmos as redes CNNs vamos ver como as tradicionais redes neurais, ou *multi-layer perceptrons* (MLPs) se saem em tarefas de classificação de imagens. Mais especificamente, vamos avaliar o desempenho de uma arquitetura relativamente simples de MLP no conjunto de dados [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwX8bTTV03cS"
   },
   "source": [
    "Vamos primeiro fazer algumas importações:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5LaoPWO9RhEq"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nbproxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchsummary --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5yNikfN0J2Np"
   },
   "source": [
    "## Preparando o Dataloader\n",
    "\n",
    "Utilizando o dataset padrão do MNIST disponibilizado pelo pacote torchvision. Para mais informações sobre o dataset, acesse a página: <https://pytorch.org/docs/stable/torchvision/datasets.html#mnist>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YKPo231vJ2Nq"
   },
   "outputs": [],
   "source": [
    "# Definimos a transformação que vai ser aplicada aos dados: transformar em tensores\n",
    "transf = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Vamos utilizar a implementação do CIFAR10 diretamente do Pytorch\n",
    "train_set = datasets.CIFAR10('/pgeoprj2/ciag2024/dados/cifar', transform=transf, train=True, download=False)\n",
    "test_set = datasets.CIFAR10('/pgeoprj2/ciag2024/dados/cifar', transform=transf, train=False, download=False)\n",
    "\n",
    "# Plotando exemplos de imagens do conjunto de treino.\n",
    "fig, ax = plt.subplots(3, 11, figsize=(15, 5))\n",
    "\n",
    "idx = 0\n",
    "for i in range(3):\n",
    "    for j in range(11):\n",
    "        ax[i][j].imshow(train_set[idx][0].numpy().transpose((1,2,0)).squeeze())\n",
    "        ax[i][j].set_yticks([])\n",
    "        ax[i][j].set_xticks([])\n",
    "        idx += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZ1j2xBm4gKk"
   },
   "source": [
    "Vamos dar uma olhada em nossos dados. Acho que você pode identificar facilmente algumas categorias aqui. Caminhões, carros, cavalos, sapos, gatos. Agora você sabe com o que estamos trabalhando. Estas são as imagens que queremos que nossa rede identifique. Apenas fornecendo os valores dos pixels na faixa RGB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QrMULqqYShdC"
   },
   "outputs": [],
   "source": [
    "# Para gerar o conjunto de validação, vamos separar 10% do conjunto de treino\n",
    "train_indices, val_indices, _, _ = train_test_split(\n",
    "    range(len(train_set)), # índice das N imagens do dataset\n",
    "    train_set.targets, # rótulos das imagens\n",
    "    stratify=train_set.targets, #  os rótulos serão usados pela função para fazer uma divisão proporcional entre as classes\n",
    "    test_size=0.1, # separamos 10% do conjunto para a validação\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Geramos um subsets dos dados conforme os índices gerados pelo split\n",
    "train_split = Subset(train_set, train_indices)\n",
    "val_split = Subset(train_set, val_indices)\n",
    "\n",
    "# Criando os dataloaders\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_split, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_split, batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size, shuffle=False)\n",
    "\n",
    "print('Número de mini-batches no treino: ', len(train_loader))\n",
    "print('Número de mini-batches na validação: ', len(val_loader))\n",
    "print('Número de mini-batches no teste: ', len(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8rAhHAjFuDT"
   },
   "source": [
    "## Definindo a arquitetura da rede"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EGtnadiqJ2Nu"
   },
   "source": [
    "### Exercício 1\n",
    "\n",
    "O pacote torch.nn que contém as implementações de todas as camadas que serão usadas nessa parte (nn.Linear): <https://pytorch.org/docs/stable/nn.html>.\n",
    "\n",
    "Vamos definir uma arquitetura com as seguintes características:\n",
    "\n",
    "* Uma camada de Flatten que recebe cada imagem como uma matriz 32x32x3, achatando em um vetor de comprimento 3072. Sem parâmetros treináveis ​​aqui, isso está preparando a imagem para nossas camadas densas.\n",
    "\n",
    "* Uma primeira camada densa (fully connected ou Linear) com 1000 neurônios. Isso significa que cada um dos 3.072 valores de x será multiplicado por 1000 pesos  (porque uma camada densa é totalmente conectada, então cada nó em uma camada será conectado a cada nó na próxima camada). Incluindo os viéses, temos 3.073 pesos por neurônio, que resultarão em 3.073.000 parâmetros. São 3073000 pesos prontos para serem treinados. Vamos utilizar um ReLU como função de ativação.\n",
    "\n",
    "* Então temos nossa primeira camada de `dropout`, com uma probabilidade de 20%.\n",
    "\n",
    "* Em seguida, outra camada densa de tamanho 512, na qual cada um dos 512 nós receberá os 1000 valores de saída da camada anterior, fornecendo 512x1001=512512 parâmetros treináveis. Isso está começando a somar, você não acha ..? Vamos utilizar ReLU como função de ativação novamente.\n",
    "\n",
    "* Outro `dropout`, a julgar pela quantidade de parâmetros, acho que você entendeu por que é bom usar.\n",
    "\n",
    "* A última camada densa é a nossa camada de saída. Temos 10 categorias, então 10 neurônios, cada um produzindo a probabilidade de uma imagem estar nessa categoria. Assim, nossos 512 (+ viés) parâmetros são lançados em cada um deles, dando-nos 10x513=5130 pesos prontos para serem otimizados.\n",
    "\n",
    "Somando tudo isso resultará na quantidade de parâmetros que são tão bem resumidos para você pelo Pytorch. Acho que você concorda que é MUITO trabalho a ser feito. Começando a ver o problema?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8gVCkSAtJYvh"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "\n",
    "class CustomNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, n_classes):\n",
    "        super(CustomNetwork, self).__init__()\n",
    "\n",
    "        # Defina aqui a arquitetura\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Defina o forward\n",
    "\n",
    "        return out\n",
    "\n",
    "input_size = 3072 # Input size (32*32*3)\n",
    "n_classes = 10 # Number of classes on CIFAR10\n",
    "\n",
    "model = CustomNetwork(input_size, n_classes).cuda()\n",
    "\n",
    "print(model)\n",
    "summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOVXXfCiJ2Ny"
   },
   "source": [
    "## Definindo o otimizador\n",
    "\n",
    "O *Pytorch* tem várias opções de otimizadores, desde os mais simples como o SGD até otimizadores mais modernos com velocidades de aprendizado adaptáveis para cada parâmetro da rede (i.e. Adam, Adagrad, RSMProp...). Todos os otimizadores estão localizados no pacote torch.optim. Para mais informnações sobre o pacote, visite: <https://pytorch.org/docs/stable/optim.html>. Vamos utilizar o Adam com learning rate de 0.001 nesse exemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fhyopppRJ2Nz"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "lr = 0.001\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MlBTGdzPJ2N1"
   },
   "source": [
    "## Definindo a função de perda\n",
    "\n",
    "Definindo um critério (loss) de classificação para calcular o erro do seu modelo a cada batch de amostras. A *CrossEntropyLoss* ou a *NLLLoss* são funções de perda indicadas para esse tipo de tarefa. Informações sobre essas losses podem ser encontradas em: <https://pytorch.org/docs/stable/nn.html#loss-functions>. Vamos usar a CrossEntropy nesse exemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H1WirBm_J2N2"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9uC1yHfJ2N4"
   },
   "source": [
    "## Treino e validação\n",
    "\n",
    "Iterando sobre batches de treino e validação ao longo de várias epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "04-4qarbJ2N5"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "train_loss = np.zeros(epochs)\n",
    "train_acc = np.zeros(epochs)\n",
    "val_loss = np.zeros(epochs)\n",
    "val_acc = np.zeros(epochs)\n",
    "\n",
    "for ep in range(epochs):\n",
    "\n",
    "    print('##############################################')\n",
    "    print('Starting epoch ' + str(ep + 1) + '/' + str(epochs) + '...')\n",
    "\n",
    "    print('Training...')\n",
    "\n",
    "    # Colocando o modelo no modo de treinamento\n",
    "    model.train()\n",
    "\n",
    "    training_metrics = list()\n",
    "    val_metrics = list()\n",
    "\n",
    "    train_label_list = list()\n",
    "    train_output_list = list()\n",
    "\n",
    "    # Iterando nos batches de treino\n",
    "    for it, data in enumerate(train_loader):\n",
    "\n",
    "        # Obtendo o dado (inps) e rótulo (labs) do batch\n",
    "        inps, labs = data\n",
    "\n",
    "        # GPU casting\n",
    "        inps = inps.cuda()\n",
    "        labs = labs.cuda()\n",
    "\n",
    "        # Zerando o otimizador\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Realizando o forward\n",
    "        output = model(inps)\n",
    "\n",
    "        # Computando a loss\n",
    "        loss = criterion(output, labs)\n",
    "\n",
    "        # Realizando o Backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Atualizando os pesos da rede\n",
    "        optimizer.step()\n",
    "\n",
    "        # Adicionando a loss do batch na lista\n",
    "        training_metrics.append(loss.detach().cpu().numpy())\n",
    "\n",
    "        # Pegando a previsão e o label do batch para calculo da acurácia ao final da época\n",
    "        train_label_list += labs.cpu().numpy().tolist()\n",
    "        train_output_list += output.max(1)[1].cpu().numpy().tolist()\n",
    "\n",
    "    # Calculando a acurácia de treino na época\n",
    "    train_label_array = np.asarray(train_label_list, dtype=np.int32).ravel()\n",
    "    train_output_array = np.asarray(train_output_list, dtype=np.int32).ravel()\n",
    "    accuracy = np.sum(train_label_array == train_output_array) / float(train_label_array.shape[0])\n",
    "    print('\\tTrain Accuracy: %.2f%%' % (100.0 * accuracy))\n",
    "\n",
    "    # Adicionando a acurácia e loss aos respectivos arrays para plotar no final do treino\n",
    "    train_acc[ep] = accuracy\n",
    "    train_loss[ep] = np.asarray(training_metrics).ravel().mean()\n",
    "\n",
    "    print('Validation...')\n",
    "\n",
    "    # Colocando o modelo no modo de validação\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        label_list = list()\n",
    "        output_list = list()\n",
    "\n",
    "        # Iterando sobre os batches de validação\n",
    "        for it, data in enumerate(val_loader):\n",
    "\n",
    "            # Obtendo o dado e rótulo do batch\n",
    "            inps, labs = data\n",
    "\n",
    "            # GPU casting\n",
    "            inps = inps.cuda()\n",
    "            labs = labs.cuda()\n",
    "\n",
    "            # Forward\n",
    "            output = model(inps)\n",
    "\n",
    "            # Computando a loss\n",
    "            loss = criterion(output, labs)\n",
    "\n",
    "            # Adicionando a loss do batch na lista\n",
    "            val_metrics.append(loss.detach().cpu().numpy())\n",
    "\n",
    "            # Pegando a previsão e rótulo do batch para cálculo de acurácia\n",
    "            label_list += labs.cpu().numpy().tolist()\n",
    "            output_list += output.max(1)[1].cpu().numpy().tolist()\n",
    "\n",
    "        # Calculando a acurácia da validação na época\n",
    "        label_array = np.asarray(label_list, dtype=np.int32).ravel()\n",
    "        output_array = np.asarray(output_list, dtype=np.int32).ravel()\n",
    "        accuracy = np.sum(label_array == output_array) / float(label_array.shape[0])\n",
    "        print('\\tValidation Accuracy: %.2f%%' % (100.0 * accuracy))\n",
    "\n",
    "        # Adicionando acurácia e loss aos respectivos arrays para plotar no final\n",
    "        val_acc[ep] = accuracy\n",
    "        val_loss[ep] = np.asarray(val_metrics).ravel().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t8iWQH_grcP-"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "plt.title('accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['training', 'validation'], loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['training', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8LzQ-2nf91Gd"
   },
   "source": [
    "Aqui, visualizamos nosso processo de treinamento. Basicamente, esse tipo de visualização pode ser útil para identificar rapidamente o ponto exato em que passamos nosso ponto de ouro e começamos a ajustar demais ao nosso conjunto de treinamento. Eu diria que, com apenas 5 épocas, não há muito que concluir além de \"talvez seja necessário aumentar o número de épocas\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "msRM8MvWj1I7"
   },
   "source": [
    "## Teste do modelo\n",
    "\n",
    "Então, depois de fazer todo o processo de treinamento, avaliamos o modelo com esses pesos em relação a dados que ele nunca viu antes, ou seja, o conjunto de teste.\n",
    "\n",
    "Iterando sobre os batchs de teste para obter a acurácia do modelo no conjunto de teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CFfz02PijqX3"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print('Test...')\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    label_list = list()\n",
    "    output_list = list()\n",
    "\n",
    "    for it, data in enumerate(test_loader):\n",
    "        inps, labs = data\n",
    "\n",
    "        inps = inps.cuda()\n",
    "        labs = labs.cuda()\n",
    "\n",
    "        output = model(inps)\n",
    "\n",
    "        label_list += labs.cpu().numpy().tolist()\n",
    "        output_list += output.max(1)[1].cpu().numpy().tolist()\n",
    "\n",
    "    label_array = np.asarray(label_list, dtype=np.int32).ravel()\n",
    "    output_array = np.asarray(output_list, dtype=np.int32).ravel()\n",
    "\n",
    "    accuracy = np.sum(label_array == output_array) / float(label_array.shape[0])\n",
    "    print('Test Accuracy: %.2f%%' % (100.0 * accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kDFrA716kZVo"
   },
   "source": [
    "Vamos fazer o forward de uma imagem aleatória do teste para visualizar a predição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z20bTc4ciFDa"
   },
   "outputs": [],
   "source": [
    "id_img = 11\n",
    "img, label = test_set[id_img]\n",
    "plt.imshow(img.numpy().transpose((1,2,0)))\n",
    "print('Image shape: ', img.shape)\n",
    "img = img.unsqueeze(0)\n",
    "print('Image shape after unsqueeze: ', img.shape)\n",
    "img = img.cuda()\n",
    "predicao = model(img)\n",
    "print('Prediction: ', predicao.max(1)[1].cpu().item(), ' | Label: ', label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fuJYN14aGBgT"
   },
   "source": [
    "# A operação de convolução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZZgYv3qN50K"
   },
   "source": [
    "### Convolução da imagem do zero\n",
    "\n",
    "Operação matemática em duas funções que produz uma terceira função representando como a forma de uma é modificada pela outra.\n",
    "\n",
    "![Image convolution — kernel filtering](https://miro.medium.com/max/728/1*Fr6Umze2waDjWVHB2yzT4A.png)\n",
    "\n",
    "\n",
    "A ideia por trás da convolução é estudar como uma função quando mapeada com outra função traz uma nova função modificada. Quando o mesmo é aplicado aos sinais é chamado de convolução 1d, às imagens — convolução 2d e aos vídeos — convolução 3d. Vamos concentrar na convolução 2d.\n",
    "\n",
    "### Visão geral\n",
    "\n",
    "Podemos pensar em uma imagem como uma matriz bidimensional contendo valores de cor de pixel na faixa de 0 a 255. Matematicamente, podemos manipular essa matriz aplicando várias operações de matriz.\n",
    "Usaremos [OpenCV](http://bit.ly/2R8Auux) (uma biblioteca flexível para processamento de imagens), NumPy para operações de matrizes e arrays e Matplotlib para plotar as imagens.\n",
    "\n",
    "### Exemplo\n",
    "\n",
    "Usamos o objeto `imread()` para ler a imagem. Por padrão `cv2.imread()` lê a imagem no formato Azul, Verde e Vermelho. Precisamos convertê-lo para o formato Vermelho, Azul e Verde.\n",
    "\n",
    "Usaremos a clássica imagem da modelo sueca *Lena Forsén* durante os exercícios seguintes. Para salvar essa imagem na pasta atual deste notebook, execute o código abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adicionando pasta e baixando a imagem\n",
    "\n",
    "A partir de agora faremos diferentes convolucoes em nossa imagem. Para organizarmos, vamos primeiro criar uma pasta de imagens para esse primeiro notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dir_name = 'imgs_aula01/'\n",
    "os.makedirs(dir_name, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "img_data = requests.get(\"https://upload.wikimedia.org/wikipedia/en/7/7d/Lenna_%28test_image%29.png\").content\n",
    "with open(dir_name + 'lena.png', 'wb') as handler:\n",
    "    handler.write(img_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tLXonI93N50N"
   },
   "source": [
    "Se a imagem estiver disponível, podemos começar a trabalhar..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v7ufz-7vN50P"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "src = cv2.imread(dir_name + 'lena.png')\n",
    "img = cv2.cvtColor(src, cv2.COLOR_BGR2RGB)\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7FDh735fN50R"
   },
   "source": [
    "### Imagem para matriz\n",
    "\n",
    "Para esses exercícios, consideraremos valores de matriz de uma imagem em escala de CINZA onde cada pixel contém valores entre 0 e 255. O problema com a imagem colorida é que cada valor de pixel é uma combinação de 3 valores provavelmente na forma de [R, G, B] ou [B, G, R] o que pode tornar o cálculo complicado. Então, para manter as coisas simples, pegamos uma imagem em escala de CINZA.\n",
    "\n",
    "Se visualizarmos a matriz, veremos que ela contém valores de pixel no intervalo de 0 a 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yh4eBITHN50T"
   },
   "outputs": [],
   "source": [
    "img = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "file = dir_name + 'lena_gray.png'\n",
    "plt.imsave(file, img, cmap='gray')\n",
    "img_mat = cv2.imread(file, 0)\n",
    "print(img_mat)\n",
    "print(img_mat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tz0bI2rAN50X"
   },
   "source": [
    "Vamos transpor a matriz acima e ver se a imagem é transposta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eBB0sCfWN50Y"
   },
   "outputs": [],
   "source": [
    "img_tran_mat = img_mat.T\n",
    "print(img_tran_mat)\n",
    "print(img_tran_mat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OTQ1awLbN50b"
   },
   "source": [
    "Você vê a diferença entre a matriz original e a matriz transposta? Agora salve a matriz como uma imagem usando o método `imwrite()` — que lê a matriz e os números e escreve como uma imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uz1cuXOmN50b"
   },
   "outputs": [],
   "source": [
    "cv2.imwrite(dir_name + 'lena_gray_tran.png', img_tran_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qu34_hlXN50e"
   },
   "source": [
    "Vamos ver a diferença..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e6xb-yoaN50f"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 25))\n",
    "\n",
    "orig = cv2.imread(dir_name + 'lena_gray.png')\n",
    "tran = cv2.imread(dir_name + 'lena_gray_tran.png')\n",
    "\n",
    "ax1 = fig.add_subplot(2,2,1)\n",
    "ax1.axis(\"off\")\n",
    "ax1.title.set_text('Original')\n",
    "ax1.imshow(orig)\n",
    "\n",
    "ax2 = fig.add_subplot(2,2,2)\n",
    "ax2.axis(\"off\")\n",
    "ax2.title.set_text('Transposed')\n",
    "ax2.imshow(tran)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDggOuD2N50i"
   },
   "source": [
    "Obtemos uma imagem totalmente transposta e é por causa da matriz transposta que realizamos anteriormente.\n",
    "\n",
    "Para convolução, exigimos um filtro de kernel separado que é operado em toda a imagem, resultando em uma imagem completamente modificada.\n",
    "\n",
    "$g(x, y) = w * f(x, y)$,\n",
    "\n",
    "onde $w$ = kernel, $g$ = resultado e $f$ = entrada\n",
    "\n",
    "No processamento de imagens; kernel, matriz de convolução ou máscara, é uma pequena matriz usada para desfoque, nitidez, relevo, detecção de borda e muito mais. Isso é feito fazendo uma convolução entre um kernel e uma imagem.\n",
    "\n",
    "### Etapas para convolução de imagens\n",
    "\n",
    "1. Converta a imagem em tons de cinza e obtenha a matriz.\n",
    "\n",
    "2. Obtenha uma matriz gigante contendo sub-matrizes de tamanho kernel da matriz original.\n",
    "\n",
    "3. Execute uma convolução fazendo uma multiplicação elemento a elemento entre o kernel e cada submatriz e some o resultado em um único inteiro ou valor flutuante. Ao fazer isso, obtenha uma matriz transformada ou filtrada.\n",
    "\n",
    "4. Converta a matriz transformada ou filtrada em uma imagem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XDB-iJRjN50j"
   },
   "source": [
    "### Exercício 2\n",
    "\n",
    "Implemente funções para executar as operações descritas nos passos 2 e 3 anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pAqGPqCgN50l"
   },
   "source": [
    "1. Converta a imagem em tons de cinza e obtenha a matriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aSfElmjTN50m"
   },
   "outputs": [],
   "source": [
    "def convert_image_matrix(img_name):\n",
    "    src = cv2.imread(img_name)\n",
    "    img = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "    name, ext = img_name.split('.')\n",
    "    plt.imsave(str(name + '_gray.' + ext), img, cmap='gray')\n",
    "\n",
    "    gray_img = cv2.imread(str(name + '_gray.' + ext), 0)\n",
    "\n",
    "    return gray_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iuCpvEjlN50n"
   },
   "source": [
    "A função acima retorna um array 2Dimentional NumPy contendo os valores de pixel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ta4lSrSN50n"
   },
   "source": [
    "2. Obtenha uma matriz gigante contendo sub-matrizes de tamanho kernel da matriz original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5qAKMwfZN50o"
   },
   "outputs": [],
   "source": [
    "def get_sub_matrices(orig_matrix, kernel_size):\n",
    "    # Seu código aqui\n",
    "\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8cJcj5VMN50s"
   },
   "source": [
    "A função acima retorna uma matriz gigante contendo sub-matrizes do tamanho do kernel que serão usadas novamente mais tarde. A matriz resultante também pode ser chamada de matriz amostrada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BxzIGAWJGRG7"
   },
   "source": [
    "3. Execute uma convolução fazendo uma multiplicação elemento a elemento entre o kernel e cada submatriz e some o resultado em um único inteiro ou valor flutuante. Ao fazer isso, obtenha uma matriz transformada ou filtrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "13xCRLaZN50s"
   },
   "outputs": [],
   "source": [
    "def get_transformed_matrix(matrix_sampling, kernel_filter):\n",
    "    transform_mat = []\n",
    "    # Seu código aqui\n",
    "\n",
    "    return transform_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qZjNhM7N50u"
   },
   "source": [
    "A matriz gigante ou a matriz amostrada é passada como argumento junto com o filtro do kernel na função acima para realizar a convolução."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e80huOfRGTba"
   },
   "source": [
    "4. Converta a matriz transformada ou filtrada em uma imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WfruqPDPN50v"
   },
   "outputs": [],
   "source": [
    "def original_VS_convoluted(img_name, kernel_name, convoluted_matrix):\n",
    "    name, ext = img_name.split('.')\n",
    "    cv2.imwrite(str(name + '_' + kernel_name + '.' + ext), convoluted_matrix)\n",
    "    orig = cv2.imread(str(name + '_gray.' + ext))\n",
    "    conv = cv2.imread(str(name + '_' + kernel_name + '.' + ext))\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 25))\n",
    "    ax1 = fig.add_subplot(2,2,1)\n",
    "    ax1.axis(\"off\")\n",
    "    ax1.title.set_text('Original')\n",
    "    ax1.imshow(orig)\n",
    "    ax2 = fig.add_subplot(2,2,2)\n",
    "    ax2.axis(\"off\")\n",
    "    ax2.title.set_text(str(kernel_name).title())\n",
    "    ax2.imshow(conv)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12K_gqEKN50w"
   },
   "source": [
    "A função acima é uma função de plotagem que compara a imagem original com a imagem transformada após a convolução."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8dPQT8UxN50x"
   },
   "source": [
    "### Exercício 3\n",
    "\n",
    "Execute as seguintes operações de convolução na imagem da Lena:\n",
    "\n",
    "* Operação de identidade\n",
    "\n",
    "* Operação de detecção de bordas\n",
    "\n",
    "* Operação de nitidez\n",
    "\n",
    "* Operação de desfoque de caixa\n",
    "\n",
    "* Operação de desfoque Gaussiano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gHR0CNZYN501"
   },
   "source": [
    "#### Tipos de convoluções\n",
    "\n",
    "Temos vários tipos de operações de convolução que podem ser aplicadas a uma imagem. Alguns deles são:\n",
    "\n",
    "* **Operação de identidade**: Função que retorna o mesmo valor que é usado como argumento.\n",
    "\n",
    "$f(x) = x;$\n",
    "\n",
    "kernel = [[0, 0, 0], [0, 1, 0], [0, 0, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lrW7I0ZvN502"
   },
   "outputs": [],
   "source": [
    "# Seu código aqui:\n",
    "\n",
    "img_name = dir_name + 'lena.png'\n",
    "img_mat = convert_image_matrix(img_name)\n",
    "identity_kernel = # definir um np array\n",
    "img_sampling = # gerar as sub matrizes com o get_sub_matrices\n",
    "transform_mat = # gerar a matriz transformada com o get_transformed_matrix\n",
    "original_VS_convoluted(img_name, 'identity', transform_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ato-qQ4UN507"
   },
   "source": [
    "Do resultado acima, fica claro que não há diferença entre a imagem original e a transformada.\n",
    "\n",
    "* **Operação de detecção de bordas**: A função inclui uma variedade de métodos matemáticos que visam identificar pontos em uma imagem digital para os quais o brilho da imagem muda. A técnica do detector de bordas de Canny funciona de forma eficaz.\n",
    "\n",
    "kernel = [[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zyoeiwx_N507"
   },
   "outputs": [],
   "source": [
    "# Seu código aqui:\n",
    "\n",
    "img_name = dir_name + 'lena.png'\n",
    "img_mat = convert_image_matrix(img_name)\n",
    "canny_edge_kernel = ...\n",
    "img_sampling = ...\n",
    "transform_mat = ...\n",
    "original_VS_convoluted(img_name, 'canny_edge', transform_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tw83LaG1N50-"
   },
   "source": [
    "A partir do resultado acima, podemos dizer que as bordas estão sendo destacadas em branco e o resto tudo é preto. O algoritmo foi capaz de identificar as bordas de detalhes específicos, como olhos e cabelos. No entanto, existem outros tipos de algoritmos de detecção de borda.\n",
    "\n",
    "* **Operação de nitidez**: A função aumenta o contraste entre as regiões claras e escuras da imagem.\n",
    "\n",
    "kernel = [[0, -1, 0], [-1, 5, -1], [0, -1, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EomTxnKSN50-"
   },
   "outputs": [],
   "source": [
    "# Seu código aqui:\n",
    "\n",
    "img_name = dir_name + 'lena.png'\n",
    "img_mat = convert_image_matrix(img_name)\n",
    "sharpen_kernel = ...\n",
    "img_sampling = ...\n",
    "transform_mat = ...\n",
    "original_VS_convoluted(img_name, 'sharpen', transform_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ljI8YFfN51A"
   },
   "source": [
    "Pelo resultado acima, fica claro que a imagem transformada persiste algum tipo de ruído e também vemos que as áreas mais claras ficaram ainda mais brilhantes e também as áreas mais escuras ficaram ainda mais escuras.\n",
    "\n",
    "* **Operação de desfoque de caixa**: a função é um tipo de filtro linear em que cada pixel na imagem resultante tem um valor igual ao valor médio de seus pixels vizinhos na imagem de entrada.\n",
    "\n",
    "kernel = (1/9) * [[1, 1, 1], [1, 1, 1], [1, 1, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V_0YeWeqN51B"
   },
   "outputs": [],
   "source": [
    "# Seu código aqui:\n",
    "\n",
    "img_name = dir_name + 'lena.png'\n",
    "img_mat = convert_image_matrix(img_name)\n",
    "box_blur_kernel = ...\n",
    "img_sampling = ...\n",
    "transform_mat = ...\n",
    "original_VS_convoluted(img_name, 'box_blur', transform_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbgD2YARN51D"
   },
   "source": [
    "A partir do resultado, notamos que a imagem transformada é ligeiramente mais suave que a imagem original. Como sabemos agora, quando o kernel é operado com as submatrizes, o resultado da soma é imediatamente calculado e, assim, deixando-o com um valor normalizado.\n",
    "\n",
    "* **Operação de desfoque gaussiano**: A função também é conhecida como função de suavização gaussiana normalmente usada para reduzir o ruído da imagem.\n",
    "\n",
    "kernel = (1/16) * [[1, 2, 1], [2, 4, 2], [1, 2, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I7KvdulmN51E"
   },
   "outputs": [],
   "source": [
    "# Seu código aqui:\n",
    "\n",
    "img_name = dir_name + 'lena.png'\n",
    "img_mat = convert_image_matrix(img_name)\n",
    "gaussian3_kernel = ...\n",
    "img_sampling = ...\n",
    "transform_mat = ...\n",
    "original_VS_convoluted(img_name, 'gaussian3', transform_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6XioXP3N51G"
   },
   "source": [
    "### Conclusão\n",
    "\n",
    "A convolução é uma operação matemática simples que é fundamental para muitos operadores comuns de processamento de imagens.\n",
    "\n",
    "Tem várias aplicações no campo da matemática, como probabilidade e estatística, sistemas lineares, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Die7LvMuN51H"
   },
   "source": [
    "# Padding\n",
    "\n",
    "A operação de convolução que vimos tem um pequeno problema: a imagem convolvida terá dimensões menores que a imagem original. Não percebemos isso porque a imagem utilizada é de alta resolução. Se testarmos as funções em imagens menores, essa perda ficará nítida.\n",
    "\n",
    "Assim, vamos executar a função anterior em imagens da coleção `CIFAR10`. Um arquivo contendo as 100 primeiras imagens desse conjunto pode ser baixado através [deste link](https://www.dropbox.com/s/qrfb8q7bzo47i2q/cifar10.zip?dl=0). Faça o download do zip e extraia o seu conteúdo para a pasta deste notebook. Depois disso, vamos testar uma convolução do tipo *identidade* em uma das imagens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NCN3LrJRN51I"
   },
   "source": [
    "### Exercício 4\n",
    "\n",
    "Execute a operação de identidade na figura `8.png` do conjunto CIFAR10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A-SXh9CmUURB"
   },
   "outputs": [],
   "source": [
    "img_8 = (train_set[7][0].numpy()*255).transpose((1,2,0))\n",
    "cv2.imwrite(dir_name + '8.png',img_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MAdzZyiKFOZ-"
   },
   "outputs": [],
   "source": [
    "# Seu código aqui:\n",
    "\n",
    "img_name = dir_name + 'lena.png'\n",
    "img_mat = convert_image_matrix(img_name)\n",
    "identity_kernel = ...\n",
    "img_sampling = ...\n",
    "transform_mat = ...\n",
    "original_VS_convoluted(img_name, 'identity', transform_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BvvAC3kpN51L"
   },
   "source": [
    "Note que a imagem convolvida é idêntica à original, mas sem as bordas extremas. Até que a perda é pequena, mas se muitas operações de convolução forem feitas de forma consecutiva, a imagem pode ficar muito pequena, ocasionando uma grande perda de informação.\n",
    "\n",
    "Para resolver esse problema, podemos realizar uma operação de *0-padding*, que adiciona `p` bordas adicionais com valores 0 à imagem original antes da operação de convolução. Embora a operação *0-padding* seja a operação padrão, e muitas vezes simplesmente chamada de *padding*, outras formas de preencher as bordas existem.\n",
    "\n",
    "Vamos implementar abaixo uma função para adicionar `p` bordas com zeros à uma imagem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dk07whS4N51M"
   },
   "source": [
    "### Exercício 5\n",
    "\n",
    "Implemente uma função para adicionar `p` bordas com zeros à uma imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ui7ktcvqN51N"
   },
   "outputs": [],
   "source": [
    "def add_padding(matrix: np.ndarray, padding: int) -> np.ndarray:\n",
    "    \"\"\"Adds padding to the matrix.\n",
    "    Args:\n",
    "        matrix (np.ndarray): Matrix that needs to be padded. Type is List[List[float]] casted to np.ndarray.\n",
    "        padding int: number of rows and columns to be padded. With the `p` padding we addding `p` rows to the top and bottom and `p` columns to the left and to the right of the matrix\n",
    "    Returns:\n",
    "        np.ndarray: Padded matrix with shape `n + 2 * p, m + 2 * p`.\n",
    "    \"\"\"\n",
    "    n, m = matrix.shape\n",
    "    p = padding\n",
    "\n",
    "    padded_matrix = []\n",
    "    # Seu código aqui\n",
    "\n",
    "    return padded_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1E0isiw2N51d"
   },
   "source": [
    "Sabendo que perdemos uma borda inteira de tamanho 1 pixel sem realizar o *padding*, vamos repetir a operação de convolução e adicionar exatamente um *padding* de tamanho 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "baCve2UrN51d"
   },
   "source": [
    "### Exercício 6\n",
    "\n",
    "Execute um padding de tamanho 1 na imagem `8.png` do conjunto CIFAR10 e depois realize a operação de convolução *identidade*. O tamanho da imagem convolvida se alterou?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p-SNknfgN51e"
   },
   "outputs": [],
   "source": [
    "img_name = dir_name + '8.png'\n",
    "img_mat = convert_image_matrix(img_name)\n",
    "img_mat = # executar o padding\n",
    "identity_kernel = # definir um np array\n",
    "img_sampling = # gerar as sub matrizes com o get_sub_matrices\n",
    "transform_mat = # gerar a matriz transformada com o get_transformed_matrix\n",
    "original_VS_convoluted(img_name, 'identity', transform_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qEJfGa0qN51g"
   },
   "source": [
    "Como esperado, a operação de identidade ficou perfeita, sem perda de informações."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "15CoqhZ6F7zjjAEkbworm2BpUrd6kBet5",
     "timestamp": 1736427474912
    },
    {
     "file_id": "1iBi6UeyI2-l9lZBve2SQiv3EIL9Wt-Ai",
     "timestamp": 1581130374675
    },
    {
     "file_id": "1Y1skfCJXPaZD7urPYYGOrNMaFSGU6h7v",
     "timestamp": 1581113055073
    },
    {
     "file_id": "1xEP0AA_NpC_P-XpdnxL1O7Ny9sHc8uF-",
     "timestamp": 1581112306324
    },
    {
     "file_id": "1Ryrv4mhgBXqllQNu5mWHH8En5O-WjCf7",
     "timestamp": 1532878867492
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
