{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"115-MyKFK6WoXNpw--3Wf5zyg9qFi_Lhs","timestamp":1737916539596}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"63a6b5d2130f49de995d8b87298f393e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1267a539a61f48b499984017b344826b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e9c52220ba4348fcb03ad3d4c37224be","IPY_MODEL_0f547a258bf4479d8566740d224b482a"]},"model_module_version":"1.5.0"},"1267a539a61f48b499984017b344826b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null},"model_module_version":"1.2.0"},"e9c52220ba4348fcb03ad3d4c37224be":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_157f152f56bb4275ad7417b60248c26e","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5b3c87a00bf146f19a4840d708fc0b9d"},"model_module_version":"1.5.0"},"0f547a258bf4479d8566740d224b482a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a652e14b414541af88d691ef255feead","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 170500096/? [00:20&lt;00:00, 52369918.15it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_647ddf9477db401fa19771363e3d95c0"},"model_module_version":"1.5.0"},"157f152f56bb4275ad7417b60248c26e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"},"model_module_version":"1.5.0"},"5b3c87a00bf146f19a4840d708fc0b9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null},"model_module_version":"1.2.0"},"a652e14b414541af88d691ef255feead":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"},"model_module_version":"1.5.0"},"647ddf9477db401fa19771363e3d95c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null},"model_module_version":"1.2.0"},"9c4a1ea66ed340d8b0419cfd1b68b07c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5c40fb6eabfc42fa94455f62312251bd","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_501a5e66387e4c8fa7c51c35a2a591b4","IPY_MODEL_70ef5ebd7daf4ccd8a419e8aba4e3f52"]},"model_module_version":"1.5.0"},"5c40fb6eabfc42fa94455f62312251bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null},"model_module_version":"1.2.0"},"501a5e66387e4c8fa7c51c35a2a591b4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1e9b184b374d40958d822f6556ab4278","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d460f93e9ab14a8db6da01b38fbaffb5"},"model_module_version":"1.5.0"},"70ef5ebd7daf4ccd8a419e8aba4e3f52":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_13b9ca5b94f44bb19bc934eb6bece083","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 170500096/? [00:20&lt;00:00, 101312684.17it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c67ab45ebd4940d289eebf389c8441d0"},"model_module_version":"1.5.0"},"1e9b184b374d40958d822f6556ab4278":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"},"model_module_version":"1.5.0"},"d460f93e9ab14a8db6da01b38fbaffb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null},"model_module_version":"1.2.0"},"13b9ca5b94f44bb19bc934eb6bece083":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"},"model_module_version":"1.5.0"},"c67ab45ebd4940d289eebf389c8441d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null},"model_module_version":"1.2.0"},"f92ff5c4f1774928b46d9943c18435ef":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a9113fb9fa3b40849fb69c86f43fdbee","IPY_MODEL_fd2bd1865219466e9d10c15130e90d3a","IPY_MODEL_f6a697299a0847c18df5814d1c04c8c7"],"layout":"IPY_MODEL_49b1f2fc5c444029bf33f548c692e476"}},"a9113fb9fa3b40849fb69c86f43fdbee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae0d934b19744531a13562bc9cf90830","placeholder":"​","style":"IPY_MODEL_6c4c7a45dc214316a1ce621a9333c25f","value":"100%"}},"fd2bd1865219466e9d10c15130e90d3a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5d8164ef5554de597d6a572d5c5f395","max":46830571,"min":0,"orientation":"horizontal","style":"IPY_MODEL_14eb6d7fa8484371b4b0066d941a72fc","value":46830571}},"f6a697299a0847c18df5814d1c04c8c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4f46b8444024ba686b48e18852e1cd2","placeholder":"​","style":"IPY_MODEL_9b8e208f52ae40d8af4b3d1932dc245f","value":" 44.7M/44.7M [00:00&lt;00:00, 106MB/s]"}},"49b1f2fc5c444029bf33f548c692e476":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae0d934b19744531a13562bc9cf90830":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c4c7a45dc214316a1ce621a9333c25f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f5d8164ef5554de597d6a572d5c5f395":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14eb6d7fa8484371b4b0066d941a72fc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d4f46b8444024ba686b48e18852e1cd2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b8e208f52ae40d8af4b3d1932dc245f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"vXlS74cg4Ebl"},"source":["# Estratégias de treino\n","\n","Até agora no curso, vimos somente uma estratégia de treino para redes neurais: o treinamento do zero.\n","Entretanto, há outras formas de se explorar redes neurais.\n","Nessa aula, vamos rever a estratégia treinamento do zero além de apresentar duas novas formas:\n","\n","1.   rede neural como um extrator de características, e\n","2.   *fine-tuning*.\n","\n","Para cada uma dessas estratégias, vamos apresentar sua definição, vantagens e desvantagens.\n"]},{"cell_type":"markdown","source":["## Configuração do ambiente"],"metadata":{"id":"MogIUS9nEGhT"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XDFChpaZ4MiW","outputId":"52e1da85-c790-40dc-bfd9-1e24f439e9fd","executionInfo":{"status":"ok","timestamp":1648169976025,"user_tz":180,"elapsed":4761,"user":{"displayName":"Matheus Barros","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhH5NyVCXJK6TrSbqUkA4UkI5i_9o6uarr2rqA_=s64","userId":"02610214632928731008"}}},"source":["import time, os, sys, numpy as np\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torch import optim\n","from torchinfo import summary\n","\n","import time, os, sys, numpy as np"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","n = torch.cuda.device_count()\n","devices_ids= list(range(n))\n","print(device)"],"metadata":{"id":"hTk3psAFD2hb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Carregamento das bases de dados\n","\n","A função `load_data_cifar10` carrega e prepara o dataset CIFAR-10 para treinamento e teste."],"metadata":{"id":"e8D3AjZ7EHqQ"}},{"cell_type":"code","metadata":{"id":"uF4QkjwG4RQI"},"source":["def load_data_cifar10(batch_size, resize=None, root='/pgeoprj2/ciag2024/dados/'):\n","    root = os.path.expanduser(root)\n","\n","    transformer = []\n","    if resize:\n","        transformer += [torchvision.transforms.Resize(resize)]\n","    transformer += [torchvision.transforms.ToTensor()]\n","    transformer = torchvision.transforms.Compose(transformer)\n","\n","    cifar10_train = torchvision.datasets.CIFAR10(root=root, train=True, transform=transformer)\n","    cifar10_test = torchvision.datasets.CIFAR10(root=root, train=False, transform=transformer)\n","\n","    num_workers = 0 if sys.platform.startswith('win32') else 4\n","\n","    train_iter = torch.utils.data.DataLoader(cifar10_train,\n","                                            batch_size, shuffle=True,\n","                                            num_workers=num_workers)\n","\n","    test_iter = torch.utils.data.DataLoader(cifar10_test,\n","                                            batch_size, shuffle=False,\n","                                            num_workers=num_workers)\n","    return train_iter, test_iter"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Funções auxiliares\n","\n","* `evaluate_accuracy` calcula a acurácia de um modelo em um dataset.\n","\n","* `train_validate` implemneta o treinamento e validação de uma rede."],"metadata":{"id":"iN00_qojFcZY"}},{"cell_type":"code","source":["def evaluate_accuracy(data_iter, net, loss):\n","    acc_sum, n, l = torch.Tensor([0]), 0, 0\n","    net.eval()\n","\n","    with torch.no_grad():\n","      for X, y in data_iter:\n","          X, y = X.to(device), y.to(device)\n","          y_hat = net(X)\n","          l += loss(y_hat, y).sum()\n","          acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n","          n += y.size()[0]\n","\n","    return acc_sum.item() / n, l.item() / len(data_iter)\n","\n","def train_validate(net, train_iter, test_iter, batch_size, trainer, loss, num_epochs):\n","    print('training on', device)\n","\n","    for epoch in range(num_epochs):\n","        net.train()\n","        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n","\n","        for X, y in train_iter:\n","            X,  y = X.to(device), y.to(device)\n","            y_hat = net(X)\n","\n","            trainer.zero_grad()\n","            l = loss(y_hat, y).sum()\n","\n","            l.backward()\n","            trainer.step()\n","\n","            train_l_sum += l.item()\n","            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n","            n += y.size()[0]\n","\n","        test_acc, test_loss = evaluate_accuracy(test_iter, net, loss)\n","\n","        print('epoch %d, train loss %.4f, train acc %.3f, test loss %.4f, '\n","              'test acc %.3f, time %.1f sec'\n","              % (epoch + 1, train_l_sum / len(train_iter), train_acc_sum / n, test_loss,\n","                 test_acc, time.time() - start))"],"metadata":{"id":"8MoklDDiFX0s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5Xu4l1od4y1N"},"source":["## Treinamento do zero\n","\n","Como dito anteriormente, essa foi a única estratégia vista até o momento no curso.\n","Nessa estratégia, uma rede neural é proposta, **inicializada com pesos aleatórios** e treinada até convergir.\n","A **vantagem** dessa estratégia é liberdade para definir como quiser a arquitetura da rede e seus hiper-parâmetros\n","Por outro lado, a **desvantagem** é que essa estratégia requer muitos dados para convergir a rede inicializada aleatoriamente.\n","Logo, se tivermos poucos dados, essa não é a estratégia mais recomendada.\n","Abaixo, uma representação visual dessa estratégia.\n","\n","<p align=\"center\">\n","  <img width=600 src=\"https://drive.google.com/uc?export=view&id=1_bBQjyoDqB3kQMncmVkuJwSxDs3rqUmM\">\n","</p>\n","\n","Apesar de já termos visto essa estratégia na prática, vamos vê-la aqui novamente para efeitos de comparação com as outras técnicas. Para tal, vamos, primeiro, definimos a arquitetura da [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf).\n","\n"]},{"cell_type":"code","metadata":{"id":"lZAEDlZ-DgGd"},"source":["class AlexNet(nn.Module):\n","    def __init__(self, input_channels, classes=10, **kwargs):\n","        super(AlexNet, self).__init__(**kwargs)\n","        self.convs = nn.Sequential(\n","            nn.Conv2d(in_channels=input_channels, out_channels=96, kernel_size=11, stride=4, padding=0),   # entrada: (b, 3, 227, 227) e saida: (b, 96, 55, 55)\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=3, stride=2, padding=0),                                   # entrada: (b, 96, 55, 55) e saida: (b, 96, 27, 27)\n","\n","            nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2),  # entrada: (b, 96, 27, 27) e saida: (b, 256, 27, 27)\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=3, stride=2, padding=0),                                   # entrada: (b, 256, 27, 27) e saida: (b, 256, 13, 13)\n","            nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1), # entrada: (b, 256, 13, 13) e saida: (b, 384, 13, 13)\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1), # entrada: (b, 384, 13, 13) e saida: (b, 384, 13, 13)\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1), # entrada: (b, 384, 13, 13) e saida: (b, 256, 13, 13)\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=3, stride=2, padding=0)                                    # entrada: (b, 256, 13, 13) e saida: (b, 256, 6, 6)\n","        )\n","\n","        self.features = nn.Sequential(\n","            nn.Flatten(),                                                                     # entrada: (b, 256, 13, 13) e saida: (b, 256*6*6) = (b, 9216)\n","            nn.Linear(9216, 4096),                                                             # entrada: (b, 9216) e saida: (b, 4096)\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(4096, 4096),                                                             # entrada: (b, 4096) e saida: (b, 4096)\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(4096, classes)                                                          # entrada: (b, 4096) e saida: (b, 10)\n","        )\n","\n","    def forward(self, x):\n","        x = self.convs(x)\n","        x = self.features(x)\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["63a6b5d2130f49de995d8b87298f393e","1267a539a61f48b499984017b344826b","e9c52220ba4348fcb03ad3d4c37224be","0f547a258bf4479d8566740d224b482a","157f152f56bb4275ad7417b60248c26e","5b3c87a00bf146f19a4840d708fc0b9d","a652e14b414541af88d691ef255feead","647ddf9477db401fa19771363e3d95c0"]},"id":"9Wr5rH-KMNZo","outputId":"5b781524-ed97-460c-e42d-6d7a1ad06560"},"source":["num_epochs, lr, batch_size, wd_lambda = 20, 0.01, 100, 0.0001\n","\n","net = AlexNet(3, 10)\n","net.to(device)\n","print(summary(net, (batch_size, 3, 227, 227)))\n","\n","loss = nn.CrossEntropyLoss()\n","\n","train_iter, test_iter = load_data_cifar10(batch_size, resize=227)\n","\n","trainer = optim.SGD(net.parameters(), lr=lr, weight_decay=wd_lambda, momentum=0.9)\n","\n","train_validate(net, train_iter, test_iter, batch_size, trainer, loss, num_epochs)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 96, 55, 55]          34,944\n","              ReLU-2           [-1, 96, 55, 55]               0\n","         MaxPool2d-3           [-1, 96, 27, 27]               0\n","            Conv2d-4          [-1, 256, 27, 27]         614,656\n","              ReLU-5          [-1, 256, 27, 27]               0\n","         MaxPool2d-6          [-1, 256, 13, 13]               0\n","            Conv2d-7          [-1, 384, 13, 13]         885,120\n","              ReLU-8          [-1, 384, 13, 13]               0\n","            Conv2d-9          [-1, 384, 13, 13]       1,327,488\n","             ReLU-10          [-1, 384, 13, 13]               0\n","           Conv2d-11          [-1, 256, 13, 13]         884,992\n","             ReLU-12          [-1, 256, 13, 13]               0\n","        MaxPool2d-13            [-1, 256, 6, 6]               0\n","          Flatten-14                 [-1, 9216]               0\n","           Linear-15                 [-1, 4096]      37,752,832\n","             ReLU-16                 [-1, 4096]               0\n","          Dropout-17                 [-1, 4096]               0\n","           Linear-18                 [-1, 4096]      16,781,312\n","             ReLU-19                 [-1, 4096]               0\n","          Dropout-20                 [-1, 4096]               0\n","           Linear-21                   [-1, 10]          40,970\n","================================================================\n","Total params: 58,322,314\n","Trainable params: 58,322,314\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.59\n","Forward/backward pass size (MB): 11.11\n","Params size (MB): 222.48\n","Estimated Total Size (MB): 234.18\n","----------------------------------------------------------------\n","None\n","Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /root/.pytorch/datasets/fashion-mnist/cifar-10-python.tar.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"63a6b5d2130f49de995d8b87298f393e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting /root/.pytorch/datasets/fashion-mnist/cifar-10-python.tar.gz to /root/.pytorch/datasets/fashion-mnist\n","Files already downloaded and verified\n","training on cuda\n","epoch 1, train loss 2.2015, train acc 0.161, test loss 1.9719, test acc 0.281, time 92.1 sec\n","epoch 2, train loss 1.7785, train acc 0.339, test loss 1.5453, test acc 0.423, time 93.5 sec\n","epoch 3, train loss 1.4151, train acc 0.483, test loss 1.2054, test acc 0.574, time 94.3 sec\n","epoch 4, train loss 1.1467, train acc 0.591, test loss 0.9854, test acc 0.656, time 94.4 sec\n","epoch 5, train loss 0.9382, train acc 0.671, test loss 0.8815, test acc 0.693, time 94.5 sec\n","epoch 6, train loss 0.7706, train acc 0.734, test loss 0.7898, test acc 0.728, time 95.9 sec\n","epoch 7, train loss 0.6444, train acc 0.777, test loss 0.6734, test acc 0.770, time 95.3 sec\n","epoch 8, train loss 0.5413, train acc 0.812, test loss 0.6623, test acc 0.779, time 95.8 sec\n","epoch 9, train loss 0.4430, train acc 0.846, test loss 0.6259, test acc 0.789, time 98.7 sec\n","epoch 10, train loss 0.3558, train acc 0.876, test loss 0.6036, test acc 0.799, time 99.4 sec\n","epoch 11, train loss 0.2787, train acc 0.903, test loss 0.6869, test acc 0.795, time 99.3 sec\n","epoch 12, train loss 0.2203, train acc 0.923, test loss 0.6432, test acc 0.808, time 99.4 sec\n","epoch 13, train loss 0.1925, train acc 0.934, test loss 0.7119, test acc 0.801, time 97.3 sec\n","epoch 14, train loss 0.1473, train acc 0.950, test loss 0.7386, test acc 0.807, time 97.1 sec\n","epoch 15, train loss 0.1273, train acc 0.957, test loss 0.8623, test acc 0.805, time 97.3 sec\n","epoch 16, train loss 0.1147, train acc 0.961, test loss 0.7945, test acc 0.803, time 98.0 sec\n","epoch 17, train loss 0.0930, train acc 0.969, test loss 0.8906, test acc 0.813, time 97.9 sec\n","epoch 18, train loss 0.0865, train acc 0.971, test loss 0.8490, test acc 0.810, time 99.5 sec\n","epoch 19, train loss 0.0689, train acc 0.977, test loss 0.9094, test acc 0.806, time 101.2 sec\n","epoch 20, train loss 0.0683, train acc 0.977, test loss 0.8422, test acc 0.816, time 100.3 sec\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RgJwhj2SSGFB"},"source":["É muito comum se usar redes já existentes para aprender características em novos dados.\n","Por isso, muitos frameworks já deixam as arquiteturas mais famosas pré-implementadas para que possam ser usadas.\n","\n","No Pytorch, podemos importar uma rede [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf) usando o pacote [torchvision.models](https://pytorch.org/docs/stable/torchvision/models.html#torchvision-models) do Pytorch.\n","Há várias arquiteturas pré-definidas nessa biblioteca, incluindo várias [DenseNets](https://arxiv.org/pdf/1608.06993.pdf) e [ResNets](https://arxiv.org/abs/1603.05027), [VGGs](https://arxiv.org/abs/1409.1556), [SqueezeNets](https://arxiv.org/abs/1602.07360), etc."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["9c4a1ea66ed340d8b0419cfd1b68b07c","5c40fb6eabfc42fa94455f62312251bd","501a5e66387e4c8fa7c51c35a2a591b4","70ef5ebd7daf4ccd8a419e8aba4e3f52","1e9b184b374d40958d822f6556ab4278","d460f93e9ab14a8db6da01b38fbaffb5","13b9ca5b94f44bb19bc934eb6bece083","c67ab45ebd4940d289eebf389c8441d0"]},"id":"f3u7xCEQM0qF","outputId":"576b9bbe-98b0-4f5b-ce44-5ff4eae067fa"},"source":["num_epochs, lr, batch_size, wd_lambda = 20, 0.01, 100, 0.0001\n","\n","# Rede importada do PyTorch\n","net = torchvision.models.alexnet(num_classes=10)\n","net.to(device)\n","print(summary(net, (batch_size, 3, 227, 227)))\n","\n","loss = nn.CrossEntropyLoss()\n","\n","train_iter, test_iter = load_data_cifar10(batch_size, resize=227)\n","\n","trainer = optim.SGD(net.parameters(), lr=lr, weight_decay=wd_lambda, momentum=0.9)\n","\n","train_validate(net, train_iter, test_iter, batch_size, trainer, loss, num_epochs)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 56, 56]          23,296\n","              ReLU-2           [-1, 64, 56, 56]               0\n","         MaxPool2d-3           [-1, 64, 27, 27]               0\n","            Conv2d-4          [-1, 192, 27, 27]         307,392\n","              ReLU-5          [-1, 192, 27, 27]               0\n","         MaxPool2d-6          [-1, 192, 13, 13]               0\n","            Conv2d-7          [-1, 384, 13, 13]         663,936\n","              ReLU-8          [-1, 384, 13, 13]               0\n","            Conv2d-9          [-1, 256, 13, 13]         884,992\n","             ReLU-10          [-1, 256, 13, 13]               0\n","           Conv2d-11          [-1, 256, 13, 13]         590,080\n","             ReLU-12          [-1, 256, 13, 13]               0\n","        MaxPool2d-13            [-1, 256, 6, 6]               0\n","AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n","          Dropout-15                 [-1, 9216]               0\n","           Linear-16                 [-1, 4096]      37,752,832\n","             ReLU-17                 [-1, 4096]               0\n","          Dropout-18                 [-1, 4096]               0\n","           Linear-19                 [-1, 4096]      16,781,312\n","             ReLU-20                 [-1, 4096]               0\n","           Linear-21                   [-1, 10]          40,970\n","================================================================\n","Total params: 57,044,810\n","Trainable params: 57,044,810\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.59\n","Forward/backward pass size (MB): 8.48\n","Params size (MB): 217.61\n","Estimated Total Size (MB): 226.68\n","----------------------------------------------------------------\n","None\n","Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /root/.pytorch/datasets/fashion-mnist/cifar-10-python.tar.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9c4a1ea66ed340d8b0419cfd1b68b07c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting /root/.pytorch/datasets/fashion-mnist/cifar-10-python.tar.gz to /root/.pytorch/datasets/fashion-mnist\n","Files already downloaded and verified\n","training on cuda\n","epoch 1, train loss 2.2569, train acc 0.132, test loss 2.0560, test acc 0.233, time 87.3 sec\n","epoch 2, train loss 1.8570, train acc 0.312, test loss 1.5836, test acc 0.414, time 87.2 sec\n","epoch 3, train loss 1.4649, train acc 0.463, test loss 1.2912, test acc 0.530, time 88.2 sec\n","epoch 4, train loss 1.2168, train acc 0.564, test loss 1.1152, test acc 0.600, time 88.2 sec\n","epoch 5, train loss 0.9965, train acc 0.651, test loss 0.9834, test acc 0.658, time 88.5 sec\n","epoch 6, train loss 0.8407, train acc 0.706, test loss 0.8171, test acc 0.722, time 88.8 sec\n","epoch 7, train loss 0.7193, train acc 0.749, test loss 0.7321, test acc 0.749, time 88.4 sec\n","epoch 8, train loss 0.6326, train acc 0.779, test loss 0.6461, test acc 0.778, time 88.1 sec\n","epoch 9, train loss 0.5552, train acc 0.805, test loss 0.6047, test acc 0.793, time 88.2 sec\n","epoch 10, train loss 0.4882, train acc 0.830, test loss 0.6147, test acc 0.788, time 88.2 sec\n","epoch 11, train loss 0.4301, train acc 0.850, test loss 0.5401, test acc 0.815, time 88.5 sec\n","epoch 12, train loss 0.3753, train acc 0.869, test loss 0.5618, test acc 0.809, time 88.5 sec\n","epoch 13, train loss 0.3325, train acc 0.881, test loss 0.5655, test acc 0.813, time 88.2 sec\n","epoch 14, train loss 0.2878, train acc 0.898, test loss 0.5629, test acc 0.827, time 88.6 sec\n","epoch 15, train loss 0.2535, train acc 0.911, test loss 0.5592, test acc 0.825, time 88.7 sec\n","epoch 16, train loss 0.2283, train acc 0.920, test loss 0.5841, test acc 0.827, time 88.7 sec\n","epoch 17, train loss 0.2010, train acc 0.929, test loss 0.6103, test acc 0.816, time 88.4 sec\n","epoch 18, train loss 0.1835, train acc 0.936, test loss 0.6266, test acc 0.816, time 88.6 sec\n","epoch 19, train loss 0.1588, train acc 0.945, test loss 0.6158, test acc 0.826, time 88.6 sec\n","epoch 20, train loss 0.1472, train acc 0.949, test loss 0.7042, test acc 0.814, time 88.0 sec\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0WyR3sukIS9D"},"source":["## Extrator de características\n","\n","A terceira e última estratégia, mostrada na figura abaixo, é usar uma rede neural pré-treinada em algum dataset grande para extrair características de um outro dataset. Essa estratégia é preferível quando o dataset que se quer extrair as *features* tem muito poucas amostras, inviabilizando o treinamento ou *fine-tuning* da rede.\n","\n","<p align=\"center\">\n","  <img width=600 src=\"https://drive.google.com/uc?export=view&id=1pWGfQIAeOODIvm-IQ7De4kl60XpRYbb5\">\n","</p>\n","\n","Existem duas formas de se explorar essa estratégia. A primeira consiste em substituir e treinar somente a última camada da rede neural. Nessa primeira forma, todas as outras camadas da rede ficam com *learning rate* 0, ou seja, não aprendem nada, e são somente usadas como codificadores/extratores de características. A segunda forma, *features* das imagens do dataset que se quer classificar são extraídas da penúltima camada da rede pré-treinada (geralmente, a camada antes da camada de classificação). Essas *features* são então usadas para se treinar um agoritmo externo (como um SVM ou *random forest*), que então classifica o dataset."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3VLBe7z2HmNK","outputId":"ba0e5ad7-9991-4e19-dce3-71d816aa7e55"},"source":["net = torchvision.models.alexnet(pretrained=True)\n","\n","for param in net.parameters():\n","    param.requires_grad = False\n","\n","print(summary(net, (batch_size, 3, 227, 227)))\n","\n","num_ftrs = net.classifier[6].in_features\n","net.classifier[6] = nn.Linear(num_ftrs,10) # Alterando a última layer para retornar 10 classes ao invés de 1000\n","\n","net.to(device)\n","\n","# Verifique no output a última camada do classifier, podemos ver que sua saída é 10\n","print(net)\n","\n","# Podemos ver que este output mostra que apenas  40970 parâmetros serão treinados. Ou seja, somente a última camada.\n","print(summary(net, (batch_size, 3, 227, 227)))\n","\n","# Código retirado de https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n","\n","# Veja os parâmetros a serem otimizados/atualizados nesta execução.\n","# Se estivermos fazendo finetuning, atualizaremos todos os parâmetros.\n","# No entanto, se estivermos fazendo o método feature extract, atualizaremos apenas os parâmetros que acabamos de inicializar, ou seja, os parâmetros com require_grad como True.\n","print(\"Params to learn: \")\n","\n","params_to_update = []\n","for name,param in net.named_parameters():\n","    if param.requires_grad == True:\n","        params_to_update.append(param)\n","        print(\"\\t\",name)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 56, 56]          23,296\n","              ReLU-2           [-1, 64, 56, 56]               0\n","         MaxPool2d-3           [-1, 64, 27, 27]               0\n","            Conv2d-4          [-1, 192, 27, 27]         307,392\n","              ReLU-5          [-1, 192, 27, 27]               0\n","         MaxPool2d-6          [-1, 192, 13, 13]               0\n","            Conv2d-7          [-1, 384, 13, 13]         663,936\n","              ReLU-8          [-1, 384, 13, 13]               0\n","            Conv2d-9          [-1, 256, 13, 13]         884,992\n","             ReLU-10          [-1, 256, 13, 13]               0\n","           Conv2d-11          [-1, 256, 13, 13]         590,080\n","             ReLU-12          [-1, 256, 13, 13]               0\n","        MaxPool2d-13            [-1, 256, 6, 6]               0\n","AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n","          Dropout-15                 [-1, 9216]               0\n","           Linear-16                 [-1, 4096]      37,752,832\n","             ReLU-17                 [-1, 4096]               0\n","          Dropout-18                 [-1, 4096]               0\n","           Linear-19                 [-1, 4096]      16,781,312\n","             ReLU-20                 [-1, 4096]               0\n","           Linear-21                 [-1, 1000]       4,097,000\n","================================================================\n","Total params: 61,100,840\n","Trainable params: 0\n","Non-trainable params: 61,100,840\n","----------------------------------------------------------------\n","Input size (MB): 0.59\n","Forward/backward pass size (MB): 8.49\n","Params size (MB): 233.08\n","Estimated Total Size (MB): 242.16\n","----------------------------------------------------------------\n","None\n","AlexNet(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n","    (1): ReLU(inplace=True)\n","    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (4): ReLU(inplace=True)\n","    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (7): ReLU(inplace=True)\n","    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (9): ReLU(inplace=True)\n","    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.5, inplace=False)\n","    (1): Linear(in_features=9216, out_features=4096, bias=True)\n","    (2): ReLU(inplace=True)\n","    (3): Dropout(p=0.5, inplace=False)\n","    (4): Linear(in_features=4096, out_features=4096, bias=True)\n","    (5): ReLU(inplace=True)\n","    (6): Linear(in_features=4096, out_features=10, bias=True)\n","  )\n",")\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 56, 56]          23,296\n","              ReLU-2           [-1, 64, 56, 56]               0\n","         MaxPool2d-3           [-1, 64, 27, 27]               0\n","            Conv2d-4          [-1, 192, 27, 27]         307,392\n","              ReLU-5          [-1, 192, 27, 27]               0\n","         MaxPool2d-6          [-1, 192, 13, 13]               0\n","            Conv2d-7          [-1, 384, 13, 13]         663,936\n","              ReLU-8          [-1, 384, 13, 13]               0\n","            Conv2d-9          [-1, 256, 13, 13]         884,992\n","             ReLU-10          [-1, 256, 13, 13]               0\n","           Conv2d-11          [-1, 256, 13, 13]         590,080\n","             ReLU-12          [-1, 256, 13, 13]               0\n","        MaxPool2d-13            [-1, 256, 6, 6]               0\n","AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n","          Dropout-15                 [-1, 9216]               0\n","           Linear-16                 [-1, 4096]      37,752,832\n","             ReLU-17                 [-1, 4096]               0\n","          Dropout-18                 [-1, 4096]               0\n","           Linear-19                 [-1, 4096]      16,781,312\n","             ReLU-20                 [-1, 4096]               0\n","           Linear-21                   [-1, 10]          40,970\n","================================================================\n","Total params: 57,044,810\n","Trainable params: 40,970\n","Non-trainable params: 57,003,840\n","----------------------------------------------------------------\n","Input size (MB): 0.59\n","Forward/backward pass size (MB): 8.48\n","Params size (MB): 217.61\n","Estimated Total Size (MB): 226.68\n","----------------------------------------------------------------\n","None\n","Params to learn: \n","\t classifier.6.weight\n","\t classifier.6.bias\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0fk0epQ2PDb0","outputId":"7538a430-fc04-4b26-e1da-4de225349e42"},"source":["# Treinando a última camada da rede acima\n","num_epochs, lr, batch_size, wd_lambda = 20, 0.001, 100, 0.0001\n","\n","loss = nn.CrossEntropyLoss()\n","\n","train_iter, test_iter = load_data_cifar10(batch_size, resize=227)\n","\n","trainer = optim.SGD(params_to_update, lr=lr, weight_decay=wd_lambda, momentum=0.9)\n","\n","train_validate(net, train_iter, test_iter, batch_size, trainer, loss, num_epochs)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","training on cuda\n","epoch 1, train loss 1.3262, train acc 0.534, test loss 1.0916, test acc 0.610, time 86.6 sec\n","epoch 2, train loss 1.1642, train acc 0.588, test loss 0.9961, test acc 0.654, time 86.8 sec\n","epoch 3, train loss 1.1277, train acc 0.602, test loss 0.9634, test acc 0.662, time 86.9 sec\n","epoch 4, train loss 1.1151, train acc 0.606, test loss 0.9462, test acc 0.672, time 86.8 sec\n","epoch 5, train loss 1.0945, train acc 0.614, test loss 0.9265, test acc 0.676, time 86.7 sec\n","epoch 6, train loss 1.0882, train acc 0.618, test loss 0.9345, test acc 0.671, time 86.8 sec\n","epoch 7, train loss 1.0796, train acc 0.618, test loss 0.9326, test acc 0.678, time 86.5 sec\n","epoch 8, train loss 1.0778, train acc 0.619, test loss 0.8997, test acc 0.684, time 86.5 sec\n","epoch 9, train loss 1.0652, train acc 0.626, test loss 0.9065, test acc 0.679, time 86.6 sec\n","epoch 10, train loss 1.0652, train acc 0.624, test loss 0.8911, test acc 0.687, time 86.8 sec\n","epoch 11, train loss 1.0613, train acc 0.623, test loss 0.9190, test acc 0.674, time 87.0 sec\n","epoch 12, train loss 1.0560, train acc 0.625, test loss 0.9070, test acc 0.678, time 86.6 sec\n","epoch 13, train loss 1.0552, train acc 0.627, test loss 0.8888, test acc 0.686, time 86.7 sec\n","epoch 14, train loss 1.0525, train acc 0.627, test loss 0.9140, test acc 0.673, time 86.8 sec\n","epoch 15, train loss 1.0493, train acc 0.628, test loss 0.8974, test acc 0.684, time 86.7 sec\n","epoch 16, train loss 1.0452, train acc 0.632, test loss 0.9008, test acc 0.683, time 86.6 sec\n","epoch 17, train loss 1.0462, train acc 0.631, test loss 0.8753, test acc 0.693, time 86.6 sec\n","epoch 18, train loss 1.0478, train acc 0.630, test loss 0.8919, test acc 0.681, time 86.8 sec\n","epoch 19, train loss 1.0452, train acc 0.630, test loss 0.9101, test acc 0.679, time 86.5 sec\n","epoch 20, train loss 1.0377, train acc 0.634, test loss 0.8619, test acc 0.698, time 86.9 sec\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ozt5EPQmSsx1","outputId":"82b0c52f-afb0-4324-f260-d832917ac1b5"},"source":["num_epochs, lr, batch_size, wd_lambda = 20, 0.01, 100, 0.0001\n","\n","net = torchvision.models.alexnet(pretrained=True)\n","net.to(device)\n","\n","train_iter, test_iter = load_data_cifar10(batch_size, resize=227)\n","\n","# Remover a última camada fully-connected\n","new_classifier = nn.Sequential(*list(net.classifier.children())[:-1])\n","net.classifier = new_classifier\n","\n","print(summary(net, (batch_size, 3, 227, 227)))\n","\n","first = True\n","with torch.no_grad():\n","    for X, y in train_iter:\n","        X, y = X.to(device), y.to(device)\n","        features = net(X)\n","        if first is True:\n","          train_features = features.cpu().numpy()\n","          train_labels = y.cpu().numpy()\n","          first = False\n","        else:\n","          train_features = np.concatenate((train_features, features.cpu().numpy()))\n","          train_labels = np.concatenate((train_labels, y.cpu().numpy()))\n","\n","first = True\n","with torch.no_grad():\n","    for X, y in test_iter:\n","        X, y = X.to(device), y.to(device)\n","        features = net(X)\n","        if first is True:\n","          test_features = features.cpu().numpy()\n","          test_labels = y.cpu().numpy()\n","          first = False\n","        else:\n","          test_features = np.concatenate((test_features, features.cpu().numpy()))\n","          test_labels = np.concatenate((test_labels, y.cpu().numpy()))\n","\n","print(train_features.shape, test_features.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 56, 56]          23,296\n","              ReLU-2           [-1, 64, 56, 56]               0\n","         MaxPool2d-3           [-1, 64, 27, 27]               0\n","            Conv2d-4          [-1, 192, 27, 27]         307,392\n","              ReLU-5          [-1, 192, 27, 27]               0\n","         MaxPool2d-6          [-1, 192, 13, 13]               0\n","            Conv2d-7          [-1, 384, 13, 13]         663,936\n","              ReLU-8          [-1, 384, 13, 13]               0\n","            Conv2d-9          [-1, 256, 13, 13]         884,992\n","             ReLU-10          [-1, 256, 13, 13]               0\n","           Conv2d-11          [-1, 256, 13, 13]         590,080\n","             ReLU-12          [-1, 256, 13, 13]               0\n","        MaxPool2d-13            [-1, 256, 6, 6]               0\n","AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n","          Dropout-15                 [-1, 9216]               0\n","           Linear-16                 [-1, 4096]      37,752,832\n","             ReLU-17                 [-1, 4096]               0\n","          Dropout-18                 [-1, 4096]               0\n","           Linear-19                 [-1, 4096]      16,781,312\n","             ReLU-20                 [-1, 4096]               0\n","================================================================\n","Total params: 57,003,840\n","Trainable params: 57,003,840\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.59\n","Forward/backward pass size (MB): 8.48\n","Params size (MB): 217.45\n","Estimated Total Size (MB): 226.52\n","----------------------------------------------------------------\n","None\n","(50000, 4096) (10000, 4096)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BR7LqiOTY6Tc","outputId":"76c66d61-8dab-46cd-cfd3-58152fc3324a"},"source":["from sklearn.svm import LinearSVC\n","from sklearn.metrics import accuracy_score\n","\n","clf = LinearSVC()\n","clf.fit(train_features, train_labels)\n","\n","pred = clf.predict(test_features)\n","print(accuracy_score(test_labels, pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  \"the number of iterations.\", ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["0.5193\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rsOgJBcofpZN"},"source":["## *Fine-tuning*\n","\n","A segunda estratégia é chamada de *fine-tuning*, e é comumente classificada como um estratégia de *transfer learning*, onde o aprendizado é transferido entre datasets.\n","Especificamente, esta estratégia, representada na figura abaixo, tenta usar um modelo pré-treinado aprendido anteriormente em algum dataset (geralmente muito grande, como o [ImageNet](http://www.image-net.org/)) para classificar outro conjunto de dados diferentes (geralmente com poucas amostras).\n","\n","<p align=\"center\">\n","  <img width=600 src=\"https://drive.google.com/uc?export=view&id=1CoOfpMcQAEl9YAL0lgW11LLYpDcnL4dQ\">\n","</p>\n","\n","Como esses dados podem possuir características diferentes, treinamos a rede usando um *learning rate* pequeno, apenas para fazer pequenos ajustes nos pesos. Entretanto, como esses datasets geralmente tem número e classes diferentes, a última camada não é usada nessa transferência de peso e, geralmente, é inicializada aleatoriamente (e por isso, tem um *learning rate* mais alto que as demais camadas).\n","\n","Por fim, é um [fato conhecido](https://arxiv.org/pdf/1602.01517.pdf) que as redes neurais conseguem aprender características de baixo nível nas camadas iniciais. Geralmente, essas características são comuns à vários datasets. Por isso, uma opção durante o processo de *fine-tuning* é \"congelar\" as camadas iniciais (ou seja, não treiná-las) e treinar somente as demais camadas com taxa de aprendizado bem pequeno (exceto pela camada de classificação).\n","\n","No bloco de código abaixo, importamos a rede pré-treinada [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf), que foi treinada no dataset do [ImageNet](http://www.image-net.org/), que tem 1000 classes. Como iremos fazer *fine-tuning* nessa arquitetura para o dataset do [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html), que tem somente 10 classes, removeremos a última camada e criaremos uma nova camada inicializada aleatoriamente."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2hDGgIDhdG2z","outputId":"61777eec-bff0-4563-e931-f0e9a101b357"},"source":["net = torchvision.models.alexnet(pretrained=True)\n","\n","print(summary(net, (batch_size, 3, 227, 227)))\n","\n","num_ftrs = net.classifier[6].in_features\n","net.classifier[6] = nn.Linear(num_ftrs, 10) # Alterando a última layer para retornar 10 classes ao invés de 1000\n","\n","net.to(device)\n","\n","# Verifique no output a última camada do classifier, podemos ver que sua saída é 10\n","print(net)\n","\n","# Podemos ver que este output mostra que apenas 40970 parâmetros serão treinados. Ou seja, somente a última camada.\n","print(summary(net, (batch_size, 3, 227, 227)))\n","\n","num_epochs, lr, batch_size, wd_lambda = 20, 0.001, 100, 0.0001\n","\n","loss = nn.CrossEntropyLoss()\n","\n","train_iter, test_iter = load_data_cifar10(batch_size, resize=227)\n","\n","trainer = optim.SGD([\n","                {'params': net.features.parameters(), 'lr': lr * 0.1},\n","                {'params': net.classifier[0:6].parameters(), 'lr': lr * 0.1},\n","                {'params': net.classifier[6].parameters(), 'lr': lr}], weight_decay=wd_lambda, momentum=0.9)\n","\n","train_validate(net, train_iter, test_iter, batch_size, trainer, loss, num_epochs)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 56, 56]          23,296\n","              ReLU-2           [-1, 64, 56, 56]               0\n","         MaxPool2d-3           [-1, 64, 27, 27]               0\n","            Conv2d-4          [-1, 192, 27, 27]         307,392\n","              ReLU-5          [-1, 192, 27, 27]               0\n","         MaxPool2d-6          [-1, 192, 13, 13]               0\n","            Conv2d-7          [-1, 384, 13, 13]         663,936\n","              ReLU-8          [-1, 384, 13, 13]               0\n","            Conv2d-9          [-1, 256, 13, 13]         884,992\n","             ReLU-10          [-1, 256, 13, 13]               0\n","           Conv2d-11          [-1, 256, 13, 13]         590,080\n","             ReLU-12          [-1, 256, 13, 13]               0\n","        MaxPool2d-13            [-1, 256, 6, 6]               0\n","AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n","          Dropout-15                 [-1, 9216]               0\n","           Linear-16                 [-1, 4096]      37,752,832\n","             ReLU-17                 [-1, 4096]               0\n","          Dropout-18                 [-1, 4096]               0\n","           Linear-19                 [-1, 4096]      16,781,312\n","             ReLU-20                 [-1, 4096]               0\n","           Linear-21                 [-1, 1000]       4,097,000\n","================================================================\n","Total params: 61,100,840\n","Trainable params: 61,100,840\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.59\n","Forward/backward pass size (MB): 8.49\n","Params size (MB): 233.08\n","Estimated Total Size (MB): 242.16\n","----------------------------------------------------------------\n","None\n","AlexNet(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n","    (1): ReLU(inplace=True)\n","    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (4): ReLU(inplace=True)\n","    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (7): ReLU(inplace=True)\n","    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (9): ReLU(inplace=True)\n","    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.5, inplace=False)\n","    (1): Linear(in_features=9216, out_features=4096, bias=True)\n","    (2): ReLU(inplace=True)\n","    (3): Dropout(p=0.5, inplace=False)\n","    (4): Linear(in_features=4096, out_features=4096, bias=True)\n","    (5): ReLU(inplace=True)\n","    (6): Linear(in_features=4096, out_features=10, bias=True)\n","  )\n",")\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 56, 56]          23,296\n","              ReLU-2           [-1, 64, 56, 56]               0\n","         MaxPool2d-3           [-1, 64, 27, 27]               0\n","            Conv2d-4          [-1, 192, 27, 27]         307,392\n","              ReLU-5          [-1, 192, 27, 27]               0\n","         MaxPool2d-6          [-1, 192, 13, 13]               0\n","            Conv2d-7          [-1, 384, 13, 13]         663,936\n","              ReLU-8          [-1, 384, 13, 13]               0\n","            Conv2d-9          [-1, 256, 13, 13]         884,992\n","             ReLU-10          [-1, 256, 13, 13]               0\n","           Conv2d-11          [-1, 256, 13, 13]         590,080\n","             ReLU-12          [-1, 256, 13, 13]               0\n","        MaxPool2d-13            [-1, 256, 6, 6]               0\n","AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n","          Dropout-15                 [-1, 9216]               0\n","           Linear-16                 [-1, 4096]      37,752,832\n","             ReLU-17                 [-1, 4096]               0\n","          Dropout-18                 [-1, 4096]               0\n","           Linear-19                 [-1, 4096]      16,781,312\n","             ReLU-20                 [-1, 4096]               0\n","           Linear-21                   [-1, 10]          40,970\n","================================================================\n","Total params: 57,044,810\n","Trainable params: 57,044,810\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.59\n","Forward/backward pass size (MB): 8.48\n","Params size (MB): 217.61\n","Estimated Total Size (MB): 226.68\n","----------------------------------------------------------------\n","None\n","Files already downloaded and verified\n","Files already downloaded and verified\n","training on cuda\n","epoch 1, train loss 0.9806, train acc 0.654, test loss 0.6364, test acc 0.776, time 84.2 sec\n","epoch 2, train loss 0.6690, train acc 0.768, test loss 0.5465, test acc 0.809, time 84.4 sec\n","epoch 3, train loss 0.5880, train acc 0.794, test loss 0.5182, test acc 0.818, time 84.2 sec\n","epoch 4, train loss 0.5356, train acc 0.815, test loss 0.4531, test acc 0.844, time 84.3 sec\n","epoch 5, train loss 0.5001, train acc 0.827, test loss 0.4471, test acc 0.847, time 84.5 sec\n","epoch 6, train loss 0.4728, train acc 0.834, test loss 0.4193, test acc 0.855, time 84.3 sec\n","epoch 7, train loss 0.4471, train acc 0.845, test loss 0.3970, test acc 0.860, time 84.6 sec\n","epoch 8, train loss 0.4314, train acc 0.849, test loss 0.4118, test acc 0.856, time 84.6 sec\n","epoch 9, train loss 0.4126, train acc 0.854, test loss 0.3848, test acc 0.864, time 84.8 sec\n","epoch 10, train loss 0.3979, train acc 0.861, test loss 0.3758, test acc 0.870, time 84.8 sec\n","epoch 11, train loss 0.3882, train acc 0.864, test loss 0.3794, test acc 0.866, time 84.6 sec\n","epoch 12, train loss 0.3738, train acc 0.868, test loss 0.3636, test acc 0.870, time 84.4 sec\n","epoch 13, train loss 0.3635, train acc 0.873, test loss 0.3448, test acc 0.877, time 84.7 sec\n","epoch 14, train loss 0.3552, train acc 0.876, test loss 0.3551, test acc 0.874, time 84.1 sec\n","epoch 15, train loss 0.3435, train acc 0.879, test loss 0.3383, test acc 0.881, time 84.4 sec\n","epoch 16, train loss 0.3370, train acc 0.882, test loss 0.3313, test acc 0.885, time 84.0 sec\n","epoch 17, train loss 0.3267, train acc 0.887, test loss 0.3287, test acc 0.883, time 83.9 sec\n","epoch 18, train loss 0.3179, train acc 0.890, test loss 0.3288, test acc 0.883, time 83.9 sec\n","epoch 19, train loss 0.3146, train acc 0.891, test loss 0.3229, test acc 0.887, time 83.9 sec\n","epoch 20, train loss 0.3056, train acc 0.893, test loss 0.3206, test acc 0.886, time 83.9 sec\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"K_uFa_Msi-EP"},"source":["## Atividade\n","\n","1. É possível melhorar o resultado obtido anteriormente?\n","Estude o [model_zoo](https://pytorch.org/vision/stable/models.html)  e tente usar as estratégias anteriores com diferentes redes neurais para melhorar o resultado.\n","Algumas redes possíveis:\n","\n","- [MobileNets](https://arxiv.org/abs/1801.04381)\n","- [VGGs](https://arxiv.org/abs/1409.1556)\n","- [ResNets](https://arxiv.org/abs/1603.05027)\n","- [DenseNets](https://arxiv.org/pdf/1608.06993.pdf)\n","\n","2. Procure agora congelar algumas camadas para realizar o *fine-tuning*. Essa estratégia é melhor quando se tem poucas imagens para fazer o *fine-tuning*.\n","\n","3. Procura usar outros algoritmos de aprendizado de máquina (como [*random forest*](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) e [SVM-RBF](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)) para classificar *deep features* extraídas de uma rede neural pré-treinada.\n","\n","- Procure também extrair e classificar *features* de outras camadas convolucionais.\n","\n","4. Procure usar as diferentes estratégias para melhorar os resultados dos datasets que já usamos, como [MNIST](https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision.datasets.MNIST) e [Fashion MNIST](https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision.datasets.FashionMNIST)."]},{"cell_type":"markdown","metadata":{"id":"HVock9TsZaYO"},"source":["### Fine-tuning ResNet-18"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f92ff5c4f1774928b46d9943c18435ef","a9113fb9fa3b40849fb69c86f43fdbee","fd2bd1865219466e9d10c15130e90d3a","f6a697299a0847c18df5814d1c04c8c7","49b1f2fc5c444029bf33f548c692e476","ae0d934b19744531a13562bc9cf90830","6c4c7a45dc214316a1ce621a9333c25f","f5d8164ef5554de597d6a572d5c5f395","14eb6d7fa8484371b4b0066d941a72fc","d4f46b8444024ba686b48e18852e1cd2","9b8e208f52ae40d8af4b3d1932dc245f"]},"id":"LUpWzBLYguiU","outputId":"c97cba55-8a77-4a29-8d86-25ee0b1877b9","executionInfo":{"status":"ok","timestamp":1648179042148,"user_tz":180,"elapsed":9052417,"user":{"displayName":"Matheus Barros","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhH5NyVCXJK6TrSbqUkA4UkI5i_9o6uarr2rqA_=s64","userId":"02610214632928731008"}}},"source":["net = torchvision.models.resnet18(pretrained=True)\n","\n","print(net)\n","\n","num_ftrs = net.fc.in_features\n","net.fc = nn.Linear(num_ftrs, 10) # Alterando a última layer para retornar 10 classes ao invés de 1000\n","\n","net.to(device)\n","\n","# Verifique no output a última camada do classifier, podemos ver que sua saída é 10\n","print(net)\n","\n","num_epochs, lr, batch_size, wd_lambda = 20, 0.001, 100, 0.0001\n","\n","loss = nn.CrossEntropyLoss()\n","\n","train_iter, test_iter = load_data_cifar10(batch_size, resize=227)\n","\n","trainer = optim.SGD([\n","                {'params': net.conv1.parameters(), 'lr': lr * 0.1},\n","                {'params': net.bn1.parameters(), 'lr': lr * 0.1},\n","                {'params': net.relu.parameters(), 'lr': lr * 0.1},\n","                {'params': net.maxpool.parameters(), 'lr': lr * 0.1},\n","                {'params': net.layer1.parameters(), 'lr': lr * 0.1},\n","                {'params': net.layer2.parameters(), 'lr': lr * 0.1},\n","                {'params': net.layer3.parameters(), 'lr': lr * 0.1},\n","                {'params': net.layer4.parameters(), 'lr': lr * 0.1},\n","                {'params': net.avgpool.parameters(), 'lr': lr * 0.1},\n","                {'params': net.fc.parameters(), 'lr': lr}], weight_decay=wd_lambda, momentum=0.9)\n","\n","train_validate(net, train_iter, test_iter, batch_size, trainer, loss, num_epochs)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/44.7M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f92ff5c4f1774928b46d9943c18435ef"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",")\n","ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=10, bias=True)\n",")\n","Files already downloaded and verified\n","Files already downloaded and verified\n","training on cuda\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["epoch 1, train loss 0.9887, train acc 0.702, test loss 0.5181, test acc 0.841, time 457.7 sec\n","epoch 2, train loss 0.4270, train acc 0.865, test loss 0.3602, test acc 0.884, time 452.9 sec\n","epoch 3, train loss 0.3200, train acc 0.895, test loss 0.3063, test acc 0.899, time 445.7 sec\n","epoch 4, train loss 0.2664, train acc 0.914, test loss 0.2718, test acc 0.909, time 448.0 sec\n","epoch 5, train loss 0.2333, train acc 0.923, test loss 0.3053, test acc 0.894, time 454.9 sec\n","epoch 6, train loss 0.2073, train acc 0.933, test loss 0.2450, test acc 0.917, time 452.5 sec\n","epoch 7, train loss 0.1879, train acc 0.938, test loss 0.2321, test acc 0.919, time 446.2 sec\n","epoch 8, train loss 0.1730, train acc 0.944, test loss 0.2219, test acc 0.922, time 447.0 sec\n","epoch 9, train loss 0.1587, train acc 0.948, test loss 0.2138, test acc 0.926, time 451.5 sec\n","epoch 10, train loss 0.1464, train acc 0.953, test loss 0.2141, test acc 0.926, time 452.8 sec\n","epoch 11, train loss 0.1346, train acc 0.957, test loss 0.2044, test acc 0.929, time 447.8 sec\n","epoch 12, train loss 0.1233, train acc 0.961, test loss 0.2029, test acc 0.928, time 449.8 sec\n","epoch 13, train loss 0.1152, train acc 0.963, test loss 0.2120, test acc 0.928, time 453.1 sec\n","epoch 14, train loss 0.1070, train acc 0.966, test loss 0.2013, test acc 0.930, time 451.7 sec\n","epoch 15, train loss 0.0962, train acc 0.971, test loss 0.2176, test acc 0.926, time 454.8 sec\n","epoch 16, train loss 0.0907, train acc 0.972, test loss 0.1943, test acc 0.935, time 453.6 sec\n","epoch 17, train loss 0.0845, train acc 0.975, test loss 0.1924, test acc 0.936, time 453.1 sec\n","epoch 18, train loss 0.0784, train acc 0.977, test loss 0.1894, test acc 0.937, time 456.9 sec\n","epoch 19, train loss 0.0718, train acc 0.979, test loss 0.1906, test acc 0.938, time 456.5 sec\n","epoch 20, train loss 0.0673, train acc 0.981, test loss 0.1902, test acc 0.938, time 459.9 sec\n"]}]},{"cell_type":"markdown","metadata":{"id":"4ru6oDk8ZgWO"},"source":["### Extracting features ResNet-152"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"651eAWJdKcuk","outputId":"07da0183-b59c-4784-cc8a-2b9c82a7ee2b"},"source":["num_epochs, lr, batch_size, wd_lambda = 20, 0.01, 100, 0.0001\n","\n","net = torchvision.models.resnet152(pretrained=True)\n","net.to(device)\n","\n","train_iter, test_iter = load_data_cifar10(batch_size, resize=227)\n","\n","# Remover última camada fully-connected\n","modules=list(net.children())[:-1]\n","net=nn.Sequential(*modules)\n","\n","print(summary(net, (batch_size, 3, 227, 227)))\n","\n","train_features = None\n","train_labels = None\n","first = True\n","with torch.no_grad():\n","    print('Extracting train features')\n","    for X, y in train_iter:\n","        X, y = X.to(device), y.to(device)\n","        features = net(X)\n","        if first is True:\n","          train_features = features.cpu().numpy()\n","          train_labels = y.cpu().numpy()\n","          first = False\n","        else:\n","          train_features = np.concatenate((train_features, features.cpu().numpy()))\n","          train_labels = np.concatenate((train_labels, y.cpu().numpy()))\n","\n","test_features = None\n","test_labels = None\n","first = True\n","with torch.no_grad():\n","    print('Extracting test features')\n","    for X, y in test_iter:\n","        X, y = X.to(device), y.to(device)\n","        features = net(X)\n","        if first is True:\n","          test_features = features.cpu().numpy()\n","          test_labels = y.cpu().numpy()\n","          first = False\n","        else:\n","          test_features = np.concatenate((test_features, features.cpu().numpy()))\n","          test_labels = np.concatenate((test_labels, y.cpu().numpy()))\n","\n","print(train_features.shape, test_features.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 114, 114]           9,408\n","       BatchNorm2d-2         [-1, 64, 114, 114]             128\n","              ReLU-3         [-1, 64, 114, 114]               0\n","         MaxPool2d-4           [-1, 64, 57, 57]               0\n","            Conv2d-5           [-1, 64, 57, 57]           4,096\n","       BatchNorm2d-6           [-1, 64, 57, 57]             128\n","              ReLU-7           [-1, 64, 57, 57]               0\n","            Conv2d-8           [-1, 64, 57, 57]          36,864\n","       BatchNorm2d-9           [-1, 64, 57, 57]             128\n","             ReLU-10           [-1, 64, 57, 57]               0\n","           Conv2d-11          [-1, 256, 57, 57]          16,384\n","      BatchNorm2d-12          [-1, 256, 57, 57]             512\n","           Conv2d-13          [-1, 256, 57, 57]          16,384\n","      BatchNorm2d-14          [-1, 256, 57, 57]             512\n","             ReLU-15          [-1, 256, 57, 57]               0\n","       Bottleneck-16          [-1, 256, 57, 57]               0\n","           Conv2d-17           [-1, 64, 57, 57]          16,384\n","      BatchNorm2d-18           [-1, 64, 57, 57]             128\n","             ReLU-19           [-1, 64, 57, 57]               0\n","           Conv2d-20           [-1, 64, 57, 57]          36,864\n","      BatchNorm2d-21           [-1, 64, 57, 57]             128\n","             ReLU-22           [-1, 64, 57, 57]               0\n","           Conv2d-23          [-1, 256, 57, 57]          16,384\n","      BatchNorm2d-24          [-1, 256, 57, 57]             512\n","             ReLU-25          [-1, 256, 57, 57]               0\n","       Bottleneck-26          [-1, 256, 57, 57]               0\n","           Conv2d-27           [-1, 64, 57, 57]          16,384\n","      BatchNorm2d-28           [-1, 64, 57, 57]             128\n","             ReLU-29           [-1, 64, 57, 57]               0\n","           Conv2d-30           [-1, 64, 57, 57]          36,864\n","      BatchNorm2d-31           [-1, 64, 57, 57]             128\n","             ReLU-32           [-1, 64, 57, 57]               0\n","           Conv2d-33          [-1, 256, 57, 57]          16,384\n","      BatchNorm2d-34          [-1, 256, 57, 57]             512\n","             ReLU-35          [-1, 256, 57, 57]               0\n","       Bottleneck-36          [-1, 256, 57, 57]               0\n","           Conv2d-37          [-1, 128, 57, 57]          32,768\n","      BatchNorm2d-38          [-1, 128, 57, 57]             256\n","             ReLU-39          [-1, 128, 57, 57]               0\n","           Conv2d-40          [-1, 128, 29, 29]         147,456\n","      BatchNorm2d-41          [-1, 128, 29, 29]             256\n","             ReLU-42          [-1, 128, 29, 29]               0\n","           Conv2d-43          [-1, 512, 29, 29]          65,536\n","      BatchNorm2d-44          [-1, 512, 29, 29]           1,024\n","           Conv2d-45          [-1, 512, 29, 29]         131,072\n","      BatchNorm2d-46          [-1, 512, 29, 29]           1,024\n","             ReLU-47          [-1, 512, 29, 29]               0\n","       Bottleneck-48          [-1, 512, 29, 29]               0\n","           Conv2d-49          [-1, 128, 29, 29]          65,536\n","      BatchNorm2d-50          [-1, 128, 29, 29]             256\n","             ReLU-51          [-1, 128, 29, 29]               0\n","           Conv2d-52          [-1, 128, 29, 29]         147,456\n","      BatchNorm2d-53          [-1, 128, 29, 29]             256\n","             ReLU-54          [-1, 128, 29, 29]               0\n","           Conv2d-55          [-1, 512, 29, 29]          65,536\n","      BatchNorm2d-56          [-1, 512, 29, 29]           1,024\n","             ReLU-57          [-1, 512, 29, 29]               0\n","       Bottleneck-58          [-1, 512, 29, 29]               0\n","           Conv2d-59          [-1, 128, 29, 29]          65,536\n","      BatchNorm2d-60          [-1, 128, 29, 29]             256\n","             ReLU-61          [-1, 128, 29, 29]               0\n","           Conv2d-62          [-1, 128, 29, 29]         147,456\n","      BatchNorm2d-63          [-1, 128, 29, 29]             256\n","             ReLU-64          [-1, 128, 29, 29]               0\n","           Conv2d-65          [-1, 512, 29, 29]          65,536\n","      BatchNorm2d-66          [-1, 512, 29, 29]           1,024\n","             ReLU-67          [-1, 512, 29, 29]               0\n","       Bottleneck-68          [-1, 512, 29, 29]               0\n","           Conv2d-69          [-1, 128, 29, 29]          65,536\n","      BatchNorm2d-70          [-1, 128, 29, 29]             256\n","             ReLU-71          [-1, 128, 29, 29]               0\n","           Conv2d-72          [-1, 128, 29, 29]         147,456\n","      BatchNorm2d-73          [-1, 128, 29, 29]             256\n","             ReLU-74          [-1, 128, 29, 29]               0\n","           Conv2d-75          [-1, 512, 29, 29]          65,536\n","      BatchNorm2d-76          [-1, 512, 29, 29]           1,024\n","             ReLU-77          [-1, 512, 29, 29]               0\n","       Bottleneck-78          [-1, 512, 29, 29]               0\n","           Conv2d-79          [-1, 128, 29, 29]          65,536\n","      BatchNorm2d-80          [-1, 128, 29, 29]             256\n","             ReLU-81          [-1, 128, 29, 29]               0\n","           Conv2d-82          [-1, 128, 29, 29]         147,456\n","      BatchNorm2d-83          [-1, 128, 29, 29]             256\n","             ReLU-84          [-1, 128, 29, 29]               0\n","           Conv2d-85          [-1, 512, 29, 29]          65,536\n","      BatchNorm2d-86          [-1, 512, 29, 29]           1,024\n","             ReLU-87          [-1, 512, 29, 29]               0\n","       Bottleneck-88          [-1, 512, 29, 29]               0\n","           Conv2d-89          [-1, 128, 29, 29]          65,536\n","      BatchNorm2d-90          [-1, 128, 29, 29]             256\n","             ReLU-91          [-1, 128, 29, 29]               0\n","           Conv2d-92          [-1, 128, 29, 29]         147,456\n","      BatchNorm2d-93          [-1, 128, 29, 29]             256\n","             ReLU-94          [-1, 128, 29, 29]               0\n","           Conv2d-95          [-1, 512, 29, 29]          65,536\n","      BatchNorm2d-96          [-1, 512, 29, 29]           1,024\n","             ReLU-97          [-1, 512, 29, 29]               0\n","       Bottleneck-98          [-1, 512, 29, 29]               0\n","           Conv2d-99          [-1, 128, 29, 29]          65,536\n","     BatchNorm2d-100          [-1, 128, 29, 29]             256\n","            ReLU-101          [-1, 128, 29, 29]               0\n","          Conv2d-102          [-1, 128, 29, 29]         147,456\n","     BatchNorm2d-103          [-1, 128, 29, 29]             256\n","            ReLU-104          [-1, 128, 29, 29]               0\n","          Conv2d-105          [-1, 512, 29, 29]          65,536\n","     BatchNorm2d-106          [-1, 512, 29, 29]           1,024\n","            ReLU-107          [-1, 512, 29, 29]               0\n","      Bottleneck-108          [-1, 512, 29, 29]               0\n","          Conv2d-109          [-1, 128, 29, 29]          65,536\n","     BatchNorm2d-110          [-1, 128, 29, 29]             256\n","            ReLU-111          [-1, 128, 29, 29]               0\n","          Conv2d-112          [-1, 128, 29, 29]         147,456\n","     BatchNorm2d-113          [-1, 128, 29, 29]             256\n","            ReLU-114          [-1, 128, 29, 29]               0\n","          Conv2d-115          [-1, 512, 29, 29]          65,536\n","     BatchNorm2d-116          [-1, 512, 29, 29]           1,024\n","            ReLU-117          [-1, 512, 29, 29]               0\n","      Bottleneck-118          [-1, 512, 29, 29]               0\n","          Conv2d-119          [-1, 256, 29, 29]         131,072\n","     BatchNorm2d-120          [-1, 256, 29, 29]             512\n","            ReLU-121          [-1, 256, 29, 29]               0\n","          Conv2d-122          [-1, 256, 15, 15]         589,824\n","     BatchNorm2d-123          [-1, 256, 15, 15]             512\n","            ReLU-124          [-1, 256, 15, 15]               0\n","          Conv2d-125         [-1, 1024, 15, 15]         262,144\n","     BatchNorm2d-126         [-1, 1024, 15, 15]           2,048\n","          Conv2d-127         [-1, 1024, 15, 15]         524,288\n","     BatchNorm2d-128         [-1, 1024, 15, 15]           2,048\n","            ReLU-129         [-1, 1024, 15, 15]               0\n","      Bottleneck-130         [-1, 1024, 15, 15]               0\n","          Conv2d-131          [-1, 256, 15, 15]         262,144\n","     BatchNorm2d-132          [-1, 256, 15, 15]             512\n","            ReLU-133          [-1, 256, 15, 15]               0\n","          Conv2d-134          [-1, 256, 15, 15]         589,824\n","     BatchNorm2d-135          [-1, 256, 15, 15]             512\n","            ReLU-136          [-1, 256, 15, 15]               0\n","          Conv2d-137         [-1, 1024, 15, 15]         262,144\n","     BatchNorm2d-138         [-1, 1024, 15, 15]           2,048\n","            ReLU-139         [-1, 1024, 15, 15]               0\n","      Bottleneck-140         [-1, 1024, 15, 15]               0\n","          Conv2d-141          [-1, 256, 15, 15]         262,144\n","     BatchNorm2d-142          [-1, 256, 15, 15]             512\n","            ReLU-143          [-1, 256, 15, 15]               0\n","          Conv2d-144          [-1, 256, 15, 15]         589,824\n","     BatchNorm2d-145          [-1, 256, 15, 15]             512\n","            ReLU-146          [-1, 256, 15, 15]               0\n","          Conv2d-147         [-1, 1024, 15, 15]         262,144\n","     BatchNorm2d-148         [-1, 1024, 15, 15]           2,048\n","            ReLU-149         [-1, 1024, 15, 15]               0\n","      Bottleneck-150         [-1, 1024, 15, 15]               0\n","          Conv2d-151          [-1, 256, 15, 15]         262,144\n","     BatchNorm2d-152          [-1, 256, 15, 15]             512\n","            ReLU-153          [-1, 256, 15, 15]               0\n","          Conv2d-154          [-1, 256, 15, 15]         589,824\n","     BatchNorm2d-155          [-1, 256, 15, 15]             512\n","            ReLU-156          [-1, 256, 15, 15]               0\n","          Conv2d-157         [-1, 1024, 15, 15]         262,144\n","     BatchNorm2d-158         [-1, 1024, 15, 15]           2,048\n","            ReLU-159         [-1, 1024, 15, 15]               0\n","      Bottleneck-160         [-1, 1024, 15, 15]               0\n","          Conv2d-161          [-1, 256, 15, 15]         262,144\n","     BatchNorm2d-162          [-1, 256, 15, 15]             512\n","            ReLU-163          [-1, 256, 15, 15]               0\n","          Conv2d-164          [-1, 256, 15, 15]         589,824\n","     BatchNorm2d-165          [-1, 256, 15, 15]             512\n","            ReLU-166          [-1, 256, 15, 15]               0\n","          Conv2d-167         [-1, 1024, 15, 15]         262,144\n","     BatchNorm2d-168         [-1, 1024, 15, 15]           2,048\n","            ReLU-169         [-1, 1024, 15, 15]               0\n","      Bottleneck-170         [-1, 1024, 15, 15]               0\n","          Conv2d-171          [-1, 256, 15, 15]         262,144\n","     BatchNorm2d-172          [-1, 256, 15, 15]             512\n","            ReLU-173          [-1, 256, 15, 15]               0\n","          Conv2d-174          [-1, 256, 15, 15]         589,824\n","     BatchNorm2d-175          [-1, 256, 15, 15]             512\n","            ReLU-176          [-1, 256, 15, 15]               0\n","          Conv2d-177         [-1, 1024, 15, 15]         262,144\n","     BatchNorm2d-178         [-1, 1024, 15, 15]           2,048\n","            ReLU-179         [-1, 1024, 15, 15]               0\n","      Bottleneck-180         [-1, 1024, 15, 15]               0\n","          Conv2d-181          [-1, 256, 15, 15]         262,144\n","     BatchNorm2d-182          [-1, 256, 15, 15]             512\n","            ReLU-183          [-1, 256, 15, 15]               0\n","          Conv2d-184          [-1, 256, 15, 15]         589,824\n","     BatchNorm2d-185          [-1, 256, 15, 15]             512\n","            ReLU-186          [-1, 256, 15, 15]               0\n","          Conv2d-187         [-1, 1024, 15, 15]         262,144\n","     BatchNorm2d-188         [-1, 1024, 15, 15]           2,048\n","            ReLU-189         [-1, 1024, 15, 15]               0\n","      Bottleneck-190         [-1, 1024, 15, 15]               0\n","          Conv2d-191          [-1, 256, 15, 15]         262,144\n","     BatchNorm2d-192          [-1, 256, 15, 15]             512\n","            ReLU-193          [-1, 256, 15, 15]               0\n","          Conv2d-194          [-1, 256, 15, 15]         589,824\n","     BatchNorm2d-195          [-1, 256, 15, 15]             512\n","            ReLU-196          [-1, 256, 15, 15]               0\n","          Conv2d-197         [-1, 1024, 15, 15]         262,144\n","     BatchNorm2d-198         [-1, 1024, 15, 15]           2,048\n","            ReLU-199         [-1, 1024, 15, 15]               0\n","      Bottleneck-200         [-1, 1024, 15, 15]               0\n","          Conv2d-201          [-1, 256, 15, 15]         262,144\n","     BatchNorm2d-202          [-1, 256, 15, 15]             512\n","            ReLU-203          [-1, 256, 15, 15]               0\n","          Conv2d-204          [-1, 256, 15, 15]         589,824\n","     BatchNorm2d-205          [-1, 256, 15, 15]             512\n","            ReLU-206          [-1, 256, 15, 15]               0\n","          Conv2d-207         [-1, 1024, 15, 15]         262,144\n","     BatchNorm2d-208         [-1, 1024, 15, 15]           2,048\n","            ReLU-209         [-1, 1024, 15, 15]               0\n","      Bottleneck-210         [-1, 1024, 15, 15]               0\n","          Conv2d-211          [-1, 256, 15, 15]         262,144\n","     BatchNorm2d-212          [-1, 256, 15, 15]             512\n","            ReLU-213          [-1, 256, 15, 15]               0\n","          Conv2d-214          [-1, 256, 15, 15]         589,824\n","     BatchNorm2d-215          [-1, 256, 15, 15]             512\n","            ReLU-216          [-1, 256, 15, 15]               0\n","          Conv2d-217         [-1, 1024, 15, 15]         262,144\n","     BatchNorm2d-218         [-1, 1024, 15, 15]           2,048\n","            ReLU-219         [-1, 1024, 15, 15]               0\n","      Bottleneck-220         [-1, 1024, 15, 15]               0\n","          Conv2d-221          [-1, 256, 15, 15]         262,144\n","     BatchNorm2d-222          [-1, 256, 15, 15]             512\n","            ReLU-223          [-1, 256, 15, 15]               0\n","          Conv2d-224          [-1, 256, 15, 15]         589,824\n","     BatchNorm2d-225          [-1, 256, 15, 15]             512\n","            ReLU-226          [-1, 256, 15, 15]               0\n","          Conv2d-227         [-1, 1024, 15, 15]         262,144\n","     BatchNorm2d-228         [-1, 1024, 15, 15]           2,048\n","            ReLU-229         [-1, 1024, 15, 15]               0\n","      Bottleneck-230         [-1, 1024, 15, 15]               0\n","          Conv2d-231          [-1, 256, 15, 15]         262,144\n","     BatchNorm2d-232          [-1, 256, 15, 15]             512\n","            ReLU-233          [-1, 256, 15, 15]               0\n","          Conv2d-234          [-1, 256, 15, 15]         589,824\n","     BatchNorm2d-235          [-1, 256, 15, 15]             512\n","            ReLU-236          [-1, 256, 15, 15]               0\n","          Conv2d-237         [-1, 1024, 15, 15]         262,144\n","     BatchNorm2d-238         [-1, 1024, 15, 15]           2,048\n","            ReLU-239         [-1, 1024, 15, 15]               0\n","      Bottleneck-240         [-1, 1024, 15, 15]               0\n","          Conv2d-241          [-1, 256, 15, 15]         262,144\n","     BatchNorm2d-242          [-1, 256, 15, 15]             512\n","            ReLU-243          [-1, 256, 15, 15]               0\n","          Conv2d-244          [-1, 256, 15, 15]         589,824\n","     BatchNorm2d-245          [-1, 256, 15, 15]             512\n","            ReLU-246          [-1, 256, 15, 15]               0\n","          Conv2d-247         [-1, 1024, 15, 15]         262,144\n","     BatchNorm2d-248         [-1, 1024, 15, 15]           2,048\n","            ReLU-249         [-1, 1024, 15, 15]               0\n","      Bottleneck-250         [-1, 1024, 15, 15]               0\n","          Conv2d-251          [-1, 256, 15, 15]         262,144\n","     BatchNorm2d-252          [-1, 256, 15, 15]             512\n","            ReLU-253          [-1, 256, 15, 15]               0\n","          Conv2d-254          [-1, 256, 15, 15]         589,824\n","     BatchNorm2d-255          [-1, 256, 15, 15]             512\n","            ReLU-256          [-1, 256, 15, 15]               0\n","          Conv2d-257         [-1, 1024, 15, 15]         262,144\n","     BatchNorm2d-258         [-1, 1024, 15, 15]           2,048\n","            ReLU-259         [-1, 1024, 15, 15]               0\n","      Bottleneck-260         [-1, 1024, 15, 15]               0\n","          Conv2d-261          [-1, 256, 15, 15]         262,144\n","     BatchNorm2d-262          [-1, 256, 15, 15]             512\n","            ReLU-263          [-1, 256, 15, 15]               0\n","          Conv2d-264          [-1, 256, 15, 15]         589,824\n","     BatchNorm2d-265          [-1, 256, 15, 15]             512\n","            ReLU-266          [-1, 256, 15, 15]               0\n","          Conv2d-267         [-1, 1024, 15, 15]         262,144\n","     BatchNorm2d-268         [-1, 1024, 15, 15]           2,048\n","            ReLU-269         [-1, 1024, 15, 15]               0\n","      Bottleneck-270         [-1, 1024, 15, 15]               0\n","          Conv2d-271          [-1, 256, 15, 15]         262,144\n","     BatchNorm2d-272          [-1, 256, 15, 15]             512\n","            ReLU-273          [-1, 256, 15, 15]               0\n","          Conv2d-274          [-1, 256, 15, 15]         589,824\n","     BatchNorm2d-275          [-1, 256, 15, 15]             512\n","            ReLU-276          [-1, 256, 15, 15]               0\n","          Conv2d-277         [-1, 1024, 15, 15]         262,144\n","     BatchNorm2d-278         [-1, 1024, 15, 15]           2,048\n","            ReLU-279         [-1, 1024, 15, 15]               0\n","      Bottleneck-280         [-1, 1024, 15, 15]               0\n","          Conv2d-281          [-1, 256, 15, 15]         262,144\n","     BatchNorm2d-282          [-1, 256, 15, 15]             512\n","            ReLU-283          [-1, 256, 15, 15]               0\n","          Conv2d-284          [-1, 256, 15, 15]         589,824\n","     BatchNorm2d-285          [-1, 256, 15, 15]             512\n","            ReLU-286          [-1, 256, 15, 15]               0\n","          Conv2d-287         [-1, 1024, 15, 15]         262,144\n","     BatchNorm2d-288         [-1, 1024, 15, 15]           2,048\n","            ReLU-289         [-1, 1024, 15, 15]               0\n","      Bottleneck-290         [-1, 1024, 15, 15]               0\n","          Conv2d-291          [-1, 256, 15, 15]         262,144\n","     BatchNorm2d-292          [-1, 256, 15, 15]             512\n","            ReLU-293          [-1, 256, 15, 15]               0\n","          Conv2d-294          [-1, 256, 15, 15]         589,824\n","     BatchNorm2d-295          [-1, 256, 15, 15]             512\n","            ReLU-296          [-1, 256, 15, 15]               0\n","          Conv2d-297         [-1, 1024, 15, 15]         262,144\n","     BatchNorm2d-298         [-1, 1024, 15, 15]           2,048\n","            ReLU-299         [-1, 1024, 15, 15]               0\n","      Bottleneck-300         [-1, 1024, 15, 15]               0\n","          Conv2d-301          [-1, 256, 15, 15]         262,144\n","     BatchNorm2d-302          [-1, 256, 15, 15]             512\n","            ReLU-303          [-1, 256, 15, 15]               0\n","          Conv2d-304          [-1, 256, 15, 15]         589,824\n","     BatchNorm2d-305          [-1, 256, 15, 15]             512\n","            ReLU-306          [-1, 256, 15, 15]               0\n","          Conv2d-307         [-1, 1024, 15, 15]         262,144\n","     BatchNorm2d-308         [-1, 1024, 15, 15]           2,048\n","            ReLU-309         [-1, 1024, 15, 15]               0\n","      Bottleneck-310         [-1, 1024, 15, 15]               0\n","          Conv2d-311          [-1, 256, 15, 15]         262,144\n","     BatchNorm2d-312          [-1, 256, 15, 15]             512\n","            ReLU-313          [-1, 256, 15, 15]               0\n","          Conv2d-314          [-1, 256, 15, 15]         589,824\n","     BatchNorm2d-315          [-1, 256, 15, 15]             512\n","            ReLU-316          [-1, 256, 15, 15]               0\n","          Conv2d-317         [-1, 1024, 15, 15]         262,144\n","     BatchNorm2d-318         [-1, 1024, 15, 15]           2,048\n","            ReLU-319         [-1, 1024, 15, 15]               0\n","      Bottleneck-320         [-1, 1024, 15, 15]               0\n","          Conv2d-321          [-1, 256, 15, 15]         262,144\n","     BatchNorm2d-322          [-1, 256, 15, 15]             512\n","            ReLU-323          [-1, 256, 15, 15]               0\n","          Conv2d-324          [-1, 256, 15, 15]         589,824\n","     BatchNorm2d-325          [-1, 256, 15, 15]             512\n","            ReLU-326          [-1, 256, 15, 15]               0\n","          Conv2d-327         [-1, 1024, 15, 15]         262,144\n","     BatchNorm2d-328         [-1, 1024, 15, 15]           2,048\n","            ReLU-329         [-1, 1024, 15, 15]               0\n","      Bottleneck-330         [-1, 1024, 15, 15]               0\n","          Conv2d-331          [-1, 256, 15, 15]         262,144\n","     BatchNorm2d-332          [-1, 256, 15, 15]             512\n","            ReLU-333          [-1, 256, 15, 15]               0\n","          Conv2d-334          [-1, 256, 15, 15]         589,824\n","     BatchNorm2d-335          [-1, 256, 15, 15]             512\n","            ReLU-336          [-1, 256, 15, 15]               0\n","          Conv2d-337         [-1, 1024, 15, 15]         262,144\n","     BatchNorm2d-338         [-1, 1024, 15, 15]           2,048\n","            ReLU-339         [-1, 1024, 15, 15]               0\n","      Bottleneck-340         [-1, 1024, 15, 15]               0\n","          Conv2d-341          [-1, 256, 15, 15]         262,144\n","     BatchNorm2d-342          [-1, 256, 15, 15]             512\n","            ReLU-343          [-1, 256, 15, 15]               0\n","          Conv2d-344          [-1, 256, 15, 15]         589,824\n","     BatchNorm2d-345          [-1, 256, 15, 15]             512\n","            ReLU-346          [-1, 256, 15, 15]               0\n","          Conv2d-347         [-1, 1024, 15, 15]         262,144\n","     BatchNorm2d-348         [-1, 1024, 15, 15]           2,048\n","            ReLU-349         [-1, 1024, 15, 15]               0\n","      Bottleneck-350         [-1, 1024, 15, 15]               0\n","          Conv2d-351          [-1, 256, 15, 15]         262,144\n","     BatchNorm2d-352          [-1, 256, 15, 15]             512\n","            ReLU-353          [-1, 256, 15, 15]               0\n","          Conv2d-354          [-1, 256, 15, 15]         589,824\n","     BatchNorm2d-355          [-1, 256, 15, 15]             512\n","            ReLU-356          [-1, 256, 15, 15]               0\n","          Conv2d-357         [-1, 1024, 15, 15]         262,144\n","     BatchNorm2d-358         [-1, 1024, 15, 15]           2,048\n","            ReLU-359         [-1, 1024, 15, 15]               0\n","      Bottleneck-360         [-1, 1024, 15, 15]               0\n","          Conv2d-361          [-1, 256, 15, 15]         262,144\n","     BatchNorm2d-362          [-1, 256, 15, 15]             512\n","            ReLU-363          [-1, 256, 15, 15]               0\n","          Conv2d-364          [-1, 256, 15, 15]         589,824\n","     BatchNorm2d-365          [-1, 256, 15, 15]             512\n","            ReLU-366          [-1, 256, 15, 15]               0\n","          Conv2d-367         [-1, 1024, 15, 15]         262,144\n","     BatchNorm2d-368         [-1, 1024, 15, 15]           2,048\n","            ReLU-369         [-1, 1024, 15, 15]               0\n","      Bottleneck-370         [-1, 1024, 15, 15]               0\n","          Conv2d-371          [-1, 256, 15, 15]         262,144\n","     BatchNorm2d-372          [-1, 256, 15, 15]             512\n","            ReLU-373          [-1, 256, 15, 15]               0\n","          Conv2d-374          [-1, 256, 15, 15]         589,824\n","     BatchNorm2d-375          [-1, 256, 15, 15]             512\n","            ReLU-376          [-1, 256, 15, 15]               0\n","          Conv2d-377         [-1, 1024, 15, 15]         262,144\n","     BatchNorm2d-378         [-1, 1024, 15, 15]           2,048\n","            ReLU-379         [-1, 1024, 15, 15]               0\n","      Bottleneck-380         [-1, 1024, 15, 15]               0\n","          Conv2d-381          [-1, 256, 15, 15]         262,144\n","     BatchNorm2d-382          [-1, 256, 15, 15]             512\n","            ReLU-383          [-1, 256, 15, 15]               0\n","          Conv2d-384          [-1, 256, 15, 15]         589,824\n","     BatchNorm2d-385          [-1, 256, 15, 15]             512\n","            ReLU-386          [-1, 256, 15, 15]               0\n","          Conv2d-387         [-1, 1024, 15, 15]         262,144\n","     BatchNorm2d-388         [-1, 1024, 15, 15]           2,048\n","            ReLU-389         [-1, 1024, 15, 15]               0\n","      Bottleneck-390         [-1, 1024, 15, 15]               0\n","          Conv2d-391          [-1, 256, 15, 15]         262,144\n","     BatchNorm2d-392          [-1, 256, 15, 15]             512\n","            ReLU-393          [-1, 256, 15, 15]               0\n","          Conv2d-394          [-1, 256, 15, 15]         589,824\n","     BatchNorm2d-395          [-1, 256, 15, 15]             512\n","            ReLU-396          [-1, 256, 15, 15]               0\n","          Conv2d-397         [-1, 1024, 15, 15]         262,144\n","     BatchNorm2d-398         [-1, 1024, 15, 15]           2,048\n","            ReLU-399         [-1, 1024, 15, 15]               0\n","      Bottleneck-400         [-1, 1024, 15, 15]               0\n","          Conv2d-401          [-1, 256, 15, 15]         262,144\n","     BatchNorm2d-402          [-1, 256, 15, 15]             512\n","            ReLU-403          [-1, 256, 15, 15]               0\n","          Conv2d-404          [-1, 256, 15, 15]         589,824\n","     BatchNorm2d-405          [-1, 256, 15, 15]             512\n","            ReLU-406          [-1, 256, 15, 15]               0\n","          Conv2d-407         [-1, 1024, 15, 15]         262,144\n","     BatchNorm2d-408         [-1, 1024, 15, 15]           2,048\n","            ReLU-409         [-1, 1024, 15, 15]               0\n","      Bottleneck-410         [-1, 1024, 15, 15]               0\n","          Conv2d-411          [-1, 256, 15, 15]         262,144\n","     BatchNorm2d-412          [-1, 256, 15, 15]             512\n","            ReLU-413          [-1, 256, 15, 15]               0\n","          Conv2d-414          [-1, 256, 15, 15]         589,824\n","     BatchNorm2d-415          [-1, 256, 15, 15]             512\n","            ReLU-416          [-1, 256, 15, 15]               0\n","          Conv2d-417         [-1, 1024, 15, 15]         262,144\n","     BatchNorm2d-418         [-1, 1024, 15, 15]           2,048\n","            ReLU-419         [-1, 1024, 15, 15]               0\n","      Bottleneck-420         [-1, 1024, 15, 15]               0\n","          Conv2d-421          [-1, 256, 15, 15]         262,144\n","     BatchNorm2d-422          [-1, 256, 15, 15]             512\n","            ReLU-423          [-1, 256, 15, 15]               0\n","          Conv2d-424          [-1, 256, 15, 15]         589,824\n","     BatchNorm2d-425          [-1, 256, 15, 15]             512\n","            ReLU-426          [-1, 256, 15, 15]               0\n","          Conv2d-427         [-1, 1024, 15, 15]         262,144\n","     BatchNorm2d-428         [-1, 1024, 15, 15]           2,048\n","            ReLU-429         [-1, 1024, 15, 15]               0\n","      Bottleneck-430         [-1, 1024, 15, 15]               0\n","          Conv2d-431          [-1, 256, 15, 15]         262,144\n","     BatchNorm2d-432          [-1, 256, 15, 15]             512\n","            ReLU-433          [-1, 256, 15, 15]               0\n","          Conv2d-434          [-1, 256, 15, 15]         589,824\n","     BatchNorm2d-435          [-1, 256, 15, 15]             512\n","            ReLU-436          [-1, 256, 15, 15]               0\n","          Conv2d-437         [-1, 1024, 15, 15]         262,144\n","     BatchNorm2d-438         [-1, 1024, 15, 15]           2,048\n","            ReLU-439         [-1, 1024, 15, 15]               0\n","      Bottleneck-440         [-1, 1024, 15, 15]               0\n","          Conv2d-441          [-1, 256, 15, 15]         262,144\n","     BatchNorm2d-442          [-1, 256, 15, 15]             512\n","            ReLU-443          [-1, 256, 15, 15]               0\n","          Conv2d-444          [-1, 256, 15, 15]         589,824\n","     BatchNorm2d-445          [-1, 256, 15, 15]             512\n","            ReLU-446          [-1, 256, 15, 15]               0\n","          Conv2d-447         [-1, 1024, 15, 15]         262,144\n","     BatchNorm2d-448         [-1, 1024, 15, 15]           2,048\n","            ReLU-449         [-1, 1024, 15, 15]               0\n","      Bottleneck-450         [-1, 1024, 15, 15]               0\n","          Conv2d-451          [-1, 256, 15, 15]         262,144\n","     BatchNorm2d-452          [-1, 256, 15, 15]             512\n","            ReLU-453          [-1, 256, 15, 15]               0\n","          Conv2d-454          [-1, 256, 15, 15]         589,824\n","     BatchNorm2d-455          [-1, 256, 15, 15]             512\n","            ReLU-456          [-1, 256, 15, 15]               0\n","          Conv2d-457         [-1, 1024, 15, 15]         262,144\n","     BatchNorm2d-458         [-1, 1024, 15, 15]           2,048\n","            ReLU-459         [-1, 1024, 15, 15]               0\n","      Bottleneck-460         [-1, 1024, 15, 15]               0\n","          Conv2d-461          [-1, 256, 15, 15]         262,144\n","     BatchNorm2d-462          [-1, 256, 15, 15]             512\n","            ReLU-463          [-1, 256, 15, 15]               0\n","          Conv2d-464          [-1, 256, 15, 15]         589,824\n","     BatchNorm2d-465          [-1, 256, 15, 15]             512\n","            ReLU-466          [-1, 256, 15, 15]               0\n","          Conv2d-467         [-1, 1024, 15, 15]         262,144\n","     BatchNorm2d-468         [-1, 1024, 15, 15]           2,048\n","            ReLU-469         [-1, 1024, 15, 15]               0\n","      Bottleneck-470         [-1, 1024, 15, 15]               0\n","          Conv2d-471          [-1, 256, 15, 15]         262,144\n","     BatchNorm2d-472          [-1, 256, 15, 15]             512\n","            ReLU-473          [-1, 256, 15, 15]               0\n","          Conv2d-474          [-1, 256, 15, 15]         589,824\n","     BatchNorm2d-475          [-1, 256, 15, 15]             512\n","            ReLU-476          [-1, 256, 15, 15]               0\n","          Conv2d-477         [-1, 1024, 15, 15]         262,144\n","     BatchNorm2d-478         [-1, 1024, 15, 15]           2,048\n","            ReLU-479         [-1, 1024, 15, 15]               0\n","      Bottleneck-480         [-1, 1024, 15, 15]               0\n","          Conv2d-481          [-1, 512, 15, 15]         524,288\n","     BatchNorm2d-482          [-1, 512, 15, 15]           1,024\n","            ReLU-483          [-1, 512, 15, 15]               0\n","          Conv2d-484            [-1, 512, 8, 8]       2,359,296\n","     BatchNorm2d-485            [-1, 512, 8, 8]           1,024\n","            ReLU-486            [-1, 512, 8, 8]               0\n","          Conv2d-487           [-1, 2048, 8, 8]       1,048,576\n","     BatchNorm2d-488           [-1, 2048, 8, 8]           4,096\n","          Conv2d-489           [-1, 2048, 8, 8]       2,097,152\n","     BatchNorm2d-490           [-1, 2048, 8, 8]           4,096\n","            ReLU-491           [-1, 2048, 8, 8]               0\n","      Bottleneck-492           [-1, 2048, 8, 8]               0\n","          Conv2d-493            [-1, 512, 8, 8]       1,048,576\n","     BatchNorm2d-494            [-1, 512, 8, 8]           1,024\n","            ReLU-495            [-1, 512, 8, 8]               0\n","          Conv2d-496            [-1, 512, 8, 8]       2,359,296\n","     BatchNorm2d-497            [-1, 512, 8, 8]           1,024\n","            ReLU-498            [-1, 512, 8, 8]               0\n","          Conv2d-499           [-1, 2048, 8, 8]       1,048,576\n","     BatchNorm2d-500           [-1, 2048, 8, 8]           4,096\n","            ReLU-501           [-1, 2048, 8, 8]               0\n","      Bottleneck-502           [-1, 2048, 8, 8]               0\n","          Conv2d-503            [-1, 512, 8, 8]       1,048,576\n","     BatchNorm2d-504            [-1, 512, 8, 8]           1,024\n","            ReLU-505            [-1, 512, 8, 8]               0\n","          Conv2d-506            [-1, 512, 8, 8]       2,359,296\n","     BatchNorm2d-507            [-1, 512, 8, 8]           1,024\n","            ReLU-508            [-1, 512, 8, 8]               0\n","          Conv2d-509           [-1, 2048, 8, 8]       1,048,576\n","     BatchNorm2d-510           [-1, 2048, 8, 8]           4,096\n","            ReLU-511           [-1, 2048, 8, 8]               0\n","      Bottleneck-512           [-1, 2048, 8, 8]               0\n","AdaptiveAvgPool2d-513           [-1, 2048, 1, 1]               0\n","================================================================\n","Total params: 58,143,808\n","Trainable params: 58,143,808\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.59\n","Forward/backward pass size (MB): 671.77\n","Params size (MB): 221.80\n","Estimated Total Size (MB): 894.16\n","----------------------------------------------------------------\n","None\n","Extracting train features\n"]}]},{"cell_type":"code","metadata":{"id":"U8jL9I9cKe-Z"},"source":["from sklearn.svm import LinearSVC\n","from sklearn.metrics import accuracy_score\n","\n","clf = LinearSVC()\n","clf.fit(train_features.squeeze(), train_labels)\n","\n","pred = clf.predict(test_features)\n","print(accuracy_score(test_labels.squeeze(), pred))"],"execution_count":null,"outputs":[]}]}