{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1p_hB-QGBCSHArX3CI0zskampVDO9SU3z","timestamp":1736429253048}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Redes residuais\n","\n","Neste notebook, vamos explorar as **redes residuais**, uma arquitetura de redes neurais que facilita o treinamento de redes muito profundas. Veremos como as redes residuais superam problemas comuns, como o desaparecimento do gradiente, e entenderemos suas aplicações em tarefas de visão computacional. Por fim, vamos implementar uma rede residual para classificação."],"metadata":{"id":"Y6aWBfmxOyHu"}},{"cell_type":"markdown","metadata":{"id":"NG-mVsVuE0if"},"source":["## Configuração do ambiente"]},{"cell_type":"code","metadata":{"id":"fEHmMCjR4PJw"},"source":["import os\n","import time\n","import numpy as np\n","import torch\n","\n","from torch import nn\n","from torch import optim\n","\n","from torch.utils.data import DataLoader\n","from torch.utils import data\n","from torch.backends import cudnn\n","\n","from torchvision import models\n","from torchvision import datasets\n","from torchvision import transforms\n","\n","from skimage import io\n","\n","from sklearn import metrics\n","\n","from matplotlib import pyplot as plt\n","\n","%matplotlib inline\n","\n","cudnn.benchmark = True"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Carregamento da base de dados"],"metadata":{"id":"MPmv9lwd1dNB"}},{"cell_type":"code","metadata":{"id":"RwhRUUlc4j23"},"source":["args = {\n","    'epoch_num': 50,\n","    'n_classes': 10,\n","    'lr': 1e-4,\n","    'weight_decay': 5e-4,\n","    'momentum': 0.9,\n","    'num_workers': 4,\n","    'batch_size': 200,\n","    'w_size': 224, # largura da imagem para redimensionar\n","    'h_size': 224, # altura da imagem para redimensionar\n","}\n","\n","if torch.cuda.is_available():\n","    args['device'] = torch.device('cuda')\n","else:\n","    args['device'] = torch.device('cpu')\n","\n","print(args['device'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ura-BNFMcoTb"},"source":["root = './'\n","\n","data_transform = transforms.Compose([\n","    transforms.Resize((100, 100)),\n","    transforms.RandomCrop((75, 75)),\n","    transforms.ColorJitter(brightness=0.5, contrast=0.5),\n","    transforms.ToTensor(),\n","])\n","\n","train_set = datasets.CIFAR10(root,\n","                             train=True,\n","                             download=True,\n","                             transform=data_transform)\n","\n","test_set = datasets.CIFAR10(root,\n","                            train=False,\n","                            download=False,\n","                            transform=data_transform)\n","\n","for iters in range(5):\n","\n","    fig, ax = plt.subplots(1, 5, figsize=(20, 4))\n","\n","    for i, test_data in enumerate(test_set):\n","\n","        if i >= 5:\n","            break\n","\n","        test_img, _ = test_data\n","\n","        ax[i].imshow(test_img.numpy().transpose(1, 2, 0))\n","        ax[i].set_yticks([])\n","        ax[i].set_xticks([])\n","        ax[i].set_title('Image ' + str(i))\n","\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vi3Zh8fQ4X_3"},"source":["data_transform = transforms.Compose([\n","    transforms.Resize((args['h_size'], args['w_size'])),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","train_set = datasets.CIFAR10(root,\n","                             train=True,\n","                             download=True,\n","                             transform=data_transform)\n","\n","test_set = datasets.CIFAR10(root,\n","                            train=False,\n","                            download=False,\n","                            transform=data_transform)\n","\n","train_loader = DataLoader(train_set,\n","                          args['batch_size'],\n","                          num_workers=args['num_workers'],\n","                          shuffle=True)\n","\n","test_loader = DataLoader(test_set,\n","                         args['batch_size'],\n","                         num_workers=args['num_workers'],\n","                         shuffle=False)\n","\n","print('Size of training set: ' + str(len(train_set)) + ' samples')\n","print('Size of test set: ' + str(len(test_set)) + ' samples')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MWKYCVh5oFtL"},"source":["## *ResNets*\n","\n","Entre 2012 e 2015, a comunidade de Visão Computacional percebeu que redes mais profundas conseguiam capturar características semânticas mais úteis dos dados para tarefas de reconhecimento de imagens (i.e. classificação, segmentação, detecção etc). Porém, redes mais profundas que as maiores arquiteturas da época -- como a [VGG](https://arxiv.org/abs/1409.1556) e a [Inception](https://arxiv.org/abs/1409.4842) -- sofriam de um problema chamado **Vanishing Gradient**.\n","\n","![VGG](https://www.researchgate.net/profile/Clifford_Yang/publication/325137356/figure/fig2/AS:670371271413777@1536840374533/llustration-of-the-network-architecture-of-VGG-19-model-conv-means-convolution-FC-means_W640.jpg)\n","\n","![Inception](https://miro.medium.com/max/700/1*uW81y16b-ptBDV8SIT1beQ.png)\n","\n","\n","O **Vanishing Gradient** se torna mais problemático em redes mais profundas porque o gradiente dos erros precisa propagar desde a última camada até o começo da rede. Dessa forma, as últimas camadas conseguem ser treinadas de forma eficiente, mas o gradiente dos erros vai desaparecendo à medida em que backpropaga pela rede, praticamente impossibilitando o treinamento das primeiras camadas. Assim, foi constatado que uma rede com, por exemplo, 34 camadas acabava por conseguir resultados piores que uma rede com apenas 18 camadas.\n","\n","![Rede Não Residual](https://www.dropbox.com/s/pq190al5b3qv194/normal_18_vs_34_layers.png?dl=1)\n","\n","Ao final de 2015 foi proposta uma solução para o **Vanishing Gradient** na forma de **Blocos Residuais** que, juntos, formam **Redes Residuais** [**(ResNets)**](https://arxiv.org/abs/1512.03385). Esses blocos residuais recebem uma entrada $x$ e a alimentam para um bloco convolucional $F$ composto por:\n","\n","1.   Convolução 3x3;\n","2.   Batch Normalization;\n","3.   ReLU;\n","4.   Convolução 3x3;\n","5.   Batch Normalization.\n","\n","A saída $F(x)$ desse bloco, antes de ser passada por uma segunda ReLU, é passada em conjunto com a entrada $x$ para uma função identidade, que, no caso das **ResNets**, é uma simples soma. Dessa forma, a saída final de um **Bloco Residual** é dada por: $F(x) + x$. O esquema de um **Bloco Residual** pode ser visto na figura abaixo.\n","\n","![Bloco Residual](https://www.dropbox.com/s/ezydump33p95ohc/residual_block.png?dl=1)\n","\n","Como pode ser visto na imagem a seguir, com o uso de blocos residuais, uma arquitetura com 34 camadas consegue resultados melhores que uma arquitetura com apenas 18 camadas. Esses resultados evidenciam que o uso da soma como **identity function** de fato permite que o backward treine mais efetivamente as primeiras camadas das **ResNets**. **ResNets** permitiram que CNNs chegassem até a casa das 100 camadas. A maior **ResNet** usada na prática possui 152 camadas, o que a deixa impraticável de imprimir numa figura como é mostrado abaixo na ResNet34.\n","\n","![Rede Residual](https://www.dropbox.com/s/q4wcjwf8qj4xjrn/resnet_18_vs_34_layers.png?dl=1)\n","\n","Como pode ser visto nas imagens abaixo, ResNets (e outras arquiteturas modernas como a [VGG](https://arxiv.org/abs/1409.1556) e as [DenseNets](https://arxiv.org/abs/1608.06993) são compostas basicamente de convoluções com kernels de tamanho 3x3. Além disso, é notável na arquitetura residual (à direita) a presença dos \"atalhos\" para o gradiente  na forma das funções identidade que ajudam no treinamento das primeiras camadas durante o backpropagation.\n","\n","![VGG vs. Plain34 vs. ResNet34](https://www.dropbox.com/s/d2w3h7dlumgclx2/vgg_plain34_resnet34.png?dl=1)"]},{"cell_type":"markdown","metadata":{"id":"UHotK0b3hqpG"},"source":["### Atividade\n","\n","Implemente as classes `ResidualBlock` e `ResNet18`."]},{"cell_type":"code","metadata":{"id":"25PD5HF-8XxD"},"source":["class ResidualBlock(nn.Module):\n","\n","    def __init__(self, in_planes, out_planes):\n","\n","        super(ResidualBlock, self).__init__()\n","\n","        # TO DO: definir o primeiro e o segundo bloco convolucional\n","\n","        self.conv1x1 = None\n","        if in_planes != out_planes:\n","            self.conv1x1 = # TO DO: definir convolução 1x1\n","\n","\n","    def forward(self, x):\n","        identity = x\n","\n","        # TO DO: forward no primeiro bloco convolucional\n","\n","        # TO DO: forward no segundo bloco convolucional (não se esqueça da conv 1x1 para igualar o número de canais)\n","\n","        # TO DO: retornar saída\n","\n","class ResNet18(nn.Module):\n","\n","    def __init__(self, num_classes=10):\n","\n","        super(ResNet, self).__init__()\n","\n","        # TO DO: bloco convolucional:\n","        #        1. conv com kernel 7x7, 64 canais de saída, stride 2,\n","        #           padding 3 e sem bias;\n","        #        2. 2d batch normalization;\n","        #        3. ReLU;\n","        #        4. 2d max pool com kernel 3x3, stride 2 e padding 1.\n","\n","        # TO DO: primeiro bloco residual + pooling:\n","        #        1. instanciar bloco residual da classe ResidualBlock com\n","        #           número de canais de saída igual a 64;\n","        #        2. 2d max pool com kernel 3x3, stride 2 e padding 1.\n","\n","        # TO DO: segundo bloco residual + pooling:\n","        #        1. instanciar bloco residual da classe ResidualBlock com\n","        #           número de canais de saída igual a 128;\n","        #        2. 2d max pool com kernel 3x3, stride 2 e padding 1.\n","\n","        # TO DO: classificador:\n","        #        1. nn.AdaptiveAvgPool2d(output_size(1, 1))\n","        #        2. definir camada de classificação FC com 10 saídas.\n","\n","        self.initialize_weights()\n","\n","    def initialize_weights(self):\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","                if m.bias is not None:\n","                    nn.init.constant_(m.bias, 0)\n","            elif isinstance(m, nn.BatchNorm2d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","            elif isinstance(m, nn.Linear):\n","                nn.init.normal_(m.weight, 0, 0.01)\n","                nn.init.constant_(m.bias, 0)\n","\n","    def forward(self, x):\n","\n","        # TO DO: forward no bloco convolucional\n","\n","        # TO DO: forward no primeiro bloco residual\n","\n","        # TO DO: forward no segundo bloco residual\n","\n","        # TO DO: forward no adaptive_pool\n","\n","        # TO DO: linearizar tensor para servir como entrada para a camada FC\n","\n","        # TO DO: obter 10 previsões (uma para cada classe) na camada FC\n","\n","        # TO DO: retornar saída\n","\n","net = ResNet18(args['n_classes']).to(args['device'])\n","\n","print(net)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nS2l_pqAI0F2"},"source":["O Pytorch possui vários otimizadores prontos no subpacote [optim](https://pytorch.org/docs/stable/optim.html), desde o SGD básico a otimizadores mais complexos e com taxas de aprendizado por parâmetro como o Adagrad, RMSProp e Adam."]},{"cell_type":"code","metadata":{"id":"Y_-RN1wH-4bB"},"source":["optimizer = optim.Adam(net.parameters(),\n","                       lr=args['lr'],\n","                       betas=(args['momentum'], 0.999),\n","                       weight_decay=args['weight_decay'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DVhOWUkWKU4f"},"source":["O subpacote [nn](https://pytorch.org/docs/stable/nn.html) possui várias funções de perda para diferentes tarefas (i.e. Cross Entropy, Negative Log Likelihood, loss L1, MSE, Kullback Leibler Divergence, etc) implementadas por padrão.\n","\n"]},{"cell_type":"code","metadata":{"id":"NX_bmN3__LIK"},"source":["criterion = nn.CrossEntropyLoss().to(args['device'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kXhZakGZK_kU"},"source":["### Treinamento e teste\n","\n","Iterando sobre os datasets de treino e teste do CIFAR10. Abaixo são implementadas a função *train()* que itera sobre os batches do dataset de treino e atualiza o modelo e a função *test()* que apenas realiza o forward dos dados de teste no modelo e calcula a acurácia no dataset de teste para o modelo no estado atual."]},{"cell_type":"code","metadata":{"id":"OCU5Gx9D_6xW"},"source":["def train(train_loader, net, criterion, optimizer, epoch):\n","    tic = time.time()\n","\n","    net.train()\n","\n","    train_loss = []\n","\n","    for i, batch_data in enumerate(train_loader):\n","        inps, labs = batch_data\n","\n","        inps = inps.to(args['device'])\n","        labs = labs.to(args['device'])\n","\n","        # Limpa os gradientes do otimizador\n","        optimizer.zero_grad()\n","\n","        # Forward\n","        outs = net(inps)\n","\n","        # Calcula perda\n","        loss = criterion(outs, labs)\n","\n","        # Calcula backpropagation\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss.append(loss.data.item())\n","\n","    toc = time.time()\n","\n","    train_loss = np.asarray(train_loss)\n","\n","    print('--------------------------------------------------------------------')\n","    print('[epoch %d], [train loss %.4f +/- %.4f], [training time %.2f]' % (\n","        epoch, train_loss.mean(), train_loss.std(), (toc - tic)))\n","    print('--------------------------------------------------------------------')\n","\n","def test(test_loader, net, criterion, epoch):\n","    tic = time.time()\n","\n","    net.eval()\n","\n","    test_loss = []\n","    prd_list = []\n","    lab_list = []\n","\n","    for i, batch_data in enumerate(train_loader):\n","        inps, labs = batch_data\n","\n","        inps = inps.to(args['device'])\n","        labs = labs.to(args['device'])\n","\n","        outs = net(inps)\n","\n","        loss = criterion(outs, labs)\n","\n","        prds = outs.data.max(dim=1)[1].cpu().numpy()\n","\n","        test_loss.append(loss.data.item())\n","        prd_list.append(prds)\n","        lab_list.append(labs.detach().cpu().numpy())\n","\n","    toc = time.time()\n","\n","    acc = metrics.accuracy_score(np.asarray(lab_list).ravel(),\n","                                 np.asarray(prd_list).ravel())\n","\n","    test_loss = np.asarray(test_loss)\n","\n","    print('--------------------------------------------------------------------')\n","    print('[epoch %d], [test loss %.4f +/- %.4f], [acc %.4f], [testing time %.2f]' % (\n","        epoch, test_loss.mean(), test_loss.std(), acc, (toc - tic)))\n","    print('--------------------------------------------------------------------')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RU2aYIob_zTu"},"source":["for epoch in range(1, args['epoch_num'] + 1):\n","\n","    train(train_loader, net, criterion, optimizer, epoch)\n","\n","    test(test_loader, net, criterion, epoch)"],"execution_count":null,"outputs":[]}]}