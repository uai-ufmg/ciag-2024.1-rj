{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"115-MyKFK6WoXNpw--3Wf5zyg9qFi_Lhs","timestamp":1737916539596}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"markdown","metadata":{"id":"vXlS74cg4Ebl"},"source":["# Estratégias de treino\n","\n","Até agora no curso, vimos somente uma estratégia de treino para redes neurais: o treinamento do zero.\n","Entretanto, há outras formas de se explorar redes neurais.\n","Nessa aula, vamos rever a estratégia treinamento do zero além de apresentar duas novas formas:\n","\n","1.   rede neural como um extrator de características, e\n","2.   *fine-tuning*.\n","\n","Para cada uma dessas estratégias, vamos apresentar sua definição, vantagens e desvantagens.\n"]},{"cell_type":"markdown","source":["## Configuração do ambiente"],"metadata":{"id":"MogIUS9nEGhT"}},{"cell_type":"code","metadata":{"id":"XDFChpaZ4MiW"},"source":["import time, os, sys, numpy as np\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torch import optim\n","from torchinfo import summary\n","\n","import time, os, sys, numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","n = torch.cuda.device_count()\n","devices_ids= list(range(n))\n","print(device)"],"metadata":{"id":"hTk3psAFD2hb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Carregamento das bases de dados\n","\n","A função `load_data_cifar10` carrega e prepara o dataset CIFAR-10 para treinamento e teste."],"metadata":{"id":"e8D3AjZ7EHqQ"}},{"cell_type":"code","metadata":{"id":"uF4QkjwG4RQI"},"source":["def load_data_cifar10(batch_size, resize=None, root='/pgeoprj2/ciag2024/dados/'):\n","    root = os.path.expanduser(root)\n","\n","    transformer = []\n","    if resize:\n","        transformer += [torchvision.transforms.Resize(resize)]\n","    transformer += [torchvision.transforms.ToTensor()]\n","    transformer = torchvision.transforms.Compose(transformer)\n","\n","    cifar10_train = torchvision.datasets.CIFAR10(root=root, train=True, transform=transformer)\n","    cifar10_test = torchvision.datasets.CIFAR10(root=root, train=False, transform=transformer)\n","\n","    num_workers = 0 if sys.platform.startswith('win32') else 4\n","\n","    train_iter = torch.utils.data.DataLoader(cifar10_train,\n","                                            batch_size, shuffle=True,\n","                                            num_workers=num_workers)\n","\n","    test_iter = torch.utils.data.DataLoader(cifar10_test,\n","                                            batch_size, shuffle=False,\n","                                            num_workers=num_workers)\n","    return train_iter, test_iter"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Funções auxiliares\n","\n","* `evaluate_accuracy` calcula a acurácia de um modelo em um dataset.\n","\n","* `train_validate` implemneta o treinamento e validação de uma rede."],"metadata":{"id":"iN00_qojFcZY"}},{"cell_type":"code","source":["def evaluate_accuracy(data_iter, net, loss):\n","    acc_sum, n, l = torch.Tensor([0]), 0, 0\n","    net.eval()\n","\n","    with torch.no_grad():\n","      for X, y in data_iter:\n","          X, y = X.to(device), y.to(device)\n","          y_hat = net(X)\n","          l += loss(y_hat, y).sum()\n","          acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n","          n += y.size()[0]\n","\n","    return acc_sum.item() / n, l.item() / len(data_iter)\n","\n","def train_validate(net, train_iter, test_iter, batch_size, trainer, loss, num_epochs):\n","    print('training on', device)\n","\n","    for epoch in range(num_epochs):\n","        net.train()\n","        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n","\n","        for X, y in train_iter:\n","            X,  y = X.to(device), y.to(device)\n","            y_hat = net(X)\n","\n","            trainer.zero_grad()\n","            l = loss(y_hat, y).sum()\n","\n","            l.backward()\n","            trainer.step()\n","\n","            train_l_sum += l.item()\n","            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n","            n += y.size()[0]\n","\n","        test_acc, test_loss = evaluate_accuracy(test_iter, net, loss)\n","\n","        print('epoch %d, train loss %.4f, train acc %.3f, test loss %.4f, '\n","              'test acc %.3f, time %.1f sec'\n","              % (epoch + 1, train_l_sum / len(train_iter), train_acc_sum / n, test_loss,\n","                 test_acc, time.time() - start))"],"metadata":{"id":"8MoklDDiFX0s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5Xu4l1od4y1N"},"source":["## Treinamento do zero\n","\n","Como dito anteriormente, essa foi a única estratégia vista até o momento no curso.\n","Nessa estratégia, uma rede neural é proposta, **inicializada com pesos aleatórios** e treinada até convergir.\n","A **vantagem** dessa estratégia é liberdade para definir como quiser a arquitetura da rede e seus hiper-parâmetros\n","Por outro lado, a **desvantagem** é que essa estratégia requer muitos dados para convergir a rede inicializada aleatoriamente.\n","Logo, se tivermos poucos dados, essa não é a estratégia mais recomendada.\n","Abaixo, uma representação visual dessa estratégia.\n","\n","<p align=\"center\">\n","  <img width=600 src=\"https://drive.google.com/uc?export=view&id=1_bBQjyoDqB3kQMncmVkuJwSxDs3rqUmM\">\n","</p>\n","\n","Apesar de já termos visto essa estratégia na prática, vamos vê-la aqui novamente para efeitos de comparação com as outras técnicas. Para tal, vamos, primeiro, definimos a arquitetura da [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf).\n","\n"]},{"cell_type":"code","metadata":{"id":"lZAEDlZ-DgGd"},"source":["class AlexNet(nn.Module):\n","    def __init__(self, input_channels, classes=10, **kwargs):\n","        super(AlexNet, self).__init__(**kwargs)\n","        self.convs = nn.Sequential(\n","            nn.Conv2d(in_channels=input_channels, out_channels=96, kernel_size=11, stride=4, padding=0),   # entrada: (b, 3, 227, 227) e saida: (b, 96, 55, 55)\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=3, stride=2, padding=0),                                   # entrada: (b, 96, 55, 55) e saida: (b, 96, 27, 27)\n","\n","            nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2),  # entrada: (b, 96, 27, 27) e saida: (b, 256, 27, 27)\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=3, stride=2, padding=0),                                   # entrada: (b, 256, 27, 27) e saida: (b, 256, 13, 13)\n","            nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1), # entrada: (b, 256, 13, 13) e saida: (b, 384, 13, 13)\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1), # entrada: (b, 384, 13, 13) e saida: (b, 384, 13, 13)\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1), # entrada: (b, 384, 13, 13) e saida: (b, 256, 13, 13)\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=3, stride=2, padding=0)                                    # entrada: (b, 256, 13, 13) e saida: (b, 256, 6, 6)\n","        )\n","\n","        self.features = nn.Sequential(\n","            nn.Flatten(),                                                                     # entrada: (b, 256, 13, 13) e saida: (b, 256*6*6) = (b, 9216)\n","            nn.Linear(9216, 4096),                                                             # entrada: (b, 9216) e saida: (b, 4096)\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(4096, 4096),                                                             # entrada: (b, 4096) e saida: (b, 4096)\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(4096, classes)                                                          # entrada: (b, 4096) e saida: (b, 10)\n","        )\n","\n","    def forward(self, x):\n","        x = self.convs(x)\n","        x = self.features(x)\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Wr5rH-KMNZo"},"source":["num_epochs, lr, batch_size, wd_lambda = 20, 0.01, 100, 0.0001\n","\n","net = AlexNet(3, 10)\n","net.to(device)\n","print(summary(net, (batch_size, 3, 227, 227)))\n","\n","loss = nn.CrossEntropyLoss()\n","\n","train_iter, test_iter = load_data_cifar10(batch_size, resize=227)\n","\n","trainer = optim.SGD(net.parameters(), lr=lr, weight_decay=wd_lambda, momentum=0.9)\n","\n","train_validate(net, train_iter, test_iter, batch_size, trainer, loss, num_epochs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RgJwhj2SSGFB"},"source":["É muito comum se usar redes já existentes para aprender características em novos dados.\n","Por isso, muitos frameworks já deixam as arquiteturas mais famosas pré-implementadas para que possam ser usadas.\n","\n","No Pytorch, podemos importar uma rede [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf) usando o pacote [torchvision.models](https://pytorch.org/docs/stable/torchvision/models.html#torchvision-models) do Pytorch.\n","Há várias arquiteturas pré-definidas nessa biblioteca, incluindo várias [DenseNets](https://arxiv.org/pdf/1608.06993.pdf) e [ResNets](https://arxiv.org/abs/1603.05027), [VGGs](https://arxiv.org/abs/1409.1556), [SqueezeNets](https://arxiv.org/abs/1602.07360), etc."]},{"cell_type":"code","metadata":{"id":"f3u7xCEQM0qF"},"source":["num_epochs, lr, batch_size, wd_lambda = 20, 0.01, 100, 0.0001\n","\n","# Rede importada do PyTorch\n","net = torchvision.models.alexnet(num_classes=10)\n","net.to(device)\n","print(summary(net, (batch_size, 3, 227, 227)))\n","\n","loss = nn.CrossEntropyLoss()\n","\n","train_iter, test_iter = load_data_cifar10(batch_size, resize=227)\n","\n","trainer = optim.SGD(net.parameters(), lr=lr, weight_decay=wd_lambda, momentum=0.9)\n","\n","train_validate(net, train_iter, test_iter, batch_size, trainer, loss, num_epochs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0WyR3sukIS9D"},"source":["## Extrator de características\n","\n","A terceira e última estratégia, mostrada na figura abaixo, é usar uma rede neural pré-treinada em algum dataset grande para extrair características de um outro dataset. Essa estratégia é preferível quando o dataset que se quer extrair as *features* tem muito poucas amostras, inviabilizando o treinamento ou *fine-tuning* da rede.\n","\n","<p align=\"center\">\n","  <img width=600 src=\"https://drive.google.com/uc?export=view&id=1pWGfQIAeOODIvm-IQ7De4kl60XpRYbb5\">\n","</p>\n","\n","Existem duas formas de se explorar essa estratégia. A primeira consiste em substituir e treinar somente a última camada da rede neural. Nessa primeira forma, todas as outras camadas da rede ficam com *learning rate* 0, ou seja, não aprendem nada, e são somente usadas como codificadores/extratores de características. A segunda forma, *features* das imagens do dataset que se quer classificar são extraídas da penúltima camada da rede pré-treinada (geralmente, a camada antes da camada de classificação). Essas *features* são então usadas para se treinar um agoritmo externo (como um SVM ou *random forest*), que então classifica o dataset."]},{"cell_type":"code","metadata":{"id":"3VLBe7z2HmNK"},"source":["net = torchvision.models.alexnet(pretrained=True)\n","\n","for param in net.parameters():\n","    param.requires_grad = False\n","\n","print(summary(net, (batch_size, 3, 227, 227)))\n","\n","num_ftrs = net.classifier[6].in_features\n","net.classifier[6] = nn.Linear(num_ftrs,10) # Alterando a última layer para retornar 10 classes ao invés de 1000\n","\n","net.to(device)\n","\n","# Verifique no output a última camada do classifier, podemos ver que sua saída é 10\n","print(net)\n","\n","# Podemos ver que este output mostra que apenas  40970 parâmetros serão treinados. Ou seja, somente a última camada.\n","print(summary(net, (batch_size, 3, 227, 227)))\n","\n","# Código retirado de https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n","\n","# Veja os parâmetros a serem otimizados/atualizados nesta execução.\n","# Se estivermos fazendo finetuning, atualizaremos todos os parâmetros.\n","# No entanto, se estivermos fazendo o método feature extract, atualizaremos apenas os parâmetros que acabamos de inicializar, ou seja, os parâmetros com require_grad como True.\n","print(\"Params to learn: \")\n","\n","params_to_update = []\n","for name,param in net.named_parameters():\n","    if param.requires_grad == True:\n","        params_to_update.append(param)\n","        print(\"\\t\",name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0fk0epQ2PDb0"},"source":["# Treinando a última camada da rede acima\n","num_epochs, lr, batch_size, wd_lambda = 20, 0.001, 100, 0.0001\n","\n","loss = nn.CrossEntropyLoss()\n","\n","train_iter, test_iter = load_data_cifar10(batch_size, resize=227)\n","\n","trainer = optim.SGD(params_to_update, lr=lr, weight_decay=wd_lambda, momentum=0.9)\n","\n","train_validate(net, train_iter, test_iter, batch_size, trainer, loss, num_epochs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ozt5EPQmSsx1"},"source":["num_epochs, lr, batch_size, wd_lambda = 20, 0.01, 100, 0.0001\n","\n","net = torchvision.models.alexnet(pretrained=True)\n","net.to(device)\n","\n","train_iter, test_iter = load_data_cifar10(batch_size, resize=227)\n","\n","# Remover a última camada fully-connected\n","new_classifier = nn.Sequential(*list(net.classifier.children())[:-1])\n","net.classifier = new_classifier\n","\n","print(summary(net, (batch_size, 3, 227, 227)))\n","\n","first = True\n","with torch.no_grad():\n","    for X, y in train_iter:\n","        X, y = X.to(device), y.to(device)\n","        features = net(X)\n","        if first is True:\n","          train_features = features.cpu().numpy()\n","          train_labels = y.cpu().numpy()\n","          first = False\n","        else:\n","          train_features = np.concatenate((train_features, features.cpu().numpy()))\n","          train_labels = np.concatenate((train_labels, y.cpu().numpy()))\n","\n","first = True\n","with torch.no_grad():\n","    for X, y in test_iter:\n","        X, y = X.to(device), y.to(device)\n","        features = net(X)\n","        if first is True:\n","          test_features = features.cpu().numpy()\n","          test_labels = y.cpu().numpy()\n","          first = False\n","        else:\n","          test_features = np.concatenate((test_features, features.cpu().numpy()))\n","          test_labels = np.concatenate((test_labels, y.cpu().numpy()))\n","\n","print(train_features.shape, test_features.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BR7LqiOTY6Tc"},"source":["from sklearn.svm import LinearSVC\n","from sklearn.metrics import accuracy_score\n","\n","clf = LinearSVC()\n","clf.fit(train_features, train_labels)\n","\n","pred = clf.predict(test_features)\n","print(accuracy_score(test_labels, pred))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rsOgJBcofpZN"},"source":["## *Fine-tuning*\n","\n","A segunda estratégia é chamada de *fine-tuning*, e é comumente classificada como um estratégia de *transfer learning*, onde o aprendizado é transferido entre datasets.\n","Especificamente, esta estratégia, representada na figura abaixo, tenta usar um modelo pré-treinado aprendido anteriormente em algum dataset (geralmente muito grande, como o [ImageNet](http://www.image-net.org/)) para classificar outro conjunto de dados diferentes (geralmente com poucas amostras).\n","\n","<p align=\"center\">\n","  <img width=600 src=\"https://drive.google.com/uc?export=view&id=1CoOfpMcQAEl9YAL0lgW11LLYpDcnL4dQ\">\n","</p>\n","\n","Como esses dados podem possuir características diferentes, treinamos a rede usando um *learning rate* pequeno, apenas para fazer pequenos ajustes nos pesos. Entretanto, como esses datasets geralmente tem número e classes diferentes, a última camada não é usada nessa transferência de peso e, geralmente, é inicializada aleatoriamente (e por isso, tem um *learning rate* mais alto que as demais camadas).\n","\n","Por fim, é um [fato conhecido](https://arxiv.org/pdf/1602.01517.pdf) que as redes neurais conseguem aprender características de baixo nível nas camadas iniciais. Geralmente, essas características são comuns à vários datasets. Por isso, uma opção durante o processo de *fine-tuning* é \"congelar\" as camadas iniciais (ou seja, não treiná-las) e treinar somente as demais camadas com taxa de aprendizado bem pequeno (exceto pela camada de classificação).\n","\n","No bloco de código abaixo, importamos a rede pré-treinada [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf), que foi treinada no dataset do [ImageNet](http://www.image-net.org/), que tem 1000 classes. Como iremos fazer *fine-tuning* nessa arquitetura para o dataset do [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html), que tem somente 10 classes, removeremos a última camada e criaremos uma nova camada inicializada aleatoriamente."]},{"cell_type":"code","metadata":{"id":"2hDGgIDhdG2z"},"source":["net = torchvision.models.alexnet(pretrained=True)\n","\n","print(summary(net, (batch_size, 3, 227, 227)))\n","\n","num_ftrs = net.classifier[6].in_features\n","net.classifier[6] = nn.Linear(num_ftrs, 10) # Alterando a última layer para retornar 10 classes ao invés de 1000\n","\n","net.to(device)\n","\n","# Verifique no output a última camada do classifier, podemos ver que sua saída é 10\n","print(net)\n","\n","# Podemos ver que este output mostra que apenas 40970 parâmetros serão treinados. Ou seja, somente a última camada.\n","print(summary(net, (batch_size, 3, 227, 227)))\n","\n","num_epochs, lr, batch_size, wd_lambda = 20, 0.001, 100, 0.0001\n","\n","loss = nn.CrossEntropyLoss()\n","\n","train_iter, test_iter = load_data_cifar10(batch_size, resize=227)\n","\n","trainer = optim.SGD([\n","                {'params': net.features.parameters(), 'lr': lr * 0.1},\n","                {'params': net.classifier[0:6].parameters(), 'lr': lr * 0.1},\n","                {'params': net.classifier[6].parameters(), 'lr': lr}], weight_decay=wd_lambda, momentum=0.9)\n","\n","train_validate(net, train_iter, test_iter, batch_size, trainer, loss, num_epochs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K_uFa_Msi-EP"},"source":["## Atividade\n","\n","1. É possível melhorar o resultado obtido anteriormente?\n","Estude o [model_zoo](https://pytorch.org/vision/stable/models.html)  e tente usar as estratégias anteriores com diferentes redes neurais para melhorar o resultado.\n","Algumas redes possíveis:\n","\n","- [MobileNets](https://arxiv.org/abs/1801.04381)\n","- [VGGs](https://arxiv.org/abs/1409.1556)\n","- [ResNets](https://arxiv.org/abs/1603.05027)\n","- [DenseNets](https://arxiv.org/pdf/1608.06993.pdf)\n","\n","2. Procure agora congelar algumas camadas para realizar o *fine-tuning*. Essa estratégia é melhor quando se tem poucas imagens para fazer o *fine-tuning*.\n","\n","3. Procura usar outros algoritmos de aprendizado de máquina (como [*random forest*](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) e [SVM-RBF](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)) para classificar *deep features* extraídas de uma rede neural pré-treinada.\n","\n","- Procure também extrair e classificar *features* de outras camadas convolucionais.\n","\n","4. Procure usar as diferentes estratégias para melhorar os resultados dos datasets que já usamos, como [MNIST](https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision.datasets.MNIST) e [Fashion MNIST](https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision.datasets.FashionMNIST)."]}]}