{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lista Teórica 04 - Pipeline de Visão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)** Por que é importante identificar e tratar outliers antes de treinar um modelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers podem influenciar negativamente o treinamento, levando o\n",
    "modelo a aprender padrões irrelevantes. Técnicas como remoção, imputação\n",
    "ou transformação podem ser usadas para lidar com eles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)** Em que situações faz sentido converter imagens coloridas para escala de cinza?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando a informação de cor não é relevante para a tarefa, como na\n",
    "análise de imagens médicas, a conversão para escala de cinza pode reduzir a\n",
    "dimensionalidade sem perda significativa de informação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3)** Quais técnicas podem ser utilizadas para remover ruídos de imagens?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtros como média, mediana e Gaussian Blur são amplamente usados para suavizar ruídos, enquanto preservam bordas importantes na imagem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4)** Quando a remoção de fundo de uma imagem é necessária? Como ela pode ser feita?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É útil em tarefas onde o objeto de interesse precisa ser isolado, como em detecção de objetos. Técnicas incluem segmentação automática, máscaras manuais ou modelos baseados em aprendizado profundo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparação do Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5)** Como identificar e corrigir problemas de classes desbalanceadas em um dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A análise da distribuição de classes pode ser feita através de histogramas. Correções incluem oversampling de classes minoritárias, undersampling de classes majoritárias ou atribuição de pesos durante o treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6)** Qual o propósito e benefícios de realizar aumento de dados?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O aumento de dados é uma técnica usada para aumentar artificialmente o tamanho de um conjunto de dados, criando versões modificadas dos dados existentes. Pode melhorar o desempenho dos modelos de aprendizado de máquina, fornecendo exemplos de treinamento adicionais e reduzindo o overfitting. Também pode tornar o modelo mais robusto a mudanças na distribuição dos dados e melhorar sua capacidade de generalização. O aumento de dados também pode ajudar a mitigar os efeitos da disponibilidade limitada de dados e permitir o uso de modelos maiores e mais complexos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7)**  Liste e explique pelo menos três técnicas de data augmentation para imagens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Rotação: altera a orientação da imagem, ajudando a generalizar o modelo.\n",
    "- Flip horizontal/vertical: aumenta a diversidade sem alterar a essência visual.\n",
    "- Alteração de brilho/contraste: simula condições de iluminação variadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8)** Qual a vantagem das CNNs em comparação com técnicas tradicionais de extração de features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As CNNs aprendem automaticamente features relevantes diretamente dos dados, reduzindo a necessidade de engenharia manual e sendo mais adaptáveis a diferentes tarefas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9)** Explique as diferenças entre os conjuntos de treino, validação e teste. Qual a proporção ideal para esses conjuntos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O conjunto de treino é usado para ajustar os pesos do modelo, o de validação para ajustar hiperparâmetros, e o de teste para avaliar a generalização. Proporções comuns são 70%-80% treino, 10%-15% validação e 10%-15% teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modelagem e Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10)** Explique a importância de escolher a learning rate corretamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma learning rate muito alta pode impedir a convergência, enquanto uma muito baixa torna o treinamento lento. Testes com valores escalonados ajudam a encontrar o valor ideal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa: Classificação de Minerais em Imagens Geológicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você recebeu um conjunto de dados geológicos contendo imagens de amostras de rochas. Sua tarefa é propor um pipeline completo de solução para classificar minerais específicos presentes nas amostras, ou seja, atribuir um único rótulo a cada imagem. O pipeline deve considerar **pré-processamento**, **preparação do dataset**, **treinamento de um modelo**, e **avaliação**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pipeline de Solução Detalhado**\n",
    "\n",
    "1. **Pré-processamento**\n",
    "    1. *Entendimento e Preparação Inicial*\n",
    "        1. *Análise do Dataset*:\n",
    "            - Verifique o tamanho do dataset e a resolução das imagens.\n",
    "            - Analise as classes (tipos de minerais) e a quantidade de amostras por classe.\n",
    "        2. *Formato e Anotações*:\n",
    "            - Certifique-se de que as imagens estão em formatos suportados (`.png` ou `.jpg`).\n",
    "            - Verifique se as anotações (rótulos) estão disponíveis em um formato estruturado (como CSV ou JSON).\n",
    "    2. *Normalização das Imagens*:\n",
    "        - Redimensione as imagens para, por exemplo, $ 224 \\times 224 $ pixels (compatível com CNNs pré-treinadas).\n",
    "        - Normalize os valores de pixel para a faixa $ [0, 1] $, reduzindo as chances de vanishing/exploding gradiente, e ajudando na convergência.\n",
    "    3. *Remoção de Ruído*:\n",
    "        - Use filtros Gaussian Blur ou mediana para remover ruídos de fundo sem comprometer as bordas importantes.\n",
    "    4. *Equalização de Histograma*:\n",
    "        - Aplique equalização para melhorar o contraste das imagens, caso haja variação significativa na iluminação.\n",
    "    5. *Rotulagem Consistente*:\n",
    "        - Padronize os rótulos para evitar inconsistências (e.g., \"Quartz\" vs. \"quartz\").\n",
    "2. **Preparação do Dataset**\n",
    "    1. *Divisão do Dataset*:\n",
    "        - Separe o dataset em 70% para treino, 15% para validação e 15% para teste.\n",
    "        - Certifique-se de que a divisão seja estratificada, preservando a proporção das classes em cada conjunto.\n",
    "    2. *Análise de Balanceamento*:\n",
    "        - Verifique a distribuição de imagens por classe.\n",
    "    3. *Correção de Desequilíbrio*:\n",
    "        - Use oversampling nas classes minoritárias com técnicas de data augmentation (explicadas abaixo).\n",
    "    4. *Data Augmentation*\n",
    "        1. *Aumentar a Diversidade dos Dados*:\n",
    "            - Rotação aleatória (até 30°).\n",
    "            - Flips horizontais e verticais.\n",
    "            - Alteração de brilho (±20%).\n",
    "            - Crop aleatório para simular diferentes ângulos de visão.\n",
    "            - Adição de ruído simulado para testar robustez.\n",
    "        2. *Validação das Transformações*:\n",
    "            - Visualize as imagens geradas para garantir que as transformações são realistas.\n",
    "3. **Treinamento do Modelo**\n",
    "    1. *Escolha da Arquitetura*:\n",
    "        - Use uma arquitetura pré-treinada, como ResNet50, para transfer learning.\n",
    "        - Congele as primeiras camadas e ajuste as camadas finais para a quantidade de classes.\n",
    "    2. *Função de Perda* e Otimização:\n",
    "        - Escolha cross-entropy como função de perda.\n",
    "        - Use Adam ou SGD com uma learning rate inicial de 0.001.\n",
    "    2. *Configuração do Treinamento*:\n",
    "        - Configure o treinamento para 50 épocas com early stopping baseado na métrica de validação.\n",
    "        - Use batches de tamanho 32.\n",
    "4. **Avaliação**\n",
    "    1. *Métricas Primárias*:\n",
    "        - Acurácia, precisão, recall e F1-score por classe.\n",
    "    2. *Métricas Secundárias*:\n",
    "        - Matriz de confusão para identificar padrões de erro.\n",
    "        - Análise de curvas ROC por classe (se houver muitas classes, escolha as mais relevantes).\n",
    "    3. *Validação Cruzada*:\n",
    "        - Realize validação cruzada k-fold para avaliar a robustez do modelo.\n",
    "    4. *Interpretação e Melhorias*\n",
    "        1. *Análise de Erros*:\n",
    "            - Inspecione exemplos mal classificados para entender possíveis falhas.\n",
    "        2. *Explicabilidade do Modelo*:\n",
    "            - Use técnicas como [Grad-CAM](https://arxiv.org/abs/1610.02391) para visualizar as regiões de interesse do modelo em cada imagem.\n",
    "        3. *Iteração*:\n",
    "            - Ajuste hiperparâmetros ou refine o dataset com base na análise de erros."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
