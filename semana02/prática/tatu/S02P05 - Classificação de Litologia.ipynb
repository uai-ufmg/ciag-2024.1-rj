{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29d41f7f-7e3f-44dd-80cc-03109c533a6b",
   "metadata": {},
   "source": [
    "## Colocando os Conhecimentos em Prática"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45ef919-e381-48dc-bbb7-3d341a9cae2d",
   "metadata": {},
   "source": [
    "Na aula de hoje, nós revisitaremos a tarefa de classificação de litologia no dataset FORCE utilizando as técnicas aprendidas ao longo da semana.\n",
    "\n",
    "A partir do que aprendemos na última semana, sabemos que temos três grandes problemas que precisamos abordar a fim de melhorar os resultados de nossa classificação:\n",
    "\n",
    "- A rede deve ter uma capacidade maior em comparação com a usada na semana 01;\n",
    "- Devemos tratar do grande desbalanceamento das classes em nossos dados, que fez com que nossa rede inicial prevesse majoritariamente algumas poucas classes.\n",
    "- Devemos implementar pensar em maneiras de diminuir um possível overfitting, principalmente ao aumentarmos a capacidade de nosso modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfb2649-70a3-4388-a44d-f6e33454a6be",
   "metadata": {},
   "source": [
    "Agora é com você! Construa um Multi Layer Perceptron, usando pytorch, para mapear cada ponto do poço para a litologia correta.\n",
    "\n",
    "> Dica: Considere fazer suas predições em uma janela deslizante.\n",
    "\n",
    "Abaixo está um passo a passo do que deve ser feito.\n",
    "\n",
    "1. Leia os dados baixados e extraídos\n",
    "> Dica: use a biblioteca pandas. Exemplo: pd.read_csv(\"train.csv\", sep=';')\n",
    "2. Divida os poços em janelas da profundidade que quiser.\n",
    "3. Construa sua base de treino e teste, bem como o dataloder para elas.\n",
    "4. Construa seu MLP usando pytorch.\n",
    "5. Treine o modelo.\n",
    "6. Extraia as previsões em seu dado de teste para cada janela, em junte-as para formar a segmentação completa do poço.\n",
    "7. Meça a qualidade de seu algoritmo com métricas a sua escolha.\n",
    "8. Teste diferentes otimizadores, técnicas de regularização.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "771ac3cc-fd38-4ff2-b177-134dedd41e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from torchmetrics.functional import accuracy\n",
    "from collections import Counter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a468aeb0-c1f9-49ff-a7bc-d14c62a36f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo os dados\n",
    "\n",
    "data_dir = '/pgeoprj2/ciag2024/dados/FORCE'\n",
    "\n",
    "df_train = pd.read_csv(f\"{data_dir}/train.csv\", sep=';')\n",
    "df_test = pd.read_csv(f\"{data_dir}/leaderboard_test_features.csv\", sep=';')\n",
    "df_test_target = pd.read_csv(f\"{data_dir}/leaderboard_test_target.csv\", sep=';')\n",
    "df_test = pd.merge(df_test, df_test_target, on=[\"WELL\", \"DEPTH_MD\"], how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7d8a591-4276-4980-b728-185ba7f3d0a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WELL</th>\n",
       "      <th>DEPTH_MD</th>\n",
       "      <th>X_LOC</th>\n",
       "      <th>Y_LOC</th>\n",
       "      <th>Z_LOC</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>FORMATION</th>\n",
       "      <th>CALI</th>\n",
       "      <th>RSHA</th>\n",
       "      <th>RMED</th>\n",
       "      <th>...</th>\n",
       "      <th>ROP</th>\n",
       "      <th>DTS</th>\n",
       "      <th>DCAL</th>\n",
       "      <th>DRHO</th>\n",
       "      <th>MUDWEIGHT</th>\n",
       "      <th>RMIC</th>\n",
       "      <th>ROPA</th>\n",
       "      <th>RXO</th>\n",
       "      <th>FORCE_2020_LITHOFACIES_LITHOLOGY</th>\n",
       "      <th>FORCE_2020_LITHOFACIES_CONFIDENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15/9-13</td>\n",
       "      <td>494.528</td>\n",
       "      <td>437641.96875</td>\n",
       "      <td>6470972.5</td>\n",
       "      <td>-469.501831</td>\n",
       "      <td>NORDLAND GP.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.480835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.611410</td>\n",
       "      <td>...</td>\n",
       "      <td>34.636410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.574928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15/9-13</td>\n",
       "      <td>494.680</td>\n",
       "      <td>437641.96875</td>\n",
       "      <td>6470972.5</td>\n",
       "      <td>-469.653809</td>\n",
       "      <td>NORDLAND GP.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.468800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.618070</td>\n",
       "      <td>...</td>\n",
       "      <td>34.636410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.570188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15/9-13</td>\n",
       "      <td>494.832</td>\n",
       "      <td>437641.96875</td>\n",
       "      <td>6470972.5</td>\n",
       "      <td>-469.805786</td>\n",
       "      <td>NORDLAND GP.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.468800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.626459</td>\n",
       "      <td>...</td>\n",
       "      <td>34.779556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.574245</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15/9-13</td>\n",
       "      <td>494.984</td>\n",
       "      <td>437641.96875</td>\n",
       "      <td>6470972.5</td>\n",
       "      <td>-469.957794</td>\n",
       "      <td>NORDLAND GP.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.459282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.621594</td>\n",
       "      <td>...</td>\n",
       "      <td>39.965164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.586315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15/9-13</td>\n",
       "      <td>495.136</td>\n",
       "      <td>437641.96875</td>\n",
       "      <td>6470972.5</td>\n",
       "      <td>-470.109772</td>\n",
       "      <td>NORDLAND GP.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.453100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.602679</td>\n",
       "      <td>...</td>\n",
       "      <td>57.483765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.597914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      WELL  DEPTH_MD         X_LOC      Y_LOC       Z_LOC         GROUP  \\\n",
       "0  15/9-13   494.528  437641.96875  6470972.5 -469.501831  NORDLAND GP.   \n",
       "1  15/9-13   494.680  437641.96875  6470972.5 -469.653809  NORDLAND GP.   \n",
       "2  15/9-13   494.832  437641.96875  6470972.5 -469.805786  NORDLAND GP.   \n",
       "3  15/9-13   494.984  437641.96875  6470972.5 -469.957794  NORDLAND GP.   \n",
       "4  15/9-13   495.136  437641.96875  6470972.5 -470.109772  NORDLAND GP.   \n",
       "\n",
       "  FORMATION       CALI  RSHA      RMED  ...        ROP  DTS  DCAL      DRHO  \\\n",
       "0       NaN  19.480835   NaN  1.611410  ...  34.636410  NaN   NaN -0.574928   \n",
       "1       NaN  19.468800   NaN  1.618070  ...  34.636410  NaN   NaN -0.570188   \n",
       "2       NaN  19.468800   NaN  1.626459  ...  34.779556  NaN   NaN -0.574245   \n",
       "3       NaN  19.459282   NaN  1.621594  ...  39.965164  NaN   NaN -0.586315   \n",
       "4       NaN  19.453100   NaN  1.602679  ...  57.483765  NaN   NaN -0.597914   \n",
       "\n",
       "   MUDWEIGHT  RMIC  ROPA  RXO  FORCE_2020_LITHOFACIES_LITHOLOGY  \\\n",
       "0        NaN   NaN   NaN  NaN                             65000   \n",
       "1        NaN   NaN   NaN  NaN                             65000   \n",
       "2        NaN   NaN   NaN  NaN                             65000   \n",
       "3        NaN   NaN   NaN  NaN                             65000   \n",
       "4        NaN   NaN   NaN  NaN                             65000   \n",
       "\n",
       "   FORCE_2020_LITHOFACIES_CONFIDENCE  \n",
       "0                                1.0  \n",
       "1                                1.0  \n",
       "2                                1.0  \n",
       "3                                1.0  \n",
       "4                                1.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17fb5d95-7190-421c-94fc-f80a7d8e6684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nomes das litologias\n",
    "lithology_keys = {\n",
    "    30000: 'Sandstone',\n",
    "    65030: 'Sandstone/Shale',\n",
    "    65000: 'Shale',\n",
    "    80000: 'Marl',\n",
    "    74000: 'Dolomite',\n",
    "    70000: 'Limestone',\n",
    "    70032: 'Chalk',\n",
    "    88000: 'Halite',\n",
    "    86000: 'Anhydrite',\n",
    "    99000: 'Tuff',\n",
    "    90000: 'Coal',\n",
    "    93000: 'Basement'\n",
    "}\n",
    "\n",
    "target_col = \"FORCE_2020_LITHOFACIES_LITHOLOGY\"\n",
    "feature_cols = [\"GR\", \"RHOB\", \"NPHI\", \"PEF\", \"DTC\", \"RDEP\", \"RSHA\", \"RMED\"] # Escolha as features que quiser\n",
    "\n",
    "# Removendo valores faltantes\n",
    "df_train = df_train.dropna(subset=feature_cols+[target_col]).reset_index(drop=True)\n",
    "df_test = df_test.dropna(subset=feature_cols+[target_col]).reset_index(drop=True)\n",
    "\n",
    "# Codificando as labels para que as possamos passar para o modelo\n",
    "le = LabelEncoder()\n",
    "all_possible_classes = list(lithology_keys.keys())\n",
    "le.fit(all_possible_classes)\n",
    "df_train[target_col] = le.transform(df_train[target_col])\n",
    "df_test[target_col] = le.transform(df_test[target_col])\n",
    "\n",
    "# Normalizando as featues\n",
    "scaler = StandardScaler()\n",
    "df_train[feature_cols] = scaler.fit_transform(df_train[feature_cols])\n",
    "df_test[feature_cols] = scaler.transform(df_test[feature_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff49a363-3aba-43e5-8e2a-eda6cd7a8eb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['15/9-13' '15/9-15' '15/9-17' '16/10-3' '16/10-5' '16/4-1' '16/7-5'\n",
      " '25/11-19 S' '25/2-13 T4' '25/2-14' '25/2-7' '25/3-1' '25/4-5' '25/5-1'\n",
      " '25/5-4' '25/8-5 S' '25/8-7' '25/9-1' '26/4-1' '29/6-1' '30/6-5'\n",
      " '31/2-19 S' '31/2-7' '31/2-8' '31/2-9' '31/3-2' '31/3-4' '31/4-5'\n",
      " '32/2-1' '33/9-17' '34/10-21' '34/10-35' '34/11-2 S' '34/12-1' '34/2-4'\n",
      " '34/7-21' '34/8-1' '35/11-1' '35/11-6' '35/11-7' '35/12-1' '35/8-4'\n",
      " '7/1-2 S']\n"
     ]
    }
   ],
   "source": [
    "# Aqui estamos listando todos os poços presentes no dataset de treino\n",
    "wells = df_train[\"WELL\"].unique()\n",
    "print(wells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18a72c25-3e2f-4df4-a008-b89dae746e02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WELL\n",
       "33/9-17       17337\n",
       "31/2-19 S     16308\n",
       "34/10-21      13945\n",
       "15/9-15       13290\n",
       "15/9-17       12873\n",
       "26/4-1        12824\n",
       "25/2-7        12043\n",
       "16/7-5        10266\n",
       "34/12-1        9109\n",
       "35/11-6        8378\n",
       "34/7-21        7576\n",
       "25/8-5 S       7455\n",
       "35/11-7        7227\n",
       "35/12-1        7073\n",
       "25/11-19 S     6908\n",
       "31/2-8         6582\n",
       "35/11-1        6195\n",
       "25/3-1         6010\n",
       "31/3-4         5223\n",
       "34/11-2 S      5073\n",
       "16/10-3        4578\n",
       "25/2-14        3845\n",
       "34/8-1         3735\n",
       "25/9-1         3596\n",
       "34/2-4         3588\n",
       "29/6-1         3409\n",
       "25/5-1         2954\n",
       "32/2-1         2789\n",
       "30/6-5         2572\n",
       "16/10-5        2498\n",
       "25/8-7         2452\n",
       "35/8-4         2263\n",
       "31/4-5         2046\n",
       "25/4-5         1891\n",
       "31/2-9         1787\n",
       "15/9-13        1623\n",
       "25/2-13 T4     1574\n",
       "7/1-2 S        1530\n",
       "25/5-4         1328\n",
       "34/10-35       1066\n",
       "31/2-7         1008\n",
       "31/3-2          620\n",
       "16/4-1          615\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"WELL\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e24bce9f-f313-4602-aa03-a252bbeb6920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (244632, 10, 8) || X_test shape: (26583, 10, 8)\n",
      "y_train shape: (244632,) || y_test shape: (26583,)\n"
     ]
    }
   ],
   "source": [
    "# Criando janelas nos dados\n",
    "# Optimized function for creating windows\n",
    "def create_windows(data, features, target, window_size=10):\n",
    "    X = np.lib.stride_tricks.sliding_window_view(data[features].values, (window_size, len(features)))[:-1, :, :]\n",
    "    Y = data[target].iloc[window_size:].values\n",
    "    return X.squeeze(), Y\n",
    "\n",
    "window_size = 10 # Escolha o tamanho de janela que quiser\n",
    "X_train = []\n",
    "y_train = []\n",
    "for well in wells:\n",
    "    well_data = df_train[df_train['WELL'] == well]\n",
    "       \n",
    "    x_well, y_well = create_windows(well_data, feature_cols, target_col, window_size=window_size)\n",
    "    X_train.append(x_well)\n",
    "    y_train.append(y_well)\n",
    "\n",
    "X_train = np.concatenate(X_train, axis=0)\n",
    "y_train = np.concatenate(y_train, axis=0)\n",
    "X_test, y_test = create_windows(df_test, feature_cols, target_col, window_size=window_size)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape} || X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape} || y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ed546ab4-03a5-4a4a-ac9e-960d628ba57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o dataset que utilizaremos\n",
    "class WellDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.Y = torch.tensor(Y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "\n",
    "# definindo os datasets\n",
    "train_dataset = WellDataset(X_train, y_train)\n",
    "test_dataset = WellDataset(X_test, y_test)\n",
    "\n",
    "# definindo os dataloaders\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9248e007-3019-4ad4-89d8-eea98f6c2736",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
