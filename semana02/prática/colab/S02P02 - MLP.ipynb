{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NG-mVsVuE0if"
      },
      "source": [
        "# Preâmbulo\n",
        "\n",
        "Imports, funções, downloads e instalação do Pytorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEHmMCjR4PJw"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils import data\n",
        "from torch.backends import cudnn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision import models\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "from skimage import io\n",
        "from sklearn import metrics\n",
        "\n",
        "%matplotlib inline\n",
        "cudnn.benchmark = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQa4-lUw7Rmp"
      },
      "source": [
        "## Casting para o dispositivo correto\n",
        "\n",
        "Como usaremos processamento vetorial principalmente em GPUs para aprendizado profundo, primeiramente é possível verificar se há uma GPU disponível com o trecho de código abaixo, armazenando os tensores nos dispositivos apropriados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX0bBEM863sY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c412711f-d872-46a3-cc1e-4c287cdd608e"
      },
      "source": [
        "# Verificando se temos GPU/CUDA\n",
        "has_cuda = torch.cuda.is_available()\n",
        "device = torch.device('cuda' if has_cuda else 'cpu')\n",
        "\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x5UK0uib2tk"
      },
      "source": [
        "# Intro MLP\n",
        "\n",
        "## Neurônios e a camada `nn.Linear`\n",
        "\n",
        "A camada Linear do Pytorch ([nn.Linear](https://pytorch.org/docs/stable/nn.html#torch.nn.Linear)) é responsável por aplicar uma transformação linear no dado de entrada. Esta camada recebe como parâmetro a dimensão (número de *features*) da entrada e da saída (que na verdade, representa o número de neurônios dessa camada). Por padrão o bias já é incluído. **Um** perceptron pode ser facilmente representado como a seguir, desconsiderando a função de ativação:\n",
        "\n",
        "```\n",
        "linear = nn.Linear(in_dimension, 1)\n",
        "```\n",
        "Mas de uma forma geral, uma camada Linear com diversas *features* de entrada e diversas *features* de saída pode ser representada como:\n",
        "```\n",
        "nn.Linear(in_features, out_features)\n",
        "```\n",
        "![](./figs/nn_linear.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlQA_vtGg8bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "017bb413-f43e-4bb2-987b-5c52a7897f7d"
      },
      "source": [
        "linear = nn.Linear(2, 1)\n",
        "print(linear)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear(in_features=2, out_features=1, bias=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AhNyLrLmFcT"
      },
      "source": [
        "Como é possível ver no código abaixo, o Pytorch já inicia os pesos da camada aleatoriamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLOlOhQVmPuj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c7a022a-40ba-41f5-c997-ae53c13f834d"
      },
      "source": [
        "for name, param in linear.named_parameters():\n",
        "    print(f'Parameter {name}:')\n",
        "    print(f'  - {param.data}\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter weight:\n",
            "  - tensor([[0.1760, 0.6900]])\n",
            "\n",
            "Parameter bias:\n",
            "  - tensor([0.2902])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAEaJGtDoZD7"
      },
      "source": [
        "O **forward** consiste em passar seu dado de entrada pela rede, gerando um resultado ao final. Considerando a camada linear instanciada anteriormente, o resultado do forward é o mesmo do somatório da multiplicação de seus pesos pelas respectivas entradas juntamente com o bias, ou seja:\n",
        "\n",
        "$$f_w(x) = w_0 + w_1x_1 + w_2x_2 + \\ldots + w_nx_n$$\n",
        "\n",
        "No Pytorch, realizamos o **forward** chamando o objeto onde nossa rede/modelo está instanciada, conforme exemplo abaixo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ibb8t7zpmpUI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "628d3658-699d-464a-f0f6-7f7f9fd79300"
      },
      "source": [
        "linear = nn.Linear(2, 1)\n",
        "X = torch.tensor([2.0, 3.0])\n",
        "\n",
        "print('Using Linear:', linear(X))\n",
        "print('Manual:', torch.sum(X * linear.weight) + linear.bias)  # .weight e .bias permite acessarmos os pesos e bias deste modelo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Linear: tensor([0.9591], grad_fn=<ViewBackward0>)\n",
            "Manual: tensor([0.9591], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ativacao = nn.ReLU()\n",
        "softmax = nn.Softmax()\n",
        "camada1 = nn.Linear(2, 4)\n",
        "camada2 = nn.Linear(4, 5)\n",
        "\n",
        "output = softmax(camada2(ativacao(camada1(X))))\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95aU8dRH5Ncx",
        "outputId": "43cef5d2-c97f-4b93-d9b4-d0fe6aa8b790"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1807, 0.2433, 0.1888, 0.1602, 0.2269], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ao fazermos linear(X), estamos fazendo implicitamente uma chamada na função forward da Linear\n",
        "print('Forward com chamada implícita:', linear(X))\n",
        "print('Forward com chamada explícita:', linear.forward(X))"
      ],
      "metadata": {
        "id": "zwjZ4t_MIz58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a953d2ef-7d99-4014-ffb0-1593a17b2b2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forward com chamada implícita: tensor([1.3874], grad_fn=<ViewBackward0>)\n",
            "Forward com chamada explícita: tensor([1.3874], grad_fn=<ViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8LMX6OMrEbw"
      },
      "source": [
        "## Exemplo de uma rede neural simples (1 camada)\n",
        "\n",
        "O código abaixo cria uma rede neural simples usando `nn.Linear` e implementa o fluxo de treinamento para essa rede, ou seja, faz o forward, calcula a loss, e otimiza seus pesos. Invista um pouco de tempo para entender a célula abaixo pois usaremos essa ideia para implementar a função de treino mais a frente."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iremos criar dados que seguem a função y = 2x + 3\n",
        "dataset = []\n",
        "for x in range(10):\n",
        "    dataset.append((x, 2*x + 3))  # tupla com (x, y)"
      ],
      "metadata": {
        "id": "_uGksRlgJYNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "Q2MwrrGAmFMZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fd5fc45-1855-441e-bcc0-c718bed05e05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 3),\n",
              " (1, 5),\n",
              " (2, 7),\n",
              " (3, 9),\n",
              " (4, 11),\n",
              " (5, 13),\n",
              " (6, 15),\n",
              " (7, 17),\n",
              " (8, 19),\n",
              " (9, 21)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definiremos uma loss (erro quadrático -> (y - y_hat)^2)\n",
        "def loss_fn(predict, label):\n",
        "    return torch.pow(label - predict, 2)"
      ],
      "metadata": {
        "id": "UHRwAuyFJvUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPJ9s5ckoA5T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88282976-b627-405d-d2e1-be9a9015edfe"
      },
      "source": [
        "linear = nn.Linear(1, 1)  # camada linear com 1 feature de entrada (mais o bias) e uma de saída\n",
        "linear.to(device)  # casting do linear para GPU\n",
        "\n",
        "learning_rate = 0.01\n",
        "print(f'Parâmetros iniciais: {list(linear.parameters())}\\n')\n",
        "\n",
        "for epoch in range(100):\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for X, y in dataset:\n",
        "        # Fazendo o casting dos dados para tensores na GPU\n",
        "        X = torch.FloatTensor([X]).to(device)\n",
        "        y = torch.FloatTensor([y]).to(device)\n",
        "\n",
        "        y_pred = linear(X)  # etapa de forward\n",
        "        loss = loss_fn(y_pred, y)  # calcula a loss\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        # Etapa de backprop\n",
        "        loss.backward()\n",
        "        with torch.no_grad(): # não queremos fazer com que o pytorch anote as operações do backprop\n",
        "            for param in linear.parameters():\n",
        "                param -= learning_rate * param.grad  # atualização dos parametros (pesos e bias) com base no gradiente\n",
        "\n",
        "        for param in linear.parameters():\n",
        "            param.grad.zero_()  # resetando o gradiente\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(\"Epoch {} - loss: {}\".format(epoch + 1, epoch_loss))\n",
        "\n",
        "print('\\nParâmetros finais: ', list(linear.parameters()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parâmetros iniciais: [Parameter containing:\n",
            "tensor([[-0.7914]], requires_grad=True), Parameter containing:\n",
            "tensor([0.2735], requires_grad=True)]\n",
            "\n",
            "Epoch 10 - loss: 3.7114275442436337\n",
            "Epoch 20 - loss: 1.2826352751580998\n",
            "Epoch 30 - loss: 0.44326957751763985\n",
            "Epoch 40 - loss: 0.15318967687198892\n",
            "Epoch 50 - loss: 0.052940971800126135\n",
            "Epoch 60 - loss: 0.018295912032044725\n",
            "Epoch 70 - loss: 0.006322939228994073\n",
            "Epoch 80 - loss: 0.0021852371537534054\n",
            "Epoch 90 - loss: 0.0007552007464255439\n",
            "Epoch 100 - loss: 0.0002610057017591316\n",
            "\n",
            "Parâmetros finais:  [Parameter containing:\n",
            "tensor([[2.0010]], requires_grad=True), Parameter containing:\n",
            "tensor([2.9907], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9uRk8mAwGIB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd746c84-98d5-435f-f410-0b03bb68e6ca"
      },
      "source": [
        "X = torch.FloatTensor([20]).to(device)\n",
        "print(linear(X))  # forward do valor 20 para conferir resultado, saida deve ser aproximadamente = 2x+3 = 2*20+3 = 43"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([43.0090], grad_fn=<ViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f-q6bCNzEmx"
      },
      "source": [
        "## O módulo `nn.Sequential`\n",
        "\n",
        "Na prática, criaremos redes com diversas camadas. O bloco `nn.Sequential` permite agrupar as camadas de forma sequencial para que o forward seja realizado na ordem desejada. Veja um exemplo para um *Multilayer Perceptron (MLP)* abaixo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCK_OkqCzdUW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb2d6f30-944e-474a-9684-910328842199"
      },
      "source": [
        "MLP = nn.Sequential(\n",
        "    nn.Linear(10, 12),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(12, 24),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(24, 2)\n",
        ")\n",
        "\n",
        "MLP = MLP.to(device)\n",
        "print(MLP)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=10, out_features=12, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=12, out_features=24, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=24, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkhjCepK0kjJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d31c600-be4d-4e81-fdfb-4579ad6f9720"
      },
      "source": [
        "test_data = torch.randn((10, 10)).to(device)  # 10 dados de input aleatórios com 10 features\n",
        "\n",
        "output = MLP(test_data)  # forward da rede\n",
        "print(output.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfb4zBjO0Lua"
      },
      "source": [
        "Informação sobre outras camadas lineares, como nn.Bilinear e nn.Identity, podem ser vistas na documentação: https://pytorch.org/docs/stable/nn.html#linear-layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9LoXL0cUYMT"
      },
      "source": [
        "## Conjunto de Exercícios 1 - Implementação de uma MLP\n",
        "\n",
        "Vamos agora treinar um MLP simples no dataset de [Breast Cancer da UCI](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)). A célula abaixo irá carregar os dados utilizando a biblioteca scikit-learn, que já possui o dataset pronto para utilizarmos.\n",
        "\n",
        "- Neste exercício, não estamos interessados em trabalhar com dados de treino/teste, mas sim apenas estudar como definir uma rede neural de múltiplas camadas em PyTorch e realizar o treinamento dos seus pesos e viéses."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi3Zh8fQ4X_3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7dd00b1-37ba-45b8-95ac-fe5f098e5c86"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "\n",
        "print('Tamanho de X:', X.shape)\n",
        "print('Dataype de X:', type(X), X.dtype)\n",
        "\n",
        "print('\\nTamanho de y:', y.shape)\n",
        "print('Dataype de y:', type(y), y.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho de X: (569, 30)\n",
            "Dataype de X: <class 'numpy.ndarray'> float64\n",
            "\n",
            "Tamanho de y: (569,)\n",
            "Dataype de y: <class 'numpy.ndarray'> int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertendo os dados para tensores PyTorch e fazendo o casting para o dispositivo apropriado\n",
        "X = torch.FloatTensor(X).to(device)\n",
        "y = torch.FloatTensor(y).to(device)\n",
        "\n",
        "# Modificando o shape das anotações para ser um vetor (n, 1) para não gerar erros no cálculo da função de perda\n",
        "# Isso é necessário pois os produtos internos feitos no PyTorch irá resultar em uma matriz (n, 1), ou seja, n-linhas\n",
        "# onde cada linha terá um valor binário (classe daquela observação)\n",
        "y = y.unsqueeze(dim=-1)  # dim=-1 representa a última dimensão do nosso vetor\n",
        "\n",
        "# Exibindo o tamanho dos tensores\n",
        "print('Tamanho de X:', X.shape)\n",
        "print('Dataype de X:', type(X), X.dtype)\n",
        "\n",
        "print('\\nTamanho de y:', y.shape)\n",
        "print('Dataype de y:', type(y), y.dtype)"
      ],
      "metadata": {
        "id": "msF6TmtsnXr8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc59f1d7-c434-46e9-b028-294af1ab9925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho de X: torch.Size([569, 30])\n",
            "Dataype de X: <class 'torch.Tensor'> torch.float32\n",
            "\n",
            "Tamanho de y: torch.Size([569, 1])\n",
            "Dataype de y: <class 'torch.Tensor'> torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Labels dos dados:', torch.unique(y))"
      ],
      "metadata": {
        "id": "EjahTNqATUvu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db8b78af-65c6-4938-8420-b0a2efc08683"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels dos dados: tensor([0., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.Tensor([1,2,3])\n",
        "t = t.reshape((1,3))\n",
        "t.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eewb-I6MfudR",
        "outputId": "ec18344e-0446-44d7-cfcf-a8ce7c12879e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MOWmBPef233",
        "outputId": "cfa30b3d-4408-4479-c384-ccdffd8c869a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMDN1viW-0Eg"
      },
      "source": [
        "1. Implemente na célula abaixo uma MLP, de nome **model**, utilizando o módulo `nn.Sequential`. A sua rede MLP deve possuir, pelo menos, uma camada oculta, usando uma ReLU como função de ativação entre as camadas.\n",
        "\n",
        "    - Note que o nosso problema é um problema de classificação binária. Iremos utilizar uma função de perda do PyTorch que recebe como entrada a saída \"crua\" (*logits*) da sua rede neural. Sendo assim, não se preocupe em aplicar alguma transformação na saída (como uma sigmóide) para converter os valores para uma probabilidade, por exemplo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYO7HWC29Ahy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c97b82e-cd2c-4771-c023-13965e8d9807"
      },
      "source": [
        "in_features = 30\n",
        "out_features = 1\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(in_features, 64), nn.ELU(),\n",
        "    nn.Linear(64, 32), nn.ELU(),\n",
        "    nn.Linear(32, 16), nn.ELU(),\n",
        "    nn.Linear(16, out_features)\n",
        ")\n",
        "\n",
        "model.to(device)  # sempre é necessario fazer o casting da rede para jogá-la para GPU\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=30, out_features=64, bias=True)\n",
            "  (1): ELU(alpha=1.0)\n",
            "  (2): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (3): ELU(alpha=1.0)\n",
            "  (4): Linear(in_features=32, out_features=16, bias=True)\n",
            "  (5): ELU(alpha=1.0)\n",
            "  (6): Linear(in_features=16, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_random = torch.randn(569, 30)\n",
        "model(x_random).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "006xHwaBnAbx",
        "outputId": "2f36c5ae-1298-4433-ee6d-b8186e558f7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([569, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWrn_MUHBz7o"
      },
      "source": [
        "Abaixo, definimos uma loss e um otimizador usando o PyTorch. Não se preocupem como isso funciona agora, pois iremos ver em detalhes como definir e usar diferentes losses e otimizadores com o PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iremos utilizar a entropia cruzada binária como função de perda para o nosso problema\n",
        "# Essa versão da BCE aceita como entrada a saída \"crua\" (logits) da sua rede neural.\n",
        "# Outras versões, como a BCELoss aceita como entrada uma saída probabilística da sua rede neural (sigmoid ou softmax),\n",
        "# sendo assim você deve colocar uma função de ativação depois do último nn.Linear do seu modelo.\n",
        "# A versão BCEWithLogitsLoss implementa uma versão mais numericamente estável da loss, podemos observar isso na própria\n",
        "# documentação do PyTorch: https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html?highlight=bcewithlogitsloss#torch.nn.BCEWithLogitsLoss\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "# criterion = nn.BCELoss()\n",
        "\n",
        "# Se quiser usar sigmoid no final da rede, troque por criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "IgEeodMiSmuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oa5DcYBf82iD"
      },
      "source": [
        "# Iremos utilizar o pacote optim para definir um otimizador que irá atualizar os pesos do modelo para nós.\n",
        "# Aqui, utilizaremos SGD - Gradiente Descendente Estocástico.\n",
        "# O pacote optim contém muitos outros algoritmos de otimização, porém, em todos o primeiro parâmetro irá dizer para os\n",
        "# otimizadores quais tensores (com requires_grad=True) do nosso modelo ele deverá otimizar.\n",
        "import torch.optim as optim\n",
        "\n",
        "learning_rate = 1e-4\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPQtOnNr-kAG"
      },
      "source": [
        "Abaixo teremos um loop de treinamento típico de PyTorch. Não precisa modificar em nada essa funçao, porém estude ela mesmo assim, já que usaremos esse fluxo como template para treinamento de outros modelos mais a frente no curso."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsMFRIDv80I3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "797f3847-bb8b-4b30-e909-dd8457957f71"
      },
      "source": [
        "# Aqui iremos criar uma lista de loss para cada época\n",
        "loss_list = []\n",
        "\n",
        "# Iterando sobre as épocas\n",
        "n_epochs = 500\n",
        "for epoch in range(n_epochs):\n",
        "    preds = model(X)\n",
        "    loss = criterion(preds, y)\n",
        "\n",
        "    # Salvando a loss da iteração atual (para plots futuros)\n",
        "    loss_list.append(loss.item())\n",
        "\n",
        "    # Antes de fazermos o backward pass, iremos zerar o gradiente de todos os tensores\n",
        "    # atrelados ao otimizador utilizando a chamada de função .zero_grad() do nosso otimizador.\n",
        "    # Faremos isso pois os gradientes são acumulados, sempre que chamamos .backward(), em buffers nos\n",
        "    # tensores que representam os pesos dos nossos modelos, ou seja, não são sobrescritos.\n",
        "    # Para mais detalhes, você pode dar uma olhada na documentação do torch.autograd.backward\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Realizando o backward pass, ou seja, computando os gradientes da nossa função de perda\n",
        "    # com respeito aos parâmetros (pesos) do nosso modelo\n",
        "    loss.backward()\n",
        "\n",
        "    # Chamando a função .step() do nosso otimizador para realizar um \"passo\" na otimização.\n",
        "    # Nesse caso, o \"passo\" será realizar o cálculo que vimos do gradiente descendente\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch {epoch + 1}: loss = {loss.item():.5f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: loss = 0.58007\n",
            "Epoch 20: loss = 0.53016\n",
            "Epoch 30: loss = 0.49990\n",
            "Epoch 40: loss = 0.47882\n",
            "Epoch 50: loss = 0.46258\n",
            "Epoch 60: loss = 0.45017\n",
            "Epoch 70: loss = 0.44060\n",
            "Epoch 80: loss = 0.43289\n",
            "Epoch 90: loss = 0.42641\n",
            "Epoch 100: loss = 0.42080\n",
            "Epoch 110: loss = 0.41578\n",
            "Epoch 120: loss = 0.41121\n",
            "Epoch 130: loss = 0.40697\n",
            "Epoch 140: loss = 0.40296\n",
            "Epoch 150: loss = 0.39911\n",
            "Epoch 160: loss = 0.39536\n",
            "Epoch 170: loss = 0.39161\n",
            "Epoch 180: loss = 0.38773\n",
            "Epoch 190: loss = 0.38345\n",
            "Epoch 200: loss = 0.37811\n",
            "Epoch 210: loss = 0.36946\n",
            "Epoch 220: loss = 0.35112\n",
            "Epoch 230: loss = 0.33808\n",
            "Epoch 240: loss = 0.33347\n",
            "Epoch 250: loss = 0.33068\n",
            "Epoch 260: loss = 0.32837\n",
            "Epoch 270: loss = 0.32627\n",
            "Epoch 280: loss = 0.32429\n",
            "Epoch 290: loss = 0.32238\n",
            "Epoch 300: loss = 0.32053\n",
            "Epoch 310: loss = 0.31871\n",
            "Epoch 320: loss = 0.31691\n",
            "Epoch 330: loss = 0.31512\n",
            "Epoch 340: loss = 0.31335\n",
            "Epoch 350: loss = 0.31162\n",
            "Epoch 360: loss = 0.30991\n",
            "Epoch 370: loss = 0.30822\n",
            "Epoch 380: loss = 0.30653\n",
            "Epoch 390: loss = 0.30485\n",
            "Epoch 400: loss = 0.30313\n",
            "Epoch 410: loss = 0.30132\n",
            "Epoch 420: loss = 0.29939\n",
            "Epoch 430: loss = 0.29735\n",
            "Epoch 440: loss = 0.29524\n",
            "Epoch 450: loss = 0.29307\n",
            "Epoch 460: loss = 0.29096\n",
            "Epoch 470: loss = 0.28890\n",
            "Epoch 480: loss = 0.28708\n",
            "Epoch 490: loss = 0.28520\n",
            "Epoch 500: loss = 0.28319\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toQyqq98-68X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "outputId": "8f637efb-09dd-4287-b386-c90cef953de0"
      },
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
        "\n",
        "ax.set_title('Evolução da função de perda ao longo das épocas')\n",
        "ax.set_ylabel('Valor da função de perda')\n",
        "ax.set_xlabel('Épocas')\n",
        "ax.plot(np.asarray(loss_list))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sigmoid como camada\n",
        "sigmoid = nn.Sigmoid()\n",
        "sigmoid(torch.tensor([10]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhb6FHwIq1Hl",
        "outputId": "b62274bc-2dfb-4297-de09-d936ce1cb17b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000])"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sigmoid como função\n",
        "y_pred = F.sigmoid(model(X))\n",
        "predictions = (y_pred > 0.5).int()  # predição das classes\n",
        "\n",
        "predictions[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJQlgRcpoDxM",
        "outputId": "013a94f3-ffcb-42e9-80f3-0022b7af0556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0]], dtype=torch.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conjunto de Exercícios 2 - Implementação de uma MLP utilizando objetos\n",
        "\n",
        "- Aqui, iremos repetir o mesmo procedimento feito anteriormente. Porém, iremos adotar uma implementação baseada no paradigma de orientação à objetos, que será muito importante em módulos futuros para definir modelos mais complexos e manter o código organizado.\n",
        "\n",
        "    - Abaixo teremos um código onde a classe MLP receberá quantas `features` teremos de entrada e saída, qual o tamanho das camadas ocultas, e quantas camadas ocultas iremos ter. Uma assinatura diferente para o `__init__` que você pode optar é `__init__(self, in_features, out_features, hidden_sizes)`, onde `hidden_sizes` representa uma lista com o tamanho de cada camada oculta, definindo assim em uma só variável o número de camadas ocultas e suas dimensões. Sinta-se livre para modificar o código e experimentar com ambas opções."
      ],
      "metadata": {
        "id": "Bp5MeuJml3l1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Teste:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def __call__(self):\n",
        "        print('Ola mundo')\n",
        "\n",
        "    def falar(self):\n",
        "        print('Ola mundo')\n",
        "\n",
        "t = Teste()\n",
        "t(), t.falar()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xC3JYpRQs041",
        "outputId": "9cdf87be-0efd-456a-b626-9e54c043ee78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ola mundo\n",
            "Ola mundo\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_layers = 3\n",
        "hidden_size = 50\n",
        "\n",
        "hidden_layers = []\n",
        "for i in range(num_layers - 1):\n",
        "    layer = nn.Linear(hidden_size, hidden_size)\n",
        "    hidden_layers.append(layer)\n",
        "    hidden_layers.append(nn.ReLU())\n",
        "\n",
        "hidden_layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqViUhiBut6F",
        "outputId": "317240d8-8013-4332-b5cb-0614f7236d8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Linear(in_features=50, out_features=50, bias=True),\n",
              " ReLU(),\n",
              " Linear(in_features=50, out_features=50, bias=True),\n",
              " ReLU()]"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_features, out_features, hidden_size, num_hidden_layers):\n",
        "        # Essa linha é obrigatória quando formos definir qualquer modelo em PyTorch dessa forma.\n",
        "        # Uma chamada equivalente é: super(self, MLP).__init__(), mas podemos omitir \"self\" e o nome da classe.\n",
        "        super().__init__()\n",
        "\n",
        "        # Implemente aqui o seu modelo (pode utilizar Sequential ou definir cada camada de forma separada)\n",
        "        hidden_layers = []\n",
        "        for i in range(num_hidden_layers - 1):\n",
        "            layer = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "            # Inserindo na lista uma Linear + ReLU\n",
        "            hidden_layers.append(layer)\n",
        "            hidden_layers.append(nn.ReLU())\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(in_features, hidden_size), nn.ReLU(),\n",
        "            *hidden_layers,\n",
        "            nn.Linear(hidden_size, out_features)\n",
        "        )\n",
        "\n",
        "    # Devemos implementar a passagem do dado ao longo da nossa rede.\n",
        "    # Para isso, sobreescrevemos o método forward, definido pela classe herdada: nn.Module.\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "4aU4-sp5abBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l = ['a', 'b', 'c']\n",
        "\n",
        "def f(x1, x2, x3):\n",
        "    print(x1, x2, x3)\n",
        "\n",
        "f(*l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gsers2DCvJ0E",
        "outputId": "6c084709-c32d-4c8f-d091-898ece367feb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a b c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "in_features = 30\n",
        "out_features = 1\n",
        "\n",
        "# Instancie o seu modelo aqui\n",
        "model = MLP(in_features, out_features, hidden_size=64, num_hidden_layers=2)\n",
        "\n",
        "model = model.to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "yDJvdazdsgrk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fe15019-9d06-460a-da76-5dabb9264f12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP(\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=30, out_features=64, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=64, out_features=1, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Agora iremos treinar o modelo normalmente."
      ],
      "metadata": {
        "id": "jSiflErnuKfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nn.Sequential(\n",
        "    nn.Linear(10, 2),\n",
        "    nn.Linear(2, 10)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lCAOzvMxh6b",
        "outputId": "fc527bed-43f6-4f40-b404-a1d6afbc7e60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=10, out_features=2, bias=True)\n",
              "  (1): Linear(in_features=2, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-4\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Aqui iremos criar uma lista de loss para cada época\n",
        "loss_list = []\n",
        "\n",
        "# Iterando sobre as épocas\n",
        "n_epochs = 500\n",
        "for epoch in range(n_epochs):\n",
        "    preds = model(X)\n",
        "    loss = criterion(preds, y)\n",
        "\n",
        "    # Salvando a loss da iteração atual (para plots futuros)\n",
        "    loss_list.append(loss.item())\n",
        "\n",
        "    # Antes de fazermos o backward pass, iremos zerar o gradiente de todos os tensores\n",
        "    # atrelados ao otimizador utilizando a chamada de função .zero_grad() do nosso otimizador.\n",
        "    # Faremos isso pois os gradientes são acumulados, sempre que chamamos .backward(), em buffers nos\n",
        "    # tensores que representam os pesos dos nossos modelos, ou seja, não são sobrescritos.\n",
        "    # Para mais detalhes, você pode dar uma olhada na documentação do torch.autograd.backward\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Realizando o backward pass, ou seja, computando os gradientes da nossa função de perda\n",
        "    # com respeito aos parâmetros (pesos) do nosso modelo\n",
        "    loss.backward()\n",
        "\n",
        "    # Chamando a função .step() do nosso otimizador para realizar um \"passo\" na otimização.\n",
        "    # Nesse caso, o \"passo\" será realizar o cálculo que vimos do gradiente descendente\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch {epoch + 1}: loss = {loss.item():.5f}')"
      ],
      "metadata": {
        "id": "Yr5ykcPwuH2D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bf6f493-80d7-44f7-ed46-4d78c67c1839"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: loss = 1.42854\n",
            "Epoch 20: loss = 0.81419\n",
            "Epoch 30: loss = 0.60711\n",
            "Epoch 40: loss = 0.57126\n",
            "Epoch 50: loss = 0.48244\n",
            "Epoch 60: loss = 0.39965\n",
            "Epoch 70: loss = 0.34919\n",
            "Epoch 80: loss = 0.33036\n",
            "Epoch 90: loss = 0.32454\n",
            "Epoch 100: loss = 0.32123\n",
            "Epoch 110: loss = 0.31829\n",
            "Epoch 120: loss = 0.31552\n",
            "Epoch 130: loss = 0.31288\n",
            "Epoch 140: loss = 0.31034\n",
            "Epoch 150: loss = 0.30791\n",
            "Epoch 160: loss = 0.30560\n",
            "Epoch 170: loss = 0.30340\n",
            "Epoch 180: loss = 0.30129\n",
            "Epoch 190: loss = 0.29928\n",
            "Epoch 200: loss = 0.29736\n",
            "Epoch 210: loss = 0.29547\n",
            "Epoch 220: loss = 0.29364\n",
            "Epoch 230: loss = 0.29188\n",
            "Epoch 240: loss = 0.29015\n",
            "Epoch 250: loss = 0.28849\n",
            "Epoch 260: loss = 0.28689\n",
            "Epoch 270: loss = 0.28532\n",
            "Epoch 280: loss = 0.28380\n",
            "Epoch 290: loss = 0.28235\n",
            "Epoch 300: loss = 0.28095\n",
            "Epoch 310: loss = 0.27959\n",
            "Epoch 320: loss = 0.27828\n",
            "Epoch 330: loss = 0.27701\n",
            "Epoch 340: loss = 0.27578\n",
            "Epoch 350: loss = 0.27458\n",
            "Epoch 360: loss = 0.27341\n",
            "Epoch 370: loss = 0.27228\n",
            "Epoch 380: loss = 0.27117\n",
            "Epoch 390: loss = 0.27008\n",
            "Epoch 400: loss = 0.26904\n",
            "Epoch 410: loss = 0.26802\n",
            "Epoch 420: loss = 0.26704\n",
            "Epoch 430: loss = 0.26607\n",
            "Epoch 440: loss = 0.26512\n",
            "Epoch 450: loss = 0.26420\n",
            "Epoch 460: loss = 0.26329\n",
            "Epoch 470: loss = 0.26241\n",
            "Epoch 480: loss = 0.26154\n",
            "Epoch 490: loss = 0.26068\n",
            "Epoch 500: loss = 0.25984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(784, 256), nn.ReLU(),\n",
        "    nn.Linear(256, 128), nn.ReLU(),\n",
        "    nn.Linear(128, 64), nn.ReLU(),\n",
        "    nn.Linear(64, 10)\n",
        ")\n",
        "\n",
        "summary(model, (784,))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgngl3g0tgOV",
        "outputId": "047fc216-1a32-4d4d-9dbf-5a03854d046c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 256]         200,960\n",
            "              ReLU-2                  [-1, 256]               0\n",
            "            Linear-3                  [-1, 128]          32,896\n",
            "              ReLU-4                  [-1, 128]               0\n",
            "            Linear-5                   [-1, 64]           8,256\n",
            "              ReLU-6                   [-1, 64]               0\n",
            "            Linear-7                   [-1, 10]             650\n",
            "================================================================\n",
            "Total params: 242,762\n",
            "Trainable params: 242,762\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.01\n",
            "Params size (MB): 0.93\n",
            "Estimated Total Size (MB): 0.94\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sgOkrzha3SE0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}