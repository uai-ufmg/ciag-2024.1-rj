{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lista Teórica 02-03\n",
        "\n",
        "> - Otimização"
      ],
      "metadata": {
        "id": "eFV4xVhmdOB_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercício 1\n",
        "\n",
        "(a) Explique o que é um erro de generalização.\n",
        "\n",
        "(b) Explique brevemente o que cada método abaixo faz e por que, intuitivamente, ele pode ajudar a resolver um erro de generalização.\n",
        "\n",
        "1.  Penalização com norma L2.\n",
        "2.  Data augmentation.\n",
        "3.  Early stopping."
      ],
      "metadata": {
        "id": "_wdnHeP1dYt3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a) Um erro de generalização ocorre quando um modelo falha em ajustar corretamente aos dados de teste, levando a resultados imprecisos. Um erro de generalização pode ocorrer por ajuste excessivo aos dados de treino (overfitting), ou ajustes insuficientes (underfitting).\n",
        "\n",
        "b)\n",
        "\n",
        "1. A penalização L2 é utilizada para reduzir overfitting e, portanto, melhora a generalização de um modelo. Para isso, ela adiciona um termo à função de perda do modelo que penaliza pesos grandes, forçando-os a ficarem mais próximos de 0. Isso impede que certos pesos se sobrasaiam em relação aos demais e dominem o modelo, o que o tornaria menos complexos.\n",
        "\n",
        "2. O Data Augmentation é utilizado para aumentar a quantidade e diversidade dos dados de treinamento, criando novas instâncias a partir das existentes. Esse método ajuda a resolver o problema de generalização, pois diversifica os dados de treinamento, fazendo com que o modelo aprenda novos padrões.\n",
        "\n",
        "3.  O Early Stopping consiste em interromper o treinamento do modelo assim que o desempenho dele no conjunto de validação começa a piorar, ou quando o desempenho não melhora por um número de épocas durante o treinamento. Essa técnica evita que o modelo se ajuste excessivamente aos dados de treino."
      ],
      "metadata": {
        "id": "mxPTktSYdvrV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercício 2\n",
        "\n",
        "Considere a seguinte função objetiva de mínimo quadrados regularizada L2 para uma regressão linear:\n",
        "\n",
        "$$f(w) = ||w”x − y|| + λ||w||2$$\n",
        "\n",
        "\n",
        "Como o λ afeta a reta estimada?"
      ],
      "metadata": {
        "id": "-tTLhXUvdy4f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O termo λ adiciona uma penalidade aos coeficientes da reta estimada, forçando-os a serem menores. Quanto maior o valor de λ, maior será a penalidade da reta, o que resultará em um menor ajuste dela aos dados. Por outro lado, quando λ é pequeno ou igual a zero, a penalidade é baixa e a reta estimada pode se ajustar mais aos dados de treinamento. Assim, λ controla o equilíbrio entre o ajuste aos dados de treinamento e a generalização da reta estimada."
      ],
      "metadata": {
        "id": "frjAIfW8eBwq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercício 3\n",
        "\n",
        "Suponha que você esteja treinando uma rede com dropout e a probabilidade de um nó ser mantido muda de 0.6 para 0.5.\n",
        "1. O que acontece com o efeito de regularização ao diminuir a probabilidade de um nó ser mantido na rede?\n",
        "2. Qual o impacto dessa mudança no erro calculado com o conjunto de treino?\n",
        "3. Durante o treinamento com dropout, a rede é modificada diversas vezes. Alguma modificação deve ser feita na rede em tempo de teste?"
      ],
      "metadata": {
        "id": "Z9uUhxnAeDhk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a) O efeito de regularização tende a ser reduzido.\n",
        "\n",
        "b) Em geral, espera-se que o erro calculado aumente. Isso, pois com a probabilidade menor de se manter um nó, mais neurônios serão desligados durante o treinamento, o que pode levar a uma perda de capacidade de representação dos dados. Como consequência, o modelo pode ter mais dificuldade em ajustar-se aos dados de treinamento, e assim o erro pode aumentar. No entanto, o aumento de erro no treinamento não necessariamente indica um desempenho pior em dados não vistos.\n",
        "\n",
        "c) Em tempo de teste, a rede deve ser utilizada por completo."
      ],
      "metadata": {
        "id": "XEYxiU2ZeWR1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MHh4bk11dWXB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}