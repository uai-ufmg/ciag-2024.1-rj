{"cells":[{"cell_type":"markdown","id":"Zitqg4OC8Rge","metadata":{"id":"Zitqg4OC8Rge"},"source":["# Sequências - Aula Prática\n","\n","## RNNs (Recurrent Neural Networks)\n","\n","Neste notebook, iremos trabalhar com a abordagem inicial de redes neurais recorrentes (RNNs), implementando do zero uma RNN utilizando PyTorch. Além disso, iremos usar RNNs para para realizar uma classificação de litologia."]},{"cell_type":"markdown","id":"AM_Fv8S1d2Ec","metadata":{"id":"AM_Fv8S1d2Ec"},"source":["- **Importante:** caso esteja rodando esse notebook no ambiente da Tatu, favor executar a próxima célula. Caso contrário, basta ignorar a sua execução."]},{"cell_type":"code","execution_count":null,"id":"pkWOvKpuQZxc","metadata":{"id":"pkWOvKpuQZxc"},"outputs":[],"source":["data_dir = '/pgeoprj/godeep/dados/l2_datasets/publico/force'"]},{"cell_type":"markdown","id":"2d00c323-bb9c-4e02-9141-7a391542f879","metadata":{"id":"2d00c323-bb9c-4e02-9141-7a391542f879"},"source":["# Configuração do ambiente\n","\n"]},{"cell_type":"code","execution_count":null,"id":"c2015299-c573-437e-8528-4a524cb356bb","metadata":{"id":"c2015299-c573-437e-8528-4a524cb356bb"},"outputs":[],"source":["import os\n","\n","import json\n","import pandas as pd\n","from tqdm import tqdm\n","import pickle\n","\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.utils.class_weight import compute_class_weight, compute_sample_weight\n","from sklearn.model_selection import train_test_split, KFold\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, confusion_matrix, matthews_corrcoef, f1_score, precision_score, recall_score, ConfusionMatrixDisplay, balanced_accuracy_score\n","\n","import torch\n","import random\n","\n","import numpy as np\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","\n","import matplotlib.pyplot as plt\n","import matplotlib"]},{"cell_type":"markdown","id":"32dc20a4-d198-42eb-98ce-11bcf49e40c3","metadata":{"id":"32dc20a4-d198-42eb-98ce-11bcf49e40c3"},"source":["Um estado aleatório fixo (`random_state = 42`) é definido para reprodutibilidade entre experimentos.\n","\n","A configuração do dispositivo garante o uso da GPU, se disponível, com um fallback para a CPU.\n"]},{"cell_type":"code","execution_count":null,"id":"d560c2d3-ae45-4c42-b2c9-d8dfc7a0d8a2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d560c2d3-ae45-4c42-b2c9-d8dfc7a0d8a2","outputId":"7555820a-a1d1-44e8-8713-14217f337434"},"outputs":[{"name":"stdout","output_type":"stream","text":["Device escolhido: cuda\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Device escolhido:', device)\n","\n","random_state = 42"]},{"cell_type":"markdown","id":"6ff88d58-556b-484c-8a1f-6d721e43361a","metadata":{"id":"6ff88d58-556b-484c-8a1f-6d721e43361a"},"source":["# Carregamento da base de dados"]},{"cell_type":"markdown","id":"410e1097-cfb9-4585-8e0b-8df58c5856f9","metadata":{"id":"410e1097-cfb9-4585-8e0b-8df58c5856f9"},"source":["### Definição da classe Force\n","\n","A classe `Force` foi projetada para lidar com o carregamento e o pré-processamento inicial de dados de registro de poços para classificação de litologia. O conjunto de dados FORCE vem de uma competição feita em 2020.\n","\n","Abaixo estão os detalhes de sua implementação:\n","\n","#### **Inicialização de classe (método `__init__`)**\n","- Parâmetros:\n","    - `directory`: Caminho para o diretório de dados.\n","    - `logs`: Uma lista de registros a serem usados dataset FORCE.\n","    - `verbose`: Se `True`, imprime detalhes adicionais durante a execução.\n","- Chaves de litologia: Um dicionário que mapeia códigos numéricos de litologia para seus respectivos nomes.\n","\n","#### **Carregamento de dados (método `open_data`)**\n","- Objetivo: Método principal para abrir, mesclar e pré-processar dados de registro de poço.\n","- Retorna um `pandas.DataFrame` contendo dados de registro de poço, e uma instância `LabelEncoder` para codificar rótulos de litologia em valores numéricos de 0 a num_classes-1.\n","\n","**Principais etapas:**\n","1. Carregamento de dados: Lê vários arquivos CSV (`train.csv`, `hidden_test.csv`, `leaderboard_test_features.csv`, etc.) em DataFrames separados.\n","2. Verificações de consistência de dados: Garante valores correspondentes para as colunas `WELL` e `DEPTH_MD` entre dataframes concatenados.\n","3. Manipulação de valores ausentes: Preenche valores ausentes na coluna `FORCE_2020_LITHOFACIES_CONFIDENCE` com `NaN`.\n","4. Concatenação e redefinição de índice:*Mescla vários conjuntos de dados (`train`, `leaderboard_test`, etc.) em um DataFrame consolidado e redefine o índice.\n","5. Codificação de rótulos: mapeia códigos de litologia para seus nomes usando `lithology_keys` e os codifica como inteiros usando `LabelEncoder`.\n","\n","**Saída:**\n","- O conjunto de dados pré-processado (`data`) e o codificador de rótulo (`le`) são retornados para uso subsequente no pipeline de modelagem.\n"]},{"cell_type":"code","execution_count":null,"id":"faed8482-04e1-430b-879b-284cb8a2c902","metadata":{"id":"faed8482-04e1-430b-879b-284cb8a2c902"},"outputs":[],"source":["class Force:\n","    def __init__(self, directory:str, logs:list[str], verbose:bool=False) -> None:\n","        \"\"\"\n","            Arguments:\n","            ---------\n","                - directory (str): Path to the directory where data is\n","                - logs (list[str] or tuple[str]): Logs used from FORCE data\n","                - verbose (bool): If True, print progress details. Else, does not print anything.\n","        \"\"\"\n","\n","        self.directory = directory\n","        self.logs = logs\n","\n","        self.lithology_keys = {30000: 'Sandstone',\n","                     65030: 'Sandstone/Shale',\n","                     65000: 'Shale',\n","                     80000: 'Marl',\n","                     74000: 'Dolomite',\n","                     70000: 'Limestone',\n","                     70032: 'Chalk',\n","                     88000: 'Halite',\n","                     86000: 'Anhydrite',\n","                     99000: 'Tuff',\n","                     90000: 'Coal',\n","                     93000: 'Basement'}\n","\n","        self.data, self.le = self.open_data()\n","\n","    def open_data(self) -> tuple[pd.DataFrame, LabelEncoder]:\n","        \"\"\"\n","        Main method to open data.\n","            Arguments:\n","            ---------\n","                -\n","            Return:\n","            ---------\n","                - data (pd.DataFrame): Well log dataset fully configured to be used\n","                - le (LabelEncoder): Label Encoder used to encode lithology classes to consecutive numbers\n","        \"\"\"\n","\n","        train_data = pd.read_csv( os.path.join(self.directory, 'train.csv'), sep=';' )\n","        hidden_test = pd.read_csv( os.path.join(self.directory, 'hidden_test.csv'), sep=';' )\n","        leaderboard_test_features = pd.read_csv( os.path.join(self.directory, 'leaderboard_test_features.csv'), sep=';' )\n","        leaderboard_test_target = pd.read_csv( os.path.join(self.directory, 'leaderboard_test_target.csv'), sep=';' )\n","\n","        ## A little of consistency checking\n","        leaderboard_test_target['WELL_tg'] = leaderboard_test_target.WELL\n","        leaderboard_test_target['DEPTH_MD_tg'] = leaderboard_test_target.DEPTH_MD\n","        leaderboard_test_target.drop(columns=['WELL', 'DEPTH_MD'], inplace=True)\n","        leaderboard_test = pd.concat([leaderboard_test_features, leaderboard_test_target], axis=1)\n","\n","        ## Make sure the values for the WELL and DEPTH_MD columns match between the two concatenated data-frames\n","        _check_well = np.all( (leaderboard_test.WELL == leaderboard_test.WELL_tg).values )\n","        _check_depth = np.all( (leaderboard_test.DEPTH_MD == leaderboard_test.DEPTH_MD_tg).values )\n","        assert _check_well and _check_depth, 'Inconsistency found in leaderboard test data...'\n","\n","        ## Passed the consistency check, we drop the redundant columns\n","        leaderboard_test.drop(columns=['WELL_tg', 'DEPTH_MD_tg'], inplace=True)\n","\n","        ## Note leaderboard_test dataframe does not have the FORCE_2020_LITHOFACIES_CONFIDENCE column. We will therefore fill it with NaNs.\n","        leaderboard_test['FORCE_2020_LITHOFACIES_CONFIDENCE'] = np.nan\n","\n","        data = pd.concat([train_data, leaderboard_test, hidden_test], axis=0, ignore_index=True)\n","        data.sort_values(by=['WELL', 'DEPTH_MD'], inplace=True)\n","        data.reset_index(drop=True, inplace=True)\n","\n","        data['LITHOLOGY_NAMES'] = data.FORCE_2020_LITHOFACIES_LITHOLOGY.map(self.lithology_keys)\n","        data = data[data[\"LITHOLOGY_NAMES\"] != 'Basement']\n","        le = LabelEncoder()\n","        data['LITHOLOGY'] = le.fit_transform(data['FORCE_2020_LITHOFACIES_LITHOLOGY'])\n","\n","        return data, le"]},{"cell_type":"markdown","id":"0ba11225-2fa0-4da2-9f69-1d8818e5bbb4","metadata":{"id":"0ba11225-2fa0-4da2-9f69-1d8818e5bbb4"},"source":["# Pré-processamento"]},{"cell_type":"markdown","id":"dbbe8aa9-3064-4d5f-81a3-b19a7f555e48","metadata":{"id":"dbbe8aa9-3064-4d5f-81a3-b19a7f555e48"},"source":["## Winsorização de dados de registro de poços (função `remove_quartiles`)\n","Esta função remove outliers em dados de registro de poços cortando valores com base em quantis superiores e inferiores.\n","\n","#### Saída\n","- Um DataFrame (`data`) com outliers removidos para os registros especificados."]},{"cell_type":"code","execution_count":null,"id":"c4f77aa7-8680-4139-81f2-7e1ff931d638","metadata":{"id":"c4f77aa7-8680-4139-81f2-7e1ff931d638"},"outputs":[],"source":["def remove_quartiles(original_data:pd.DataFrame, logs:list[str], q:list=[0.01, 0.99], verbose:bool=True) -> pd.DataFrame:\n","    \"\"\"\n","    Function to apply winsorization (remove outliers by clipping extreme quartiles. Upper or lower quartiles)\n","        Arguments:\n","        ---------\n","            - original_data (pd.DataFrame): Well log data, including lithology column\n","            - logs (list[str]): List of log names used. Ex: GR, NPHI, ...\n","            - class_col (str): Name of the lithology column\n","        Return:\n","        ---------\n","            - data (pd.DataFrame): Well log data without outliers.\n","    \"\"\"\n","\n","    data = original_data.copy()\n","    num_cols = len(logs)\n","\n","    for i, col in enumerate(logs):\n","        if verbose:\n","            print(f'Handling log {i + 1}/{num_cols} - {col}')\n","        array_data = data[col].values\n","        only_nans = np.all( np.isnan(array_data) )\n","\n","        if not only_nans:\n","            min_quart, max_quart = np.nanquantile(array_data, q=q)\n","\n","            if verbose:\n","                print(f'{col}: min: {min_quart:.4f} - max: {max_quart:.4f} ')\n","\n","            # Set outlier values as nan\n","            outlier_idx = np.logical_or(array_data < min_quart, array_data > max_quart)\n","            if verbose:\n","                print(f'Ignoring {np.sum(outlier_idx)} values')\n","\n","            # Set series in dataframe with clipped values\n","            data[col] = data[col].clip(min_quart, max_quart)\n","\n","    if verbose:\n","        print()\n","\n","    return data"]},{"cell_type":"markdown","id":"eb084a31-ab2a-4ef8-881c-5e8dd76e6802","metadata":{"id":"eb084a31-ab2a-4ef8-881c-5e8dd76e6802"},"source":["## Abrir e pré-processar dados de registro de poço (função `open_and_preprocess_data`)\n","Esta função carrega, pré-processa e divide dados de registro de poço para treinamento, validação e teste.\n","\n","#### Processo\n","1. Carregamento de dados: Usa a classe `Force` para carregar e pré-processar dados.\n","2. Winsorização: Remove outliers dos registros de poço usando `remove_quartiles`.\n","3. Divisão de poço: Divide poços em conjuntos de treinamento, validação e teste com base em tamanhos especificados.\n","\n","#### Saída\n","- `data`: DataFrame pré-processado.\n","- `le`: Codificador de rótulo para classes de litologia.\n","- `well_names`: Lista de todos os nomes de poço.\n","- `train_wells`, `val_wells`, `test_wells`: Listas de poços para treinamento, validação e teste.\n"]},{"cell_type":"code","execution_count":null,"id":"89b6105b-76f7-48ce-819c-1c477164e448","metadata":{"id":"89b6105b-76f7-48ce-819c-1c477164e448"},"outputs":[],"source":["def open_and_preprocess_data(data_dir:str, logs:list[str], class_col:str, test_size:float, val_size:float, shuffle:bool, random_state:int|np.random.RandomState, verbose:bool=True) -> tuple[pd.DataFrame, LabelEncoder, list, list, list]:\n","\n","    \"\"\"\n","    Function that receives all necessary parameters to open and preprocess data and calls all necessary functions, classes and methods.\n","        Arguments:\n","        ---------\n","            - data_dir (str): Path for folder containing dataset.\n","            - logs (str): List of names of logs used.\n","            - class_col (str): Name of the label column (usually 'Lithology')\n","            - test_size (float): Size of test set. Range: 0-1.\n","            - val_size (float): Size of validation set. Range: 0-1.\n","            - shuffle (bool): Wether to shuffle or not while data splitting.\n","            - random_state (int or np.random.RandomState): Random state to define random operations.\n","            - verbose (bool): If True, print progress details. Else, does not print anything.\n","        Return:\n","        ---------\n","            - data (pd.DataFrame): Well log dataset fully configured to be used\n","            - le (LabelEncoder): Label Encoder used to encode lithology classes to consecutive numbers\n","            - well_names (list[str]): List of all well names contained in dataset\n","            - train_wells (list[str]): List of train wells after splitting\n","            - val_wells (list[str] or None): List of validation wells after splitting. Can be None if there is no validation split.\n","            - test_wells (list[str] or None): List of test wells after splitting. Can be None if there is no test split.\n","    \"\"\"\n","\n","    force_dataset = Force(data_dir, logs)\n","    data, le = force_dataset.data, force_dataset.le\n","\n","    data = remove_quartiles(data, logs, verbose=verbose)\n","\n","    well_names = list(data['WELL'].unique())\n","    train_wells, test_wells = train_test_split(well_names, test_size=test_size, shuffle=shuffle, random_state=random_state)\n","    train_wells, val_wells = train_test_split(train_wells, test_size=val_size, shuffle=shuffle, random_state=random_state)\n","\n","\n","    return data, le, well_names, train_wells, val_wells, test_wells"]},{"cell_type":"markdown","id":"36f8b41d-fc65-47d1-ae15-b0bbe62f6b02","metadata":{"id":"36f8b41d-fc65-47d1-ae15-b0bbe62f6b02"},"source":["## Pipeline de pré-processamento de dados\n","Esta seção usa a função `open_and_preprocess_data` para carregar e preparar dados para o aprendizado de máquina:\n","1. Carrega o conjunto de dados com remoção de outliers habilitada.\n","2. Divide os dados em conjuntos de treinamento, validação e teste com base em nomes de poços.\n","3. Atribui dados de entrada (`X`) e rótulos de destino (`y`) para cada divisão.\n","4. Normaliza valores de log de poços usando `StandardScaler`.\n","\n","#### Saída de dados\n","- `X_train`, `y_train`: Dados de treinamento e rótulos.\n","- `X_val`, `y_val`: Dados de validação e rótulos.\n","- `X_test`, `y_test`: Dados de teste e rótulos.\n","\n","Este pipeline garante pré-processamento consistente e prepara o conjunto de dados para modelagem."]},{"cell_type":"code","execution_count":null,"id":"evWBg12rTuPT","metadata":{"id":"evWBg12rTuPT"},"outputs":[],"source":["class Config:\n","    seq_size = 256\n","    batch_size = 64\n","\n","    split_form = 'train_val_test' ## kfold, train_test or train_val_test\n","    n_splits = 5\n","    test_size = 0.2\n","    val_size = 0.1\n","    shuffle = True\n","\n","    scaling_method = 'standard' # standard or min-max\n","\n","    data_dir = data_dir\n","    logs = ['GR', 'RHOB', 'NPHI', 'DTC']\n","    logs_info = logs + ['WELL', 'DEPTH_MD', 'LITHOLOGY']\n","    class_col = 'LITHOLOGY'\n","\n","    num_classes = 11\n","\n","    verbose = True\n","\n","cfg = Config()"]},{"cell_type":"code","execution_count":null,"id":"861db508-8807-4470-9303-ccbc77750e1c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"861db508-8807-4470-9303-ccbc77750e1c","outputId":"7fce587d-3454-4845-f747-3c688b32379f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Handling log 1/4 - GR\n","GR: min: 8.9536 - max: 180.3104 \n","Ignoring 28592 values\n","Handling log 2/4 - RHOB\n","RHOB: min: 1.6196 - max: 2.6975 \n","Ignoring 24838 values\n","Handling log 3/4 - NPHI\n","NPHI: min: 0.0491 - max: 0.6245 \n","Ignoring 19320 values\n","Handling log 4/4 - DTC\n","DTC: min: 60.0862 - max: 173.0303 \n","Ignoring 26878 values\n","\n"]}],"source":["data, le_data, well_names, train_wells, val_wells, test_wells = open_and_preprocess_data(cfg.data_dir, cfg.logs, cfg.class_col,\n","                                                                                   cfg.test_size, cfg.val_size, cfg.shuffle,\n","                                                                                   random_state, verbose=cfg.verbose)"]},{"cell_type":"code","execution_count":null,"id":"80ed454b-14af-4a13-919d-799dd244899e","metadata":{"id":"80ed454b-14af-4a13-919d-799dd244899e"},"outputs":[],"source":["train_data = data[data['WELL'].isin(train_wells)]\n","X_train = train_data[cfg.logs_info]\n","y_train = train_data[cfg.class_col]\n","\n","val_data = data[data['WELL'].isin(val_wells)]\n","X_val = val_data[cfg.logs_info]\n","y_val = val_data[cfg.class_col]\n","\n","test_data = data[data['WELL'].isin(test_wells)]\n","X_test = test_data[cfg.logs_info]\n","y_test = test_data[cfg.class_col]"]},{"cell_type":"code","execution_count":null,"id":"83df5339-ce22-408a-bca8-f5569859ceff","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"83df5339-ce22-408a-bca8-f5569859ceff","outputId":"1dec8726-24ba-4d60-ac73-8d4fae17a8be"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-12-36ac85b6a544>:3: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  X_train[cfg.logs] = scaler.fit_transform(X_train[cfg.logs])\n","<ipython-input-12-36ac85b6a544>:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  X_val[cfg.logs] = scaler.transform(X_val[cfg.logs])\n","<ipython-input-12-36ac85b6a544>:5: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  X_test[cfg.logs] = scaler.transform(X_test[cfg.logs])\n"]}],"source":["scaler = StandardScaler()\n","\n","X_train[cfg.logs] = scaler.fit_transform(X_train[cfg.logs])\n","X_val[cfg.logs] = scaler.transform(X_val[cfg.logs])\n","X_test[cfg.logs] = scaler.transform(X_test[cfg.logs])"]},{"cell_type":"markdown","id":"87d87215-f21c-446a-adb1-7e7fd1c728ca","metadata":{"id":"87d87215-f21c-446a-adb1-7e7fd1c728ca"},"source":["# Dataset e DataLoader"]},{"cell_type":"markdown","id":"205f387e-2b0a-4012-a99a-d4aa2029655d","metadata":{"id":"205f387e-2b0a-4012-a99a-d4aa2029655d"},"source":["### Classe LithologyDataset\n","Esta classe é um conjunto de dados PyTorch personalizado projetado para classificação de litologia. Ele processa dados de registro de poços, gera sequências e prepara os dados para treinamento do modelo.\n","\n","#### Criando sequências (método `_create_dataset`)\n","- Objetivo: Gera sequências de comprimento fixo (`seq_size`) a partir dos dados para cada poço.\n","- Processo:\n","1. Itera por cada poço no conjunto de dados.\n","2. Extrai sequências consecutivas de tamanho `seq_size`.\n","3. Lida com valores ausentes pulando sequências com NaNs.\n","4. Acrescenta sequências válidas junto com seus rótulos à lista de sequências.\n","- Saída: Uma lista de sequências sem valores ausentes.\n","\n","#### Tamanho do conjunto de dados (método `__len__`)\n","- Objetivo: Retorna o número total de sequências no conjunto de dados.\n","\n","#### Obter item (método `__getitem__`)\n","- Objetivo: Recupera uma única sequência e seus rótulos correspondentes com base no índice.\n","\n","### Funcionalidade geral\n","A classe `LithologyDataset`:\n","1. Prepara dados de registro de poços para classificação de litologia.\n","2. Lida com geração de sequência, valores ausentes e formatação.\n","3. Fornece estruturas de dados compatíveis com PyTorch para treinamento de modelos de aprendizado de máquina.\n"]},{"cell_type":"code","execution_count":null,"id":"925543bc-7409-4b5c-a5ff-f3ba0dd195ac","metadata":{"id":"925543bc-7409-4b5c-a5ff-f3ba0dd195ac"},"outputs":[],"source":["class LithologyDataset(Dataset):\n","    def __init__(self, df:pd.DataFrame, labels:pd.Series, logs:list[str], num_classes:int, seq_size:int=100, interval_size:int=100, well_name_column:str='WELL', lithology_column:str='LITHOLOGY') -> None:\n","        \"\"\"\n","            Arguments:\n","            ---------\n","                - df (pd.DataFrame): Well log data\n","                - labels (pd.Series): Column containing lithology classes for each depth\n","                - logs (list[str]): List of logs used. Ex: GR, NPHI, ...\n","                - num_classes (int): Number of lithology classes\n","                - seq_size (int): Size of sequence sent to the model\n","                - interval_size (int): Size of the interval used to extract consecutive sequences\n","                - well_name_column (str): Name of the column that indicates the well name in the data\n","                - lithology_column (str): Name of the lithology column\n","            Return:\n","            ---------\n","                None\n","        \"\"\"\n","\n","        self.data = df\n","        self.list_of_wells = list(df[well_name_column].unique())\n","        self.labels = labels\n","        self.logs = logs\n","        self.num_classes = num_classes\n","        self.seq_size = seq_size\n","        self.interval_size = interval_size\n","        self.well_name_column = well_name_column\n","        self.lithology_column = lithology_column\n","        self.no_missing_logs = self.logs + [self.lithology_column]\n","\n","        self.data['labels'] = labels\n","        self.list_of_sequences = self.__create_dataset(self.data, verbose=False)\n","\n","    def __create_dataset(self, df:pd.DataFrame, verbose:bool=False) -> list:\n","        \"\"\"\n","            Arguments:\n","            ---------\n","                - df (pd.DataFrame): Well log data\n","            Return:\n","            ---------\n","                - list_of_sequences (list): list of all sequences without null values in the dataset\n","        \"\"\"\n","\n","        list_of_sequences = list()\n","\n","        for wellname in tqdm(self.list_of_wells, disable=(not verbose)):\n","\n","            well_df = df[df[self.well_name_column] == wellname]\n","\n","            j=0\n","            while j < well_df.shape[0]-(self.seq_size-1): # Enquanto for possível pegar uma sequência de tamanho seq_size no meu poço\n","\n","                sequence = well_df.iloc[j:j+self.seq_size]\n","\n","                # Busca indíces de valores nulos dentro da sequência\n","                idx_null = [k for k,x in enumerate(sequence[self.no_missing_logs].values) if np.isnan(x).any()]\n","\n","                # Se não tiver valor nulo na sequência\n","                if idx_null == []:\n","                    list_of_sequences.append([wellname, sequence[self.logs], sequence['labels']])\n","                    j = j + self.interval_size\n","                # Se tiver, pular para o indíce seguinte ao último valor nulo na sequência\n","                else:\n","                    j = j + idx_null[-1] + 1\n","\n","        return list_of_sequences\n","\n","    def __len__(self):\n","\n","        return len(self.list_of_sequences)\n","\n","    def __getitem__(self, idx) -> tuple[str, torch.Tensor, torch.Tensor]:\n","        \"\"\"\n","            Arguments:\n","            ---------\n","                - idx (int): Index for selecting a sample from the dataset\n","            Return:\n","            ---------\n","                - wellname (str): Name of the well from which the sequence is taken\n","                - well_data_torch (torch.Tensor): Well log sequence\n","                - labels_torch (torch.Tensor): One-hot-encoded lithology labels sequence\n","        \"\"\"\n","\n","        wellname, sequence, labels = self.list_of_sequences[idx]\n","        # To numpy\n","        sequence_numpy = sequence.to_numpy()\n","        sequence_numpy = np.reshape(sequence_numpy, (-1, len(self.logs)))\n","\n","        # Create one-hot vector to represent labels\n","        labels_numpy = np.array([np.array([1. if i==label else 0. for i in range(self.num_classes)]) for label in labels.to_numpy()])\n","\n","        # To torch\n","        well_data_torch = torch.from_numpy(sequence_numpy).float()\n","        labels_torch = torch.from_numpy(labels_numpy).float()\n","\n","        return wellname, well_data_torch, labels_torch"]},{"cell_type":"markdown","id":"299f2876-8fe6-48e7-bf32-82ef900908b6","metadata":{"id":"299f2876-8fe6-48e7-bf32-82ef900908b6"},"source":["### Criando Datasets e DataLoaders\n","\n","Esta seção prepara os dados para treinamento, validação e teste utilizando a classe `LithologyDataset` e o `DataLoader` do PyTorch. Os DataLoaders facilitam o processamento em lote durante o treinamento e a avaliação do modelo.\n","\n","#### Datasets\n","**Dataset de treinamento, validação ou teste (`{split_type}_dataset`)**:\n","- Entradas: `X_{split_type}`, `y_{split_type}` e parâmetros de configuração.\n","- As sequências são geradas usando a classe `LithologyDataset` com tamanho de sequência especificado (`cfg.seq_size`) e tamanho de intervalo.\n","\n","#### DataLoaders\n","**DataLoader (`{split_type}_dataloader`)**:\n","- Envolve o `{split_type}_dataset` para processamento em lote eficiente.\n","- Tamanho do lote: `cfg.batch_size`.\n","- O embaralhamento habilitado (`shuffle=True`) garante a randomização durante o treinamento.\n","\n","### Objetivo\n","Esta configuração garante:\n","1. Carregamento de dados eficiente e escalável para treinamento, validação e teste.\n","2. Compatibilidade com o loop de treinamento do PyTorch.\n","3. Manipulação adequada de sequências com tamanhos de lote configuráveis e embaralhamento de dados conforme necessário.\n"]},{"cell_type":"code","execution_count":null,"id":"b61c3114-4d92-4998-a92b-174d2ef54797","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b61c3114-4d92-4998-a92b-174d2ef54797","outputId":"b4fb305c-78aa-4a6b-fd37-a66808ccebd6"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-13-33781b61fbc3>:30: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self.data['labels'] = labels\n","<ipython-input-13-33781b61fbc3>:30: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self.data['labels'] = labels\n","<ipython-input-13-33781b61fbc3>:30: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self.data['labels'] = labels\n"]}],"source":["train_dataset = LithologyDataset(X_train, y_train, cfg.logs, cfg.num_classes, seq_size=cfg.seq_size, interval_size=cfg.seq_size)\n","train_dataloader = DataLoader(train_dataset, batch_size=cfg.batch_size, shuffle=True)\n","\n","val_dataset = LithologyDataset(X_val, y_val, cfg.logs, cfg.num_classes, seq_size=cfg.seq_size, interval_size=cfg.seq_size)\n","val_dataloader = DataLoader(val_dataset, batch_size=cfg.batch_size, shuffle=False)\n","\n","test_dataset = LithologyDataset(X_test, y_test, cfg.logs, cfg.num_classes, seq_size=cfg.seq_size, interval_size=cfg.seq_size)\n","test_dataloader = DataLoader(test_dataset, batch_size=cfg.batch_size, shuffle=False)"]},{"cell_type":"markdown","id":"4bfb3613-cdcc-487f-84ae-60fc463e071a","metadata":{"id":"4bfb3613-cdcc-487f-84ae-60fc463e071a"},"source":["# Modelos"]},{"cell_type":"markdown","id":"dfac773f-e869-4e70-af7d-5543d4d3cd4c","metadata":{"id":"dfac773f-e869-4e70-af7d-5543d4d3cd4c"},"source":["#### **Classe RNN**\n","\n","1. Implemente uma RNN. Ela deve ser projetada para manipular dados sequenciais, e ter uma camada totalmente conectada para gerar saídas. Deve ser possível configurar seu modelo para que seja unidirecional ou bidirecional."]},{"cell_type":"code","execution_count":null,"id":"f33e5109-ae9d-46a2-b57a-0fea7e55f0cd","metadata":{"id":"f33e5109-ae9d-46a2-b57a-0fea7e55f0cd"},"outputs":[],"source":["# Implemente a sua solução aqui"]},{"cell_type":"markdown","id":"9dfbe405-c32b-496e-9fee-bfd6987543bb","metadata":{"id":"9dfbe405-c32b-496e-9fee-bfd6987543bb"},"source":["# Treinamento"]},{"cell_type":"markdown","id":"707100fa-f939-467c-badd-0b2749d60526","metadata":{"id":"707100fa-f939-467c-badd-0b2749d60526"},"source":["### Função de avaliação (`evaluate`)\n","\n","2. Implemente uma função para avaliar o desempenho de um modelo. Calcule acurácia, MCC, precisão, recall e F1-score. Crie uma matriz de confusão com rótulos de classe de litologia."]},{"cell_type":"code","execution_count":null,"id":"d482a993-b2fa-42f2-bb59-e9de2bba0a05","metadata":{"id":"d482a993-b2fa-42f2-bb59-e9de2bba0a05"},"outputs":[],"source":["# Implemente a sua solução aqui"]},{"cell_type":"markdown","id":"33a62928-cc0c-4abc-8a20-36431df09984","metadata":{"id":"33a62928-cc0c-4abc-8a20-36431df09984"},"source":["### Configuração do modelo, função de perda e otimizador\n","\n","3. Configure e instancie dois modelos: RNN e BiRNN. Depois, defina uma função de perda e um otimizador para o treinamento. **Dica:** Não se esqueça de enviar os modelos para a GPU.\n"]},{"cell_type":"code","execution_count":null,"id":"6954f8b2-7287-451b-8e19-1a85a595142a","metadata":{"id":"6954f8b2-7287-451b-8e19-1a85a595142a"},"outputs":[],"source":["# Implemente a sua solução aqui"]},{"cell_type":"markdown","id":"018cf662-a286-4876-969b-383e92b3c2b4","metadata":{"id":"018cf662-a286-4876-969b-383e92b3c2b4"},"source":["### Loop de treinamento\n","\n","4. Implemente a função `train` e treine cada um dos modelos."]},{"cell_type":"code","execution_count":null,"id":"039a55a8-69c7-4bd8-8e57-516b9f70ff42","metadata":{"id":"039a55a8-69c7-4bd8-8e57-516b9f70ff42"},"outputs":[],"source":["def train(model, epochs=100):\n","    \n","    # Implemente a sua solução aqui"]},{"cell_type":"markdown","id":"7e4de766-5b17-4a22-91d8-45a1a13a1c1e","metadata":{"id":"7e4de766-5b17-4a22-91d8-45a1a13a1c1e"},"source":["### Avaliação final\n","\n","5. Avalie cada um dos modelos por meio da função de avaliação."]},{"cell_type":"code","execution_count":null,"id":"1b3c7c35","metadata":{},"outputs":[],"source":["# Implemente a sua solução aqui"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["6ff88d58-556b-484c-8a1f-6d721e43361a","410e1097-cfb9-4585-8e0b-8df58c5856f9","205f387e-2b0a-4012-a99a-d4aa2029655d"],"gpuType":"T4","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":5}
