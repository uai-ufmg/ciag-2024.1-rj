{"cells":[{"cell_type":"markdown","id":"Zitqg4OC8Rge","metadata":{"id":"Zitqg4OC8Rge"},"source":["# Sequências - Aula Prática\n","\n","## LSTM + GRU\n","\n","Neste notebook, iremos implementar novos tipos de redes neurais recorrentes (LSTM, GRU, BiLSTM, BiGRU) para o conjunto de dados de classificação de litologia."]},{"cell_type":"markdown","id":"AM_Fv8S1d2Ec","metadata":{"id":"AM_Fv8S1d2Ec"},"source":["- **Importante:** caso esteja rodando esse notebook no ambiente do Google Colab, favor executar as próximas células. Caso contrário, basta ignorar a sua execução."]},{"cell_type":"code","execution_count":null,"id":"NmL0yIKueb6z","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NmL0yIKueb6z","outputId":"33005dbd-bdf0-4a6e-8b99-a6e58f61f95c"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2024-11-25 18:09:33--  https://raw.githubusercontent.com/bolgebrygg/Force-2020-Machine-Learning-competition/refs/heads/master/lithology_competition/data/hidden_test.csv\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 30292497 (29M) [text/plain]\n","Saving to: ‘hidden_test.csv’\n","\n","hidden_test.csv     100%[===================>]  28.89M   127MB/s    in 0.2s    \n","\n","2024-11-25 18:09:36 (127 MB/s) - ‘hidden_test.csv’ saved [30292497/30292497]\n","\n","--2024-11-25 18:09:37--  https://raw.githubusercontent.com/bolgebrygg/Force-2020-Machine-Learning-competition/refs/heads/master/lithology_competition/data/leaderboard_test_features.csv\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 31688732 (30M) [text/plain]\n","Saving to: ‘leaderboard_test_features.csv’\n","\n","leaderboard_test_fe 100%[===================>]  30.22M   186MB/s    in 0.2s    \n","\n","2024-11-25 18:09:39 (186 MB/s) - ‘leaderboard_test_features.csv’ saved [31688732/31688732]\n","\n","--2024-11-25 18:09:39--  https://raw.githubusercontent.com/bolgebrygg/Force-2020-Machine-Learning-competition/refs/heads/master/lithology_competition/data/leaderboard_test_target.csv\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3694123 (3.5M) [text/plain]\n","Saving to: ‘leaderboard_test_target.csv’\n","\n","leaderboard_test_ta 100%[===================>]   3.52M  --.-KB/s    in 0.07s   \n","\n","2024-11-25 18:09:39 (53.5 MB/s) - ‘leaderboard_test_target.csv’ saved [3694123/3694123]\n","\n","--2024-11-25 18:09:40--  https://raw.githubusercontent.com/bolgebrygg/Force-2020-Machine-Learning-competition/refs/heads/master/lithology_competition/data/train.zip\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 91653972 (87M) [application/zip]\n","Saving to: ‘train.zip’\n","\n","train.zip           100%[===================>]  87.41M   166MB/s    in 0.5s    \n","\n","2024-11-25 18:09:51 (166 MB/s) - ‘train.zip’ saved [91653972/91653972]\n","\n"]}],"source":["!wget -nc https://raw.githubusercontent.com/bolgebrygg/Force-2020-Machine-Learning-competition/refs/heads/master/lithology_competition/data/hidden_test.csv\n","!wget -nc https://raw.githubusercontent.com/bolgebrygg/Force-2020-Machine-Learning-competition/refs/heads/master/lithology_competition/data/leaderboard_test_features.csv\n","!wget -nc https://raw.githubusercontent.com/bolgebrygg/Force-2020-Machine-Learning-competition/refs/heads/master/lithology_competition/data/leaderboard_test_target.csv\n","!wget -nc https://raw.githubusercontent.com/bolgebrygg/Force-2020-Machine-Learning-competition/refs/heads/master/lithology_competition/data/train.zip"]},{"cell_type":"code","execution_count":null,"id":"YSii-v8wfaaW","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YSii-v8wfaaW","outputId":"8c8cabee-f9dc-4beb-aa3b-b41e4e53ae79"},"outputs":[{"name":"stdout","output_type":"stream","text":["Archive:  train.zip\n","  inflating: train.csv               \n"]}],"source":["!unzip -o train.zip"]},{"cell_type":"code","execution_count":null,"id":"f2gDHYpmd7-c","metadata":{"id":"f2gDHYpmd7-c"},"outputs":[],"source":["data_dir = '/content'"]},{"cell_type":"markdown","id":"2d00c323-bb9c-4e02-9141-7a391542f879","metadata":{"id":"2d00c323-bb9c-4e02-9141-7a391542f879"},"source":["# Configuração do ambiente\n","\n"]},{"cell_type":"code","execution_count":null,"id":"c2015299-c573-437e-8528-4a524cb356bb","metadata":{"id":"c2015299-c573-437e-8528-4a524cb356bb"},"outputs":[],"source":["import os\n","\n","import json\n","import pandas as pd\n","from tqdm import tqdm\n","import pickle\n","\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.utils.class_weight import compute_class_weight, compute_sample_weight\n","from sklearn.model_selection import train_test_split, KFold\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, confusion_matrix, matthews_corrcoef, f1_score, precision_score, recall_score, ConfusionMatrixDisplay, balanced_accuracy_score\n","\n","import torch\n","import random\n","\n","import numpy as np\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torchinfo import summary\n","\n","import matplotlib.pyplot as plt\n","import matplotlib"]},{"cell_type":"code","execution_count":null,"id":"d560c2d3-ae45-4c42-b2c9-d8dfc7a0d8a2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d560c2d3-ae45-4c42-b2c9-d8dfc7a0d8a2","outputId":"7555820a-a1d1-44e8-8713-14217f337434"},"outputs":[{"name":"stdout","output_type":"stream","text":["Device escolhido: cuda\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Device escolhido:', device)\n","\n","random_state = 42"]},{"cell_type":"markdown","id":"6ff88d58-556b-484c-8a1f-6d721e43361a","metadata":{"id":"6ff88d58-556b-484c-8a1f-6d721e43361a"},"source":["# Carregamento da base de dados"]},{"cell_type":"code","execution_count":null,"id":"faed8482-04e1-430b-879b-284cb8a2c902","metadata":{"id":"faed8482-04e1-430b-879b-284cb8a2c902"},"outputs":[],"source":["class Force:\n","    def __init__(self, directory:str, logs:list[str], verbose:bool=False) -> None:\n","        \"\"\"\n","            Arguments:\n","            ---------\n","                - directory (str): Path to the directory where data is\n","                - logs (list[str] or tuple[str]): Logs used from FORCE data\n","                - verbose (bool): If True, print progress details. Else, does not print anything.\n","        \"\"\"\n","\n","        self.directory = directory\n","        self.logs = logs\n","\n","        self.lithology_keys = {30000: 'Sandstone',\n","                     65030: 'Sandstone/Shale',\n","                     65000: 'Shale',\n","                     80000: 'Marl',\n","                     74000: 'Dolomite',\n","                     70000: 'Limestone',\n","                     70032: 'Chalk',\n","                     88000: 'Halite',\n","                     86000: 'Anhydrite',\n","                     99000: 'Tuff',\n","                     90000: 'Coal',\n","                     93000: 'Basement'}\n","\n","        self.data, self.le = self.open_data()\n","\n","    def open_data(self) -> tuple[pd.DataFrame, LabelEncoder]:\n","        \"\"\"\n","        Main method to open data.\n","            Arguments:\n","            ---------\n","                -\n","            Return:\n","            ---------\n","                - data (pd.DataFrame): Well log dataset fully configured to be used\n","                - le (LabelEncoder): Label Encoder used to encode lithology classes to consecutive numbers\n","        \"\"\"\n","\n","        train_data = pd.read_csv( os.path.join(self.directory, 'train.csv'), sep=';' )\n","        hidden_test = pd.read_csv( os.path.join(self.directory, 'hidden_test.csv'), sep=';' )\n","        leaderboard_test_features = pd.read_csv( os.path.join(self.directory, 'leaderboard_test_features.csv'), sep=';' )\n","        leaderboard_test_target = pd.read_csv( os.path.join(self.directory, 'leaderboard_test_target.csv'), sep=';' )\n","\n","        ## A little of consistency checking\n","        leaderboard_test_target['WELL_tg'] = leaderboard_test_target.WELL\n","        leaderboard_test_target['DEPTH_MD_tg'] = leaderboard_test_target.DEPTH_MD\n","        leaderboard_test_target.drop(columns=['WELL', 'DEPTH_MD'], inplace=True)\n","        leaderboard_test = pd.concat([leaderboard_test_features, leaderboard_test_target], axis=1)\n","\n","        ## Make sure the values for the WELL and DEPTH_MD columns match between the two concatenated data-frames\n","        _check_well = np.all( (leaderboard_test.WELL == leaderboard_test.WELL_tg).values )\n","        _check_depth = np.all( (leaderboard_test.DEPTH_MD == leaderboard_test.DEPTH_MD_tg).values )\n","        assert _check_well and _check_depth, 'Inconsistency found in leaderboard test data...'\n","\n","        ## Passed the consistency check, we drop the redundant columns\n","        leaderboard_test.drop(columns=['WELL_tg', 'DEPTH_MD_tg'], inplace=True)\n","\n","        ## Note leaderboard_test dataframe does not have the FORCE_2020_LITHOFACIES_CONFIDENCE column. We will therefore fill it with NaNs.\n","        leaderboard_test['FORCE_2020_LITHOFACIES_CONFIDENCE'] = np.nan\n","\n","        data = pd.concat([train_data, leaderboard_test, hidden_test], axis=0, ignore_index=True)\n","        data.sort_values(by=['WELL', 'DEPTH_MD'], inplace=True)\n","        data.reset_index(drop=True, inplace=True)\n","\n","        data['LITHOLOGY_NAMES'] = data.FORCE_2020_LITHOFACIES_LITHOLOGY.map(self.lithology_keys)\n","        data = data[data[\"LITHOLOGY_NAMES\"] != 'Basement']\n","        le = LabelEncoder()\n","        data['LITHOLOGY'] = le.fit_transform(data['FORCE_2020_LITHOFACIES_LITHOLOGY'])\n","\n","        return data, le"]},{"cell_type":"markdown","id":"0ba11225-2fa0-4da2-9f69-1d8818e5bbb4","metadata":{"id":"0ba11225-2fa0-4da2-9f69-1d8818e5bbb4"},"source":["# Pré-processamento"]},{"cell_type":"code","execution_count":null,"id":"c4f77aa7-8680-4139-81f2-7e1ff931d638","metadata":{"id":"c4f77aa7-8680-4139-81f2-7e1ff931d638"},"outputs":[],"source":["def remove_quartiles(original_data:pd.DataFrame, logs:list[str], q:list=[0.01, 0.99], verbose:bool=True) -> pd.DataFrame:\n","    \"\"\"\n","    Function to apply winsorization (remove outliers by clipping extreme quartiles. Upper or lower quartiles)\n","        Arguments:\n","        ---------\n","            - original_data (pd.DataFrame): Well log data, including lithology column\n","            - logs (list[str]): List of log names used. Ex: GR, NPHI, ...\n","            - class_col (str): Name of the lithology column\n","        Return:\n","        ---------\n","            - data (pd.DataFrame): Well log data without outliers.\n","    \"\"\"\n","\n","    data = original_data.copy()\n","    num_cols = len(logs)\n","\n","    for i, col in enumerate(logs):\n","        if verbose:\n","            print(f'Handling log {i + 1}/{num_cols} - {col}')\n","        array_data = data[col].values\n","        only_nans = np.all( np.isnan(array_data) )\n","\n","        if not only_nans:\n","            min_quart, max_quart = np.nanquantile(array_data, q=q)\n","\n","            if verbose:\n","                print(f'{col}: min: {min_quart:.4f} - max: {max_quart:.4f} ')\n","\n","            # Set outlier values as nan\n","            outlier_idx = np.logical_or(array_data < min_quart, array_data > max_quart)\n","            if verbose:\n","                print(f'Ignoring {np.sum(outlier_idx)} values')\n","\n","            # Set series in dataframe with clipped values\n","            data[col] = data[col].clip(min_quart, max_quart)\n","\n","    if verbose:\n","        print()\n","\n","    return data"]},{"cell_type":"code","execution_count":null,"id":"89b6105b-76f7-48ce-819c-1c477164e448","metadata":{"id":"89b6105b-76f7-48ce-819c-1c477164e448"},"outputs":[],"source":["def open_and_preprocess_data(data_dir:str, logs:list[str], class_col:str, test_size:float, val_size:float, shuffle:bool, random_state:int|np.random.RandomState, verbose:bool=True) -> tuple[pd.DataFrame, LabelEncoder, list, list, list]:\n","\n","    \"\"\"\n","    Function that receives all necessary parameters to open and preprocess data and calls all necessary functions, classes and methods.\n","        Arguments:\n","        ---------\n","            - data_dir (str): Path for folder containing dataset.\n","            - logs (str): List of names of logs used.\n","            - class_col (str): Name of the label column (usually 'Lithology')\n","            - test_size (float): Size of test set. Range: 0-1.\n","            - val_size (float): Size of validation set. Range: 0-1.\n","            - shuffle (bool): Wether to shuffle or not while data splitting.\n","            - random_state (int or np.random.RandomState): Random state to define random operations.\n","            - verbose (bool): If True, print progress details. Else, does not print anything.\n","        Return:\n","        ---------\n","            - data (pd.DataFrame): Well log dataset fully configured to be used\n","            - le (LabelEncoder): Label Encoder used to encode lithology classes to consecutive numbers\n","            - well_names (list[str]): List of all well names contained in dataset\n","            - train_wells (list[str]): List of train wells after splitting\n","            - val_wells (list[str] or None): List of validation wells after splitting. Can be None if there is no validation split.\n","            - test_wells (list[str] or None): List of test wells after splitting. Can be None if there is no test split.\n","    \"\"\"\n","\n","    force_dataset = Force(data_dir, logs)\n","    data, le = force_dataset.data, force_dataset.le\n","\n","    data = remove_quartiles(data, logs, verbose=verbose)\n","\n","    well_names = list(data['WELL'].unique())\n","    train_wells, test_wells = train_test_split(well_names, test_size=test_size, shuffle=shuffle, random_state=random_state)\n","    train_wells, val_wells = train_test_split(train_wells, test_size=val_size, shuffle=shuffle, random_state=random_state)\n","\n","\n","    return data, le, well_names, train_wells, val_wells, test_wells"]},{"cell_type":"code","execution_count":null,"id":"kAf1BVF1sUrE","metadata":{"id":"kAf1BVF1sUrE"},"outputs":[],"source":["class Config:\n","    seq_size = 256\n","    batch_size = 64\n","\n","    split_form = 'train_val_test' ## kfold, train_test or train_val_test\n","    n_splits = 5\n","    test_size = 0.2\n","    val_size = 0.1\n","    shuffle = True\n","\n","    scaling_method = 'standard' # standard or min-max\n","\n","    data_dir = data_dir\n","    logs = ['GR', 'RHOB', 'NPHI', 'DTC']\n","    logs_info = logs + ['WELL', 'DEPTH_MD', 'LITHOLOGY']\n","    class_col = 'LITHOLOGY'\n","\n","    num_classes = 11\n","\n","    verbose = True\n","\n","cfg = Config()"]},{"cell_type":"code","execution_count":null,"id":"861db508-8807-4470-9303-ccbc77750e1c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"861db508-8807-4470-9303-ccbc77750e1c","outputId":"7fce587d-3454-4845-f747-3c688b32379f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Handling log 1/4 - GR\n","GR: min: 8.9536 - max: 180.3104 \n","Ignoring 28592 values\n","Handling log 2/4 - RHOB\n","RHOB: min: 1.6196 - max: 2.6975 \n","Ignoring 24838 values\n","Handling log 3/4 - NPHI\n","NPHI: min: 0.0491 - max: 0.6245 \n","Ignoring 19320 values\n","Handling log 4/4 - DTC\n","DTC: min: 60.0862 - max: 173.0303 \n","Ignoring 26878 values\n","\n"]}],"source":["data, le_data, well_names, train_wells, val_wells, test_wells = open_and_preprocess_data(cfg.data_dir, cfg.logs, cfg.class_col,\n","                                                                                   cfg.test_size, cfg.val_size, cfg.shuffle,\n","                                                                                   random_state, verbose=cfg.verbose)"]},{"cell_type":"code","execution_count":null,"id":"80ed454b-14af-4a13-919d-799dd244899e","metadata":{"id":"80ed454b-14af-4a13-919d-799dd244899e"},"outputs":[],"source":["train_data = data[data['WELL'].isin(train_wells)]\n","X_train = train_data[cfg.logs_info]\n","y_train = train_data[cfg.class_col]\n","\n","val_data = data[data['WELL'].isin(val_wells)]\n","X_val = val_data[cfg.logs_info]\n","y_val = val_data[cfg.class_col]\n","\n","test_data = data[data['WELL'].isin(test_wells)]\n","X_test = test_data[cfg.logs_info]\n","y_test = test_data[cfg.class_col]"]},{"cell_type":"code","execution_count":null,"id":"83df5339-ce22-408a-bca8-f5569859ceff","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"83df5339-ce22-408a-bca8-f5569859ceff","outputId":"1dec8726-24ba-4d60-ac73-8d4fae17a8be"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-12-36ac85b6a544>:3: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  X_train[cfg.logs] = scaler.fit_transform(X_train[cfg.logs])\n","<ipython-input-12-36ac85b6a544>:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  X_val[cfg.logs] = scaler.transform(X_val[cfg.logs])\n","<ipython-input-12-36ac85b6a544>:5: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  X_test[cfg.logs] = scaler.transform(X_test[cfg.logs])\n"]}],"source":["scaler = StandardScaler()\n","\n","X_train[cfg.logs] = scaler.fit_transform(X_train[cfg.logs])\n","X_val[cfg.logs] = scaler.transform(X_val[cfg.logs])\n","X_test[cfg.logs] = scaler.transform(X_test[cfg.logs])"]},{"cell_type":"markdown","id":"87d87215-f21c-446a-adb1-7e7fd1c728ca","metadata":{"id":"87d87215-f21c-446a-adb1-7e7fd1c728ca"},"source":["# Dataset e DataLoader"]},{"cell_type":"code","execution_count":null,"id":"925543bc-7409-4b5c-a5ff-f3ba0dd195ac","metadata":{"id":"925543bc-7409-4b5c-a5ff-f3ba0dd195ac"},"outputs":[],"source":["class LithologyDataset(Dataset):\n","    def __init__(self, df:pd.DataFrame, labels:pd.Series, logs:list[str], num_classes:int, seq_size:int=100, interval_size:int=100, well_name_column:str='WELL', lithology_column:str='LITHOLOGY') -> None:\n","        \"\"\"\n","            Arguments:\n","            ---------\n","                - df (pd.DataFrame): Well log data\n","                - labels (pd.Series): Column containing lithology classes for each depth\n","                - logs (list[str]): List of logs used. Ex: GR, NPHI, ...\n","                - num_classes (int): Number of lithology classes\n","                - seq_size (int): Size of sequence sent to the model\n","                - interval_size (int): Size of the interval used to extract consecutive sequences\n","                - well_name_column (str): Name of the column that indicates the well name in the data\n","                - lithology_column (str): Name of the lithology column\n","            Return:\n","            ---------\n","                None\n","        \"\"\"\n","\n","        self.data = df\n","        self.list_of_wells = list(df[well_name_column].unique())\n","        self.labels = labels\n","        self.logs = logs\n","        self.num_classes = num_classes\n","        self.seq_size = seq_size\n","        self.interval_size = interval_size\n","        self.well_name_column = well_name_column\n","        self.lithology_column = lithology_column\n","        self.no_missing_logs = self.logs + [self.lithology_column]\n","\n","        self.data['labels'] = labels\n","        self.list_of_sequences = self.__create_dataset(self.data, verbose=False)\n","\n","    def __create_dataset(self, df:pd.DataFrame, verbose:bool=False) -> list:\n","        \"\"\"\n","            Arguments:\n","            ---------\n","                - df (pd.DataFrame): Well log data\n","            Return:\n","            ---------\n","                - list_of_sequences (list): list of all sequences without null values in the dataset\n","        \"\"\"\n","\n","        list_of_sequences = list()\n","\n","        for wellname in tqdm(self.list_of_wells, disable=(not verbose)):\n","\n","            well_df = df[df[self.well_name_column] == wellname]\n","\n","            j=0\n","            while j < well_df.shape[0]-(self.seq_size-1): # Enquanto for possível pegar uma sequência de tamanho seq_size no meu poço\n","\n","                sequence = well_df.iloc[j:j+self.seq_size]\n","\n","                # Busca indíces de valores nulos dentro da sequência\n","                idx_null = [k for k,x in enumerate(sequence[self.no_missing_logs].values) if np.isnan(x).any()]\n","\n","                # Se não tiver valor nulo na sequência\n","                if idx_null == []:\n","                    list_of_sequences.append([wellname, sequence[self.logs], sequence['labels']])\n","                    j = j + self.interval_size\n","                # Se tiver, pular para o indíce seguinte ao último valor nulo na sequência\n","                else:\n","                    j = j + idx_null[-1] + 1\n","\n","        return list_of_sequences\n","\n","    def __len__(self):\n","\n","        return len(self.list_of_sequences)\n","\n","    def __getitem__(self, idx) -> tuple[str, torch.Tensor, torch.Tensor]:\n","        \"\"\"\n","            Arguments:\n","            ---------\n","                - idx (int): Index for selecting a sample from the dataset\n","            Return:\n","            ---------\n","                - wellname (str): Name of the well from which the sequence is taken\n","                - well_data_torch (torch.Tensor): Well log sequence\n","                - labels_torch (torch.Tensor): One-hot-encoded lithology labels sequence\n","        \"\"\"\n","\n","        wellname, sequence, labels = self.list_of_sequences[idx]\n","        # To numpy\n","        sequence_numpy = sequence.to_numpy()\n","        sequence_numpy = np.reshape(sequence_numpy, (-1, len(self.logs)))\n","\n","        # Create one-hot vector to represent labels\n","        labels_numpy = np.array([np.array([1. if i==label else 0. for i in range(self.num_classes)]) for label in labels.to_numpy()])\n","\n","        # To torch\n","        well_data_torch = torch.from_numpy(sequence_numpy).float()\n","        labels_torch = torch.from_numpy(labels_numpy).float()\n","\n","        return wellname, well_data_torch, labels_torch"]},{"cell_type":"code","execution_count":null,"id":"b61c3114-4d92-4998-a92b-174d2ef54797","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b61c3114-4d92-4998-a92b-174d2ef54797","outputId":"b4fb305c-78aa-4a6b-fd37-a66808ccebd6"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-13-33781b61fbc3>:30: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self.data['labels'] = labels\n","<ipython-input-13-33781b61fbc3>:30: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self.data['labels'] = labels\n","<ipython-input-13-33781b61fbc3>:30: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self.data['labels'] = labels\n"]}],"source":["train_dataset = LithologyDataset(X_train, y_train, cfg.logs, cfg.num_classes, seq_size=cfg.seq_size, interval_size=cfg.seq_size)\n","train_dataloader = DataLoader(train_dataset, batch_size=cfg.batch_size, shuffle=True)\n","\n","val_dataset = LithologyDataset(X_val, y_val, cfg.logs, cfg.num_classes, seq_size=cfg.seq_size, interval_size=cfg.seq_size)\n","val_dataloader = DataLoader(val_dataset, batch_size=cfg.batch_size, shuffle=False)\n","\n","test_dataset = LithologyDataset(X_test, y_test, cfg.logs, cfg.num_classes, seq_size=cfg.seq_size, interval_size=cfg.seq_size)\n","test_dataloader = DataLoader(test_dataset, batch_size=cfg.batch_size, shuffle=False)"]},{"cell_type":"markdown","id":"4bfb3613-cdcc-487f-84ae-60fc463e071a","metadata":{"id":"4bfb3613-cdcc-487f-84ae-60fc463e071a"},"source":["# Modelos"]},{"cell_type":"markdown","id":"71f61863-f32e-4cd9-ad22-f9168b959639","metadata":{"id":"71f61863-f32e-4cd9-ad22-f9168b959639"},"source":["#### **Classe LSTM**\n","\n","1. Implemente uma LSTM para modelagem de dependência de longo prazo. Deve ser possível configurar seu modelo para que seja unidirecional ou bidirecional."]},{"cell_type":"code","execution_count":null,"id":"11392c8b-5629-40ef-b9a9-623cfcfb25af","metadata":{"id":"11392c8b-5629-40ef-b9a9-623cfcfb25af"},"outputs":[],"source":["# Implemente a sua solução aqui"]},{"cell_type":"markdown","id":"60834bff-a72c-4122-8f3f-fa8720aa9be5","metadata":{"id":"60834bff-a72c-4122-8f3f-fa8720aa9be5"},"source":["#### **Classe GRU**\n","\n","2. Implemente uma GRU. Da mesma forma, o modelo pode ser configurado como unidirecional ou bidirecional."]},{"cell_type":"code","execution_count":null,"id":"55727253-27b7-4a0f-81b9-8e6f3c88ad6b","metadata":{"id":"55727253-27b7-4a0f-81b9-8e6f3c88ad6b"},"outputs":[],"source":["# Implemente a sua solução aqui"]},{"cell_type":"markdown","id":"9dfbe405-c32b-496e-9fee-bfd6987543bb","metadata":{"id":"9dfbe405-c32b-496e-9fee-bfd6987543bb"},"source":["# Treinamento"]},{"cell_type":"markdown","id":"707100fa-f939-467c-badd-0b2749d60526","metadata":{"id":"707100fa-f939-467c-badd-0b2749d60526"},"source":["### Função de avaliação (`evaluate`)"]},{"cell_type":"code","execution_count":null,"id":"d482a993-b2fa-42f2-bb59-e9de2bba0a05","metadata":{"id":"d482a993-b2fa-42f2-bb59-e9de2bba0a05"},"outputs":[],"source":["def evaluate(model, dataloader, print_metrics=False):\n","\n","    model.eval()\n","    y_pred_deep = []\n","    y_test_deep = []\n","    with torch.no_grad():\n","\n","        for i, (wellnames, well_data_torch, labels_torch) in enumerate(dataloader):\n","\n","            well_data_torch = well_data_torch.to(device)\n","            labels_torch = labels_torch.to(device)\n","\n","            output, hidden = model(well_data_torch)\n","\n","            # Reshape to 2D tensor (batch_size * seq_len, num_classes)\n","            output = output.reshape(-1, cfg.num_classes).detach().cpu().numpy()\n","\n","            labels_torch = labels_torch.reshape(-1, cfg.num_classes).detach().cpu().numpy()\n","\n","            test_probs = np.argmax(output, axis=1).tolist()\n","            test_labels = np.argmax(labels_torch, axis=1).tolist()\n","\n","            y_pred_deep.extend(test_probs)\n","            y_test_deep.extend(test_labels)\n","\n","    y_test = y_test_deep\n","    y_predict = y_pred_deep\n","\n","    if print_metrics:\n","        print(f'Accuracy: {accuracy_score(y_test, y_predict):.2f}')\n","        print(f'MCC: {matthews_corrcoef(y_test, y_predict):.2f}')\n","        print(f'Precision: {precision_score(y_test, y_predict, average=\"macro\"):.2f}')\n","        print(f'Recall: {recall_score(y_test, y_predict, average=\"macro\"):.2f}')\n","        print(f'F1-Score: {f1_score(y_test, y_predict, average=\"macro\"):.2f}')\n","\n","    lithology_keys = {30000: 'Sandstone',\n","                     65030: 'Sandstone/Shale',\n","                     65000: 'Shale',\n","                     80000: 'Marl',\n","                     74000: 'Dolomite',\n","                     70000: 'Limestone',\n","                     70032: 'Chalk',\n","                     88000: 'Halite',\n","                     86000: 'Anhydrite',\n","                     99000: 'Tuff',\n","                     90000: 'Coal',\n","                     93000: 'Basement'}\n","\n","    labels = [le_data.inverse_transform([value])[0] for value in np.unique(np.hstack((y_test, y_predict)))]\n","    label_names = [lithology_keys[label_values] for label_values in labels]\n","\n","    cm = confusion_matrix(y_test, y_predict, normalize='true')\n","    conf_mat_norm = np.around(cm.astype('float'), decimals=2)\n","\n","    disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat_norm, display_labels=label_names)\n","    disp.plot()\n","    plt.xticks(rotation=90)\n","    plt.show()"]},{"cell_type":"markdown","id":"33a62928-cc0c-4abc-8a20-36431df09984","metadata":{"id":"33a62928-cc0c-4abc-8a20-36431df09984"},"source":["### Configuração do modelo, função de perda e otimizador\n"]},{"cell_type":"markdown","id":"euCfA90lNr_Y","metadata":{"id":"euCfA90lNr_Y"},"source":["Inicialização do modelo\n","- Parâmetros do modelo:\n","    - Tamanho da entrada (`len(cfg.logs)`): Número de atributos de entrada (tipos de registro).\n","    - Tamanho da camada oculta (`64`): Número de unidades ocultas no modelo.\n","    - Tamanho da saída (`cfg.num_classes`): Número de classes de litologia.\n","    - Bidirecionalidade (`bidirectional`): Indica se a rede é bidirecional.\n","\n","Função de perda\n","- Calcula pesos de classe para lidar com conjuntos de dados desbalanceados usando `compute_class_weight`.\n","- Aplica `nn.CrossEntropyLoss` com os pesos de classe computados.\n","\n","Otimizador\n","- Configura o otimizador como Adam (`torch.optim.Adam`) com os parâmetros do modelo e a taxa de aprendizado (`lr`)."]},{"cell_type":"markdown","id":"07b1d71a","metadata":{},"source":["3. Complete o código abaixo para criar os modelos: LSTM, GRU, BiLSTM e BiGRU."]},{"cell_type":"code","execution_count":null,"id":"6954f8b2-7287-451b-8e19-1a85a595142a","metadata":{"id":"6954f8b2-7287-451b-8e19-1a85a595142a"},"outputs":[],"source":["LSTM_model = ...\n","\n","GRU_model = ...\n","\n","BiLSTM_model = ...\n","\n","BiGRU_model = ...\n","\n","class_weights = compute_class_weight('balanced', classes=np.unique(y_train.values), y=y_train.values)\n","class_weights_torch = torch.tensor(class_weights, dtype=torch.float).to(device)\n","criterion = nn.CrossEntropyLoss(weight=class_weights_torch, reduction='mean')\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"]},{"cell_type":"markdown","id":"018cf662-a286-4876-969b-383e92b3c2b4","metadata":{"id":"018cf662-a286-4876-969b-383e92b3c2b4"},"source":["### Loop de treinamento"]},{"cell_type":"markdown","id":"T309mwAiPyX-","metadata":{"id":"T309mwAiPyX-"},"source":["- Iteração de época: Itera pelo número de épocas.\n","\n","    - Iteração de batch: Faz um loop pelo `train_dataloader`, buscando batches de dados de registro de poços e rótulos correspondentes.\n","\n","        - Forward pass: Calcula previsões do modelo para os dados de entrada.\n","\n","        - Cálculo de perda: Calcula a perda usando o critério especificado (por exemplo, `nn.CrossEntropyLoss`).\n","\n","        - Backward pass: Calcula gradientes usando `loss.backward()`.\n","\n","        - Otimização: Atualiza parâmetros do modelo usando `optimizer.step()` com base nos gradientes.\n","\n","    - Logging: imprime a perda média de treinamento para a época e avalia o modelo no conjunto de validação a cada `n` épocas (por exemplo, a cada 20 épocas)."]},{"cell_type":"code","execution_count":null,"id":"039a55a8-69c7-4bd8-8e57-516b9f70ff42","metadata":{"id":"039a55a8-69c7-4bd8-8e57-516b9f70ff42"},"outputs":[],"source":["def train(model, epochs=100):\n","\n","    for epoch in range(epochs):\n","\n","        if cfg.verbose:\n","            print(f'Epoch {epoch+1}/{epochs}', end='\\r')\n","\n","        total_loss = 0\n","        model.train()\n","\n","        for i, (wellnames, well_data_torch, labels_torch) in enumerate(train_dataloader):\n","\n","            well_data_torch = well_data_torch.float().to(device)\n","            labels_torch = labels_torch.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            output, hidden = model(well_data_torch)\n","\n","            # Reshape to 2D tensor (batch_size * seq_len, num_classes)\n","            output = output.reshape(-1, cfg.num_classes)\n","\n","            labels_torch = labels_torch.reshape(-1, cfg.num_classes)\n","\n","            loss = criterion(output, labels_torch)\n","            total_loss += loss.item()\n","\n","            loss.backward()\n","\n","            optimizer.step()\n","\n","        if cfg.verbose == True and epoch%11==0:\n","            print(f\"Epoch {epoch+1}/{epochs} - Training Loss: {(total_loss/len(train_dataloader)):.2f}\")\n","\n","        if epoch%33==0:\n","            evaluate(model, val_dataloader)"]},{"cell_type":"code","execution_count":null,"id":"G-avw0ivR0t_","metadata":{"id":"G-avw0ivR0t_"},"outputs":[],"source":["train(LSTM_model)"]},{"cell_type":"code","execution_count":null,"id":"1uVBOJkHR06y","metadata":{"id":"1uVBOJkHR06y"},"outputs":[],"source":["train(GRU_model)"]},{"cell_type":"code","execution_count":null,"id":"lEW0uP1QR1Hv","metadata":{"id":"lEW0uP1QR1Hv"},"outputs":[],"source":["train(BiLSTM_model)"]},{"cell_type":"code","execution_count":null,"id":"ZZVEzgpnR1WF","metadata":{"id":"ZZVEzgpnR1WF"},"outputs":[],"source":["train(BiGRU_model)"]},{"cell_type":"markdown","id":"VylamqVJRXS8","metadata":{"id":"VylamqVJRXS8"},"source":["### Avaliação final"]},{"cell_type":"markdown","id":"GKnfsL18pnI1","metadata":{"id":"GKnfsL18pnI1"},"source":["4. Compare o tempo de treino e inferência de cada arquitetura (LSTM, GRU, BiLSTM e BiGRU). Compare também o número de parâmetros."]},{"cell_type":"code","execution_count":null,"id":"QIImRq-OStKO","metadata":{"id":"QIImRq-OStKO"},"outputs":[],"source":["# Implemente a sua solução aqui"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["Zitqg4OC8Rge","2d00c323-bb9c-4e02-9141-7a391542f879","6ff88d58-556b-484c-8a1f-6d721e43361a","0ba11225-2fa0-4da2-9f69-1d8818e5bbb4","87d87215-f21c-446a-adb1-7e7fd1c728ca","4bfb3613-cdcc-487f-84ae-60fc463e071a","71f61863-f32e-4cd9-ad22-f9168b959639","9dfbe405-c32b-496e-9fee-bfd6987543bb"],"gpuType":"T4","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":5}
