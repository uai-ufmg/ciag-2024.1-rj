{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sSp2Ah-NTAKs"
   },
   "source": [
    "# Regress√£o Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfPRWL3dSysf"
   },
   "source": [
    "### Configura√ß√µes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvXDyjR8Z2kD"
   },
   "source": [
    "A c√©lula abaixo define fun√ß√µes que iremos usar para exibir nossos dados. Voc√™ pode ignor√°-la. (Mas lembre-se de executar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oup3WO38THhv"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def plot_class_points(class_1, class_2, y_values = None):\n",
    "\n",
    "    plt.figure(figsize=(6, 4)) # Define uma figura com as dimens√µes 6cmx4cm\n",
    "    plt.scatter(class_1[:, 0], class_1[:, 1], color='blue', label='Classe 1') # Plota o conjunto de pontos da classe 1\n",
    "    plt.scatter(class_2[:, 0], class_2[:, 1], color='red', label='Classe 2') # Plota o conjunto de pontos da classe 2\n",
    "\n",
    "    if y_values is not None:\n",
    "        plt.plot(np.linspace(-4, 4, 100), y_values, color='green', label='Reta') # Plota uma lina entre x=-4 e x=4 com os valores especificados em y_values\n",
    "\n",
    "\n",
    "    # Configura√ß√µes do gr√°fico\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.title('Pontos Linearmente Separ√°veis em um Plano 2D')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_points(x, y, y_hat = None):\n",
    "\n",
    "\n",
    "    # Plotar os dados\n",
    "    plt.scatter(x, y, color='blue', label='Pontos de Dados')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title('Conjunto de Dados para Regress√£o Linear')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    if y_hat is not None:\n",
    "        plt.plot(np.linspace(0, x.max(), 100), y_hat, color='green', label='Reta')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def generate_rgt():\n",
    "\n",
    "    np.random.seed(27) # Setando uma seed aleat√≥ria para gerarmos sempre o mesmo rgt.\n",
    "\n",
    "\n",
    "    width, height = 128, 192  # Dimens√µes da imagem (largura x altura)\n",
    "    image = np.zeros((height, width)) # Matriz vazia para armazenar o rgt.\n",
    "\n",
    "    # 1. Gerando horizontes aleat√≥rios completamente retos.\n",
    "    num_lines = 16  # N√∫mero de linhas horizontais iniciais\n",
    "    line_positions = np.sort(np.random.choice(height, num_lines, replace=False))\n",
    "    line_values = np.abs(np.arange(-num_lines, 0))  # Valores crescentes para cada linha\n",
    "\n",
    "    \n",
    "\n",
    "    # 2. Aplicar deforma√ß√µes para curvar os horizontes.\n",
    "    for i, pos in enumerate(line_positions):\n",
    "        curve = (torch.sin(torch.linspace(0, np.pi * 2, width)) * 7).int()  # Curva de seno\n",
    "        curved_line = pos + curve  # Aplicar curva na posi√ß√£o da linha\n",
    "\n",
    "        # Garantir que a linha curva esteja dentro dos limites da imagem\n",
    "        curved_line = torch.clamp(curved_line, 0, height - 1)\n",
    "\n",
    "        # Aplicar os valores das linhas curvadas na imagem\n",
    "        for x in range(width):\n",
    "            image[curved_line[x], x] = line_values[i]\n",
    "\n",
    "    # 3. Interpolar linearmente entre os horizontes para preencher os valores do rgt\n",
    "    for x in range(width):\n",
    "        # Obter os valores n√£o zero na coluna x\n",
    "        y_vals = np.where(image[:, x] > 0)[0]\n",
    "        if len(y_vals) > 1:\n",
    "            f_interp = interp1d(y_vals, image[y_vals, x], kind='linear', fill_value=\"extrapolate\")\n",
    "            image[:, x] = f_interp(np.arange(height))\n",
    "\n",
    "    # Dividindo o rgt em duas imagens com overlap de 64.\n",
    "    rgt1 = image[:128, :]\n",
    "    rgt2 = image[64:, :]\n",
    "    # Normalizando o rgt\n",
    "    rgt1 = rgt1 - rgt1.min()\n",
    "    rgt1 = rgt1 / rgt1.max()\n",
    "    rgt2 = rgt2 - rgt2.min()\n",
    "    rgt2 = rgt2 / rgt2.max()\n",
    "\n",
    "    return torch.tensor(rgt1), torch.tensor(rgt2)\n",
    "\n",
    "def show_rgt(rgt):\n",
    "\n",
    "    plt.imshow(rgt, cmap=\"magma_r\", origin=\"lower\", aspect='auto') # Mostra uma imagem\n",
    "    plt.title(\"RGT Sint√©tico 1\")\n",
    "    plt.colorbar(label=\"Intensidade\")\n",
    "    plt.show()\n",
    "\n",
    "def show_rgts(rgt1, rgt2):\n",
    "    plt.figure(figsize=(12, 4)) \n",
    "\n",
    "    # Exibir o primeiro RGT\n",
    "    plt.subplot(1, 2, 1)  # 1 linha, 2 colunas, posi√ß√£o 1\n",
    "    plt.imshow(rgt1, cmap=\"magma_r\", origin=\"lower\", aspect='auto')\n",
    "    plt.title(\"RGT Sint√©tico 1\")\n",
    "    plt.colorbar(label=\"Intensidade\")\n",
    "\n",
    "    # Exibir o segundo RGT\n",
    "    plt.subplot(1, 2, 2)  # 1 linha, 2 colunas, posi√ß√£o 2\n",
    "    plt.imshow(rgt2, cmap=\"magma_r\", origin=\"lower\", aspect='auto')\n",
    "    plt.title(\"RGT Sint√©tico 2\")\n",
    "    plt.colorbar(label=\"Intensidade\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EAGyyCRuTL6o"
   },
   "source": [
    "## Introdu√ß√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VCPUl_P4TwYP"
   },
   "source": [
    "Na aula de hoje iremos entender melhor como as regress√µes lineares funcionam na pr√°tica. Para isso, n√≥s iremos usar o pytorch e a computa√ß√£o diferenci√°vel para fazer uma regress√£o do zero. Implementa√ß√µes deste m√©todo  (e de quase todas as t√©cnicas cl√°ssicas de aprendizado de m√°quina) j√° foram feitas em bibliotecas como o scikit-learn, e, no dia-a-dia, seu uso √© certamente mais pr√°tico do que fazer tudo voc√™ mesmo! Para mais informa√ß√µes, consulte a documenta√ß√£o do sklearn:\n",
    "\n",
    "https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "\n",
    "Objetivos:\n",
    "\n",
    "- Entender como funciona uma regress√£o linear.\n",
    "- Aplicar uma regress√£o linear em tarefas de classifica√ß√£o e regress√£o.\n",
    "- Ver uma aplica√ß√£o pr√°tica de regress√£o linear na geologia.\n",
    "- Extender regress√µes lineares para dados n√£o lineares por meio de features polinomiais.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "frH5UHcUVxDH"
   },
   "source": [
    "A regress√£o linear √© um m√©todo cl√°ssico de aprendizado de m√°quina que nos possibilita estimar algum valor dado um conjunto de var√°veis de entrada. Em uma regress√£o linear simples, temos uma vari√°vel de entrada (ou feature), que chamamos de\n",
    "ùë•, e um valor que queremos prever (ou target), que chamamos de\n",
    "ùë¶."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UetLlGU1Wmau"
   },
   "source": [
    "O objetivo da regress√£o linear √© encontrar uma reta que melhor se ajusta aos dados, de forma que possamos usar essa reta para fazer previs√µes sobre novos valores.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5oivTRaMX1PK"
   },
   "source": [
    ">Relembrando a equa√ß√£o de uma reta:\n",
    ">\n",
    ">$$\n",
    "y = w \\cdot x + b\n",
    "$$\n",
    ">onde:\n",
    ">\n",
    ">- ùë§ √© o coeficiente ou peso da vari√°vel ùë• e ele determina a inclina√ß√£o da linha.\n",
    ">- ùëè √© o intercepto (ou bias), que representa o ponto onde a linha intercepta o eixo ùë¶ quando $ùë•=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8SYN0p_YPrT"
   },
   "source": [
    "## Exerc√≠cio 1: Criando uma reta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DfPtsAOiaLZF"
   },
   "source": [
    "O c√≥digo abaixo define dois conjuntos de pontos, os azuis e os vermelhos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "id": "YGgFnp8yYO0Z",
    "outputId": "f46b8563-aa70-4f9b-c943-8710059994a9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Configurar a semente para reprodutibilidade\n",
    "np.random.seed(42)\n",
    "\n",
    "# Criando nossos pontos\n",
    "azul = np.random.randn(8, 2) + np.array([-2, 0])\n",
    "vermelho = np.random.randn(8, 2) + np.array([2, 2])\n",
    "\n",
    "plot_class_points(azul, vermelho) # Fun√ß√£o de exibir os pontos definida mais acima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iuLs0LH8adPO"
   },
   "source": [
    "Usando numpy defina uma reta que separe os dois cojuntos de pontos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "id": "BdvWY6urY475",
    "outputId": "f8d071d6-ef44-42a2-da8b-b4ebc9af6476"
   },
   "outputs": [],
   "source": [
    "def reta(x):\n",
    "    # Fa√ßa aqui. Retorne o valor de y correto para um x.\n",
    "    return y\n",
    "\n",
    "x_values = np.linspace(-4, 4, 100) # Definindo os valores v√°lidos de x\n",
    "y_values = reta(x_values) # Definindo os valores de y para cada x\n",
    "plot_class_points(azul, vermelho, y_values=y_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkgvUewAcv8s"
   },
   "source": [
    "## Exerc√≠cio 2: Encontrando a reta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KBzUR-ovdMI_"
   },
   "source": [
    "Para encontrar a melhor linha, precisamos determinar os valores de $w$ e $b$ que minimizam a diferen√ßa entre as previs√µes $\\hat{y}$ e os valores reais $y$. Essa diferen√ßa √© chamada de **erro**. Em regress√£o linear, usamos uma medida de erro chamada de **erro quadr√°tico m√©dio** (ou MSE, do ingl√™s *Mean Squared Error*):\n",
    "\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{N} \\sum_{i=1}^N (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "onde:\n",
    "- $N$ √© o n√∫mero de pontos nos dados,\n",
    "- $y_i$ √© o valor real da vari√°vel dependente para o ponto $i$,\n",
    "- $\\hat{y}_i$ √© o valor predito pelo modelo para o ponto $i$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rbhxxnF19jXR"
   },
   "source": [
    "### a. Classifica√ß√£o\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LdzTTQfSeMWi"
   },
   "source": [
    "No nosso caso, temos uma tarefa de *Classifica√ß√£o*.\n",
    "\n",
    "> Em uma tarefa de classifica√ß√£o, queremos separar nossos dados em grupos *conhecidos*. Nesse caso, temos dois grupos: pontos azuis e vermelhos.\n",
    "\n",
    "Assim, atribu√≠remos um valor num√©rico a cada classe (azul: -1, vermelho: 1) e usaremos eles para calcular o nosso erro.\n",
    "\n",
    ">obs: Na pr√°tica, para tarefas de classifica√ß√£o, outras fun√ß√µes de perda s√£o mais adequadas (como a entropia cruzada). Estudaremos elas em aulas seguintes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9O-g1gQrfHbw"
   },
   "source": [
    "**Agora √© com voc√™!**  Usando pytorch, fa√ßa um modelo de regress√£o linear que encontre a reta que separa os pontos azuis dos vermelhos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AvNqlsXT-9A_"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "## Antes de mais nada, vamos converter passar nossos pontos para o pytorch\n",
    "azul = torch.tensor(azul).float() # convertemos o tensor para float para evitar conflitos\n",
    "vermelho = torch.tensor(vermelho).float()\n",
    "\n",
    "## Agora, vamos criar um √∫nico vetor, X, que cont√©m todos os pontos\n",
    "X = torch.cat([azul, vermelho]).float()\n",
    "\n",
    "## Por fim, vamos criar o vetor de respostas, y.\n",
    "## Note que pontos azuis correspondem a y=-1, e vermelhos a y=1\n",
    "y = torch.cat([torch.zeros(len(azul)) - 1, torch.ones(len(vermelho))]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PH7QIZbLczE-",
    "outputId": "2adf108d-f3cf-41eb-eede-2d6b5f52b587"
   },
   "outputs": [],
   "source": [
    "\n",
    "w = # Inicialize os pesos\n",
    "bias = # Inicialize o bias\n",
    "\n",
    "def model(X, w, bias):\n",
    "    # Fa√ßa aqui.\n",
    "    # Esta fun√ß√£o deve retornar a predi√ß√£o do modelo.\n",
    "    # Dica: Use um produto matricial em sua implementa√ß√£o\n",
    "    return y_pred\n",
    "\n",
    "def mse_loss(y_pred, y_true):\n",
    "    # Fa√ßa aqui.\n",
    "    # Essa fun√ß√£o deve retornar o mse entre y_pred e y_true\n",
    "    return mse\n",
    "\n",
    "def train(X, y, w, bias, num_epochs, learning_rate):\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        y_pred = model(X, w, bias) # Extraindo a previs√£o do modelo para nossos dados.\n",
    "        loss = mse_loss(y_pred, y) # Calculando o MSE entre a predi√ß√£o e nossas labels.\n",
    "        \n",
    "        # Fa√ßa aqui.\n",
    "        ## Primeiro calcule os gradientes da loss.\n",
    "        ## Em seguida atualize o seu modelo.\n",
    "        ## Dica: Lembre-se de zerar os gradientes do modelo ap√≥s a atualiza√ß√£o dos pesos.\n",
    "\n",
    "\n",
    "\n",
    "        if (epoch + 1) % (num_epochs/10) == 0:\n",
    "            print(f'√âpoca {epoch+1}, Perda: {loss.item():.4f}')\n",
    "\n",
    "train(X, y, w, bias, 500, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vcP8M3057GG"
   },
   "source": [
    "Pronto! O modelo acima aprendeu a separar os pontos azuis dos vermelhos. Como? Simples, caso o modelo veja um ponto azul, ele retornar√° um valor negativo, e caso veja um ponto vermelho, retornar√° um valor positivo.\n",
    "\n",
    " Vamos verificar se deu certo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SMsHA6UahULc",
    "outputId": "3747b99c-858b-4504-bdc0-adda99004d02"
   },
   "outputs": [],
   "source": [
    "pred_azuis = model(azul, w, bias) # Usando nosso modelo para prever os pontos azuis.\n",
    "\n",
    "# O c√≥digo abaixo verifica se todas nossas predi√ß√µes est√£o corretas, isto √©, se elas foram n√∫meros negativos.\n",
    "assert torch.all(pred_azuis < 0), \"Ops, parece que alguns pontos azuis foram classificados como vermelhos\"\n",
    "\n",
    "pred_azuis.detach() # Usamos .detach() para remover os gradientes dos nossos tensores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zhr546XJ5iEe",
    "outputId": "d680a23f-3ee7-4b3c-d051-b8e54094f6ca"
   },
   "outputs": [],
   "source": [
    "pred_vermelhos = model(vermelho, w, bias)\n",
    "assert torch.all(pred_vermelhos > 0), \"Ops, parece que alguns pontos vermelhos foram classificados como azuis\"\n",
    "pred_vermelhos.detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9oBQdOcy63F0"
   },
   "source": [
    "#### Desafio!\n",
    "\n",
    "Encontre a reta definida pelo nosso modelo.\n",
    "> Dica: podemos definir nossa regress√£o pela f√≥rmula:\n",
    "> $$pred=w_0x + w_1y + b$$\n",
    "> Para encontrar a reta, encontre os valores para os quais pred = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TYCx44Ac7beJ"
   },
   "outputs": [],
   "source": [
    "x_values = np.linspace(-4, 4, 100)\n",
    "y_values = # Defina o valor de y para todo x em x_values. Dica: use produtos matriciais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "id": "FxfEIg5F7czi",
    "outputId": "604ed89a-8522-4f39-b663-59db5a6d98a5"
   },
   "outputs": [],
   "source": [
    "plot_class_points(azul, vermelho, y_values=y_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dMI7BaSs9ILD"
   },
   "source": [
    "Note que a reta n√£o exatamente igual √† que voc√™ definiu manualmente... Mas n√£o tem problema! Existem infinitas retas que dividem esses dois conjuntos de pontos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywNph5oNBWu8"
   },
   "source": [
    "### Regress√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V9_a7kwjBa9w"
   },
   "source": [
    "Podemos tamb√©m usar uma regress√£o linear para encontrar a reta que melhor representa um conjunto de pontos. Para isso, um processo parecido com o anterior, mas agora nosso modelo receber√° uma √∫ncia entrada, x, e tentar√° prever y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8AO4majCKQu"
   },
   "source": [
    "O c√≥digo abaixo gera um conjunto de pontos para usarmos de exemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "OAzoxMfM9TG3",
    "outputId": "37058036-9e19-4982-e857-d774534b0d65"
   },
   "outputs": [],
   "source": [
    "# Configurar a semente para reprodutibilidade\n",
    "np.random.seed(42)\n",
    "\n",
    "# Gerar 10 valores para a vari√°vel independente x entre 0 e 10\n",
    "x = np.linspace(0, 10, 10)\n",
    "\n",
    "# Definir a rela√ß√£o linear verdadeira entre x e y: y = 2x + 1\n",
    "# Adicionar algum ru√≠do gaussiano para tornar os dados mais realistas\n",
    "y = 2 * x + 1 + np.random.normal(0, 2, size=x.shape)\n",
    "\n",
    "plot_points(x, y) # Fun√ß√£o definida mais acima\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pNgygWdrC7-E"
   },
   "source": [
    "Fa√ßa uma regress√£o linear para encontrar a reta que melhor aproxima esse conjunto de pontos. Use a fun√ß√£o train, definida no exerc√≠cio anterior.\n",
    "\n",
    "> dica: Use X.unsqueeze(1) para adicionar uma dimens√£o a mais no seu vetor X. Verifique o shape de X antes e depois da opera√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yIo_onBjDENy",
    "outputId": "68f84cde-0ff5-449f-9612-dcebd2ceb28f"
   },
   "outputs": [],
   "source": [
    "## Fa√ßa aqui\n",
    "## Defina X, y, w e bias para passar para sua fun√ß√£o de treino anterior.\n",
    "\n",
    "\n",
    "train(X, y, w, bias, 500, 0.01) # Voc√™ pode brincar com os valores de num_epoch e learning_rate, mas estes devem funcionar bem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWI9tzTvDbmF"
   },
   "source": [
    "Agora vamos plotar a reta para verificar se nosso modelo est√° correto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "5XTx8-zhEDJE",
    "outputId": "b58cd7e8-10f2-43bb-a276-bd5fb1876b26"
   },
   "outputs": [],
   "source": [
    "## Fa√ßa aqui.\n",
    "plot_x = np.linspace(0, 10, 100)\n",
    "y_hat = ## Extraia as predi√ß√µes do seu modelo para todo x em plot_x. Dica: se necess√°rio, adicione mais dimens√µes em plot_x para passar para o modelo.\n",
    "\n",
    "plot_points(x, y, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xOdvtwa8FImi"
   },
   "source": [
    "## Desafio: Regress√£o e RGT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YC274sGnFW49"
   },
   "source": [
    "O tempo geol√≥gico relativo(RGT) √© uma medida *relativa* da idade de algum elemento geol√≥gico. Uma tarefa comum na geologia √©, dada uma imagem s√≠smica, tentar estimar o RGT de cada p√≠xel da imagem.\n",
    "\n",
    "Como n√£o temos uma escala absoluta de compara√ß√£o, podemos representar o rgt de uma imagem como um valor entre 0 e 1, tal que, quanto maior o valor de um p√≠xel, mais antigo ele √©."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ufwm-MUVIdqg"
   },
   "source": [
    "### Concatena√ß√£o\n",
    "\n",
    "Como a predi√ß√£o de RGT √© uma tarefa altamente complexa, √© comum que treinemos um grande modelo de aprendizado profundo para estimar o RGT de uma s√≠smica. Esses modelos, no entanto, tem um grande problema: devido ao grande tamanho das s√≠smicas, n√£o √© poss√≠vel pass√°-las inteiramente para a nossa rede.\n",
    "\n",
    "Para resolver isso, n√≥s dividimos a s√≠smica em diversas regi√µes menores. O c√≥digo abaixo simula isso, gerando 2 previs√µes sint√©ticas de um modelo de RGT.. Geogr√°ficamente, rgt1 est√° em cima de rgt 2.\n",
    "\n",
    "> obs: Note que as imagens geradas tem uma interse√ß√£o (ou overlap) de 64 pixeis. Ou seja, a primeira metade de rgt2 √© igual a primeira metade de rgt1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rbuYHguRFTeq"
   },
   "outputs": [],
   "source": [
    "rgt1, rgt2 = generate_rgt() # Gerando um rgt sint√©tico. Fun√ß√£o definida mais acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "vz5GMDzfH1Lq",
    "outputId": "d95244c8-3bad-4914-b048-ec55337863be"
   },
   "outputs": [],
   "source": [
    "show_rgts(rgt1, rgt2) # Fun√ß√£o definida mais acima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4sm-9HvKkiP"
   },
   "source": [
    "Como queremos observar o rgt completo de nossa s√≠smica, precisamos juntar essas duas images. Use a fun√ß√£o torch.cat para concatenar os 2 rgts.\n",
    "> dica: lembre-se que que existe um overlap de 64 p√≠exeis entre as duas imagens. O formato final da sa√≠da deve ser (192x128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "PwVYsmW5iV0P",
    "outputId": "b39859c5-1b25-46d8-cda7-afe860a1537e"
   },
   "outputs": [],
   "source": [
    "# Note que a regi√£o de overlap √© exatamente igual (com excess√£o dos valores)\n",
    "show_rgts(rgt1[64:], rgt2[:64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "A7jxQjTmKIFn",
    "outputId": "4d950de5-4ee9-4488-d5a4-b4055180381d"
   },
   "outputs": [],
   "source": [
    "## Fa√ßa aqui\n",
    "rgt_concat = # Concatene rgt1 e rgt2 em uma √∫nica imagem de shape (192x128)\n",
    "show_rgt(rgt_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zZDp528FMet3"
   },
   "source": [
    "Parece que esse m√©todo simples n√£o funciona... Mas Por que?\n",
    "\n",
    "Como o RGT est√° em uma escala relativa, p√≠xeis com o mesmo valor em 2 imagens diferentes n√£o representam a mesma idade. Em rgt2, por exemplo, um p√≠xel com valor de 0.5 pode representar uma regi√£o com idade de 10M anos, enquanto essa mesma idade em rgt1 seria o valor 0.9.\n",
    "\n",
    "Para resolver esse problema, n√≥s precisamos estabelecer uma rele√ß√£o entre os valores de rgt1 e rgt2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nYFrO0HHNTn6"
   },
   "source": [
    "Usando pytroch, fa√ßa uma regress√£o linear que encontre a rela√ß√£o entre rgt1 e rgt2 e concatena as duas imagens. Ao final do exerc√≠cio, a divis√£o entre rgt1 e rgt2 deve ser impercept√≠vel.\n",
    "\n",
    "> Dica: Considerando **apenas a regi√£o de overlap**, use os valores de rgt1 como X e de rgt2 como y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RaCCLa_vNS5I",
    "outputId": "77aded4d-ecd8-434b-8fd8-850c3a83e7b7"
   },
   "outputs": [],
   "source": [
    "## Fa√ßa aqui\n",
    "## Defina X, y, w e bias para passar para o modelo.\n",
    "\n",
    "\n",
    "# Dica: essa tarefa √© um pouco mais dif√≠cil, tenta aumentar o n√∫mero de epochs.\n",
    "train(X, y, w, bias, 20000, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "jK1mn6yBOf6E",
    "outputId": "95d43845-fe24-40ca-f923-591500062e32"
   },
   "outputs": [],
   "source": [
    "# Fa√ßa aqui\n",
    "# Use seu modelo para modificar os valores de rgt1 e concatene as duas imagens novamente.\n",
    "show_rgt(rgt_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-OpRlcYqdGum"
   },
   "source": [
    "## Exerc√≠cio 3: Dados n√£o-lineares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghYa4EvgdPnJ"
   },
   "source": [
    "At√© aqui, todos os exerc√≠cios tinham como uma solu√ß√£o uma equa√ß√£o linear. Isso, no entanto, nem sempre √© poss√≠vel.\n",
    "\n",
    "O c√≥digo abaixo gera um conjunto de pontos n√£o linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "-JXgnG-kdMiv",
    "outputId": "61a50c63-c1aa-40ba-e111-45dda02922be"
   },
   "outputs": [],
   "source": [
    "x_range = np.linspace(0, 1, 50)\n",
    "sin_x = np.sin(x_range * 2 * np.pi)\n",
    "plot_points(x_range, sin_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9k8ClfLEeEb-"
   },
   "source": [
    "Usando uma regress√£o linear, encontre a reta que melhor representa esses pontos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FxvP6o9Nd0ra",
    "outputId": "a80d92cb-f8fe-4c01-f190-272b1fa4cc4f"
   },
   "outputs": [],
   "source": [
    "## Fa√ßa aqui\n",
    "## Defina X, y, w e bias para passar para o modelo.\n",
    "\n",
    "# Dica: essa tarefa √© um pouco mais dif√≠cil, tenta aumentar o n√∫mero de epochs.\n",
    "train(X, y, w, bias, 1000, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "g8FIE_AAq5do",
    "outputId": "acb41d93-8c2e-4fb1-860d-948bcf4ed5cd"
   },
   "outputs": [],
   "source": [
    "## Fa√ßa aqui\n",
    "## Extraia as predi√ß√µes de seu modelo para todo x em um intervalo 0 a 1 com 100 pontos.\n",
    "\n",
    "plot_points(x_range, sin_x, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UIRffQSQrNMd"
   },
   "source": [
    "Parece que nossa reta n√£o captura muito bem os dados. O que podemos fazer para resolver esse problema? Bom, precisamos de pensar em algum jeito de introduzir uma n√£o-linearidade em nossa regress√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gz7VcfkusP3I"
   },
   "source": [
    "Uma das formas mais comuns de introduzir n√£o linearidade em uma regress√£o linear √© utilizando features polinomiais. Em vez de modelar apenas uma rela√ß√£o linear entre $x$ e $y$ podemos incluir pot√™ncias de $x$ como features adicionais. Por exemplo, ao adicionar termos quadr√°ticos e c√∫bicos, estamos transformando nosso modelo linear em um polin√¥mio:\n",
    "\n",
    "$$y = w_0 + w_1x + w_2x^2 + ... + w_dx^d$$\n",
    "\n",
    "onde d √© o grau m√°ximo do polin√¥mio que queremos incluir.\n",
    "\n",
    "Essas features polinomiais permitem que o modelo capture rela√ß√µes n√£o lineares nos dados, mantendo a simplicidade e a interpretabilidade de um modelo linear nos par√¢metros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-HPOSyW2sxSa"
   },
   "source": [
    "Usando features n√£o lineares, ache um modelo que aproxime bem a fun√ß√£o seno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P-5_h1chtk8l",
    "outputId": "3383bb5e-4813-46c8-800b-43a6737c3914"
   },
   "outputs": [],
   "source": [
    "def create_polynomial_features(X, degree):\n",
    "    ## Fa√ßa aqui\n",
    "    ## Crie as feaures polinomiais para seu X\n",
    "    return X_poly\n",
    "\n",
    "## Defina X e y\n",
    "\n",
    "degree = 3  # Exemplo: grau polinomial\n",
    "X_poly = create_polynomial_features(X, degree)  # Expandir as features para o grau desejado\n",
    "\n",
    "## Inicialize w e bias\n",
    "\n",
    "train(X_poly, y, w, bias, num_epochs=10000, learning_rate=0.01) # Agora passamos x_poly para o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "YOBa1Bh0tkaR",
    "outputId": "e5785721-982b-4554-e0aa-5ea3eda73efc"
   },
   "outputs": [],
   "source": [
    "## Fa√ßa aqui\n",
    "## Extraia as predi√ß√µes de seu modelo para todo x em um intervalo 0 a 1 com 100 pontos.\n",
    "\n",
    "plot_points(x_range, sin_x, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " O que acontece quando aumentamos o valor de d?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
