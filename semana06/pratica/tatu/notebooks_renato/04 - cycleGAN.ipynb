{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cN9Sd0YqbrvE"
   },
   "source": [
    "# CycleGAN\n",
    "\n",
    "from photos to Monet-style images and vice-versa.\n",
    "\n",
    "a ResNet-based generator for the architecture. building a ResNet architecture. This involves creating ResidualBlock and assembling the generator model.\n",
    "a PatchGAN discriminator, cycle consistency loss, identity loss, and adversarial losses. Also choosing optimizers and outlining the training loop.\n",
    "\n",
    "The Generator is a ResNet-based network with reflection padding, downsampling, several residual blocks, and upsampling.\n",
    "The Discriminator is a PatchGAN that outputs a feature map (not a single scalar) used to classify patches as real or fake.\n",
    "\n",
    "Loss Functions:\n",
    "The implementation uses MSELoss for the adversarial loss (common in CycleGAN implementations), L1Loss for both cycle consistency and identity losses.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9841,
     "status": "ok",
     "timestamp": 1738520078442,
     "user": {
      "displayName": "Renato Assunção",
      "userId": "09374091195909290678"
     },
     "user_tz": 180
    },
    "id": "_Iy8JBK-w97U",
    "outputId": "31871c3f-bd97-4e91-b6de-46d46012b2f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import itertools\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.v2 as T\n",
    "import torchvision.transforms.v2.functional as K\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1K117mLx0Sb"
   },
   "source": [
    "########################################\n",
    "# 1. DATALOADER\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot samples and metadata of a dataset\n",
    "def plot_dataset(\n",
    "    dataset,\n",
    "    n_rows=4,\n",
    "    figsize=(6, 6),\n",
    "    denormalize=False,\n",
    "):\n",
    "    print(f'Number of samples: {len(dataset)}')\n",
    "    print(f'Number of samples A: {len(dataset.files_A)}')\n",
    "    print(f'Number of samples B: {len(dataset.files_B)}')\n",
    "    print(f'Sample shape A: {dataset[0][\"A\"].shape}')\n",
    "    print(f'Sample shape B: {dataset[0][\"B\"].shape}')\n",
    "\n",
    "    samples = np.random.randint(0, len(dataset), size=n_rows)\n",
    "    fig, axes = plt.subplots(n_rows, 2, figsize=figsize)\n",
    "\n",
    "    for i in range(n_rows):\n",
    "        imageA, imageB = dataset[samples[i]].values()\n",
    "        if denormalize:\n",
    "            imageA = K.normalize(imageA, -1, 2)\n",
    "            imageA = imageA.clamp(0, 1)\n",
    "\n",
    "            imageB = K.normalize(imageB, -1, 2)\n",
    "            imageB = imageB.clamp(0, 1)\n",
    "\n",
    "        imageA = imageA.permute(1, 2, 0)\n",
    "        imageB = imageB.permute(1, 2, 0)\n",
    "        im = axes[i, 0].imshow(imageA)\n",
    "        if imageA.shape[2] == 1:\n",
    "            im.set_cmap('gray')\n",
    "\n",
    "        im = axes[i, 1].imshow(imageB)\n",
    "        if imageB.shape[2] == 1:\n",
    "            im.set_cmap('gray')\n",
    "        axes[i, 0].set_title('A')\n",
    "        axes[i, 1].set_title('B')\n",
    "        axes[i, 0].axis('off')\n",
    "        axes[i, 1].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 225,
     "status": "ok",
     "timestamp": 1738520634862,
     "user": {
      "displayName": "Renato Assunção",
      "userId": "09374091195909290678"
     },
     "user_tz": 180
    },
    "id": "cO-yR1ctxNcq"
   },
   "outputs": [],
   "source": [
    "# dataloader\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A dataset class for unpaired image-to-image translation.\n",
    "    Expects the following folder structure inside the dataset root:\n",
    "\n",
    "        <root>/\n",
    "            trainA/\n",
    "            trainB/\n",
    "            testA/\n",
    "            testB/\n",
    "\n",
    "    For Monet2Photo, you can treat one domain as 'A' (e.g., photos)\n",
    "    and the other as 'B' (e.g., Monet-style paintings).\n",
    "    \"\"\"\n",
    "    def __init__(self, root, transforms_=None, mode='train'):\n",
    "        self.transform = transforms_\n",
    "        self.files_A = sorted(glob.glob(os.path.join(root, f'{mode}A') + '/*.*'))\n",
    "        self.files_B = sorted(glob.glob(os.path.join(root, f'{mode}B') + '/*.*'))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_A = Image.open(self.files_A[index % len(self.files_A)]).convert('RGB')\n",
    "        img_B = Image.open(self.files_B[index % len(self.files_B)]).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            img_A = self.transform(img_A)\n",
    "            img_B = self.transform(img_B)\n",
    "\n",
    "        return {'A': img_A, 'B': img_B}\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(len(self.files_A), len(self.files_B))\n",
    "\n",
    "# Define image transformations – these are similar to those used in the CycleGAN paper\n",
    "transforms_ = T.Compose([\n",
    "    T.ToImage(),\n",
    "    T.ToDtype(torch.float32, scale=True),\n",
    "    T.Resize(int(256*1.12), Image.BICUBIC),\n",
    "    T.RandomCrop(256),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Set the dataset root\n",
    "dataset_root = \"/pgeoprj2/ciag2024/dados/cycleGAN/monet2photo/\"\n",
    "train_dataset = ImageDataset(root=dataset_root, transforms_=transforms_, mode='train')\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 199,
     "status": "ok",
     "timestamp": 1738526025641,
     "user": {
      "displayName": "Renato Assunção",
      "userId": "09374091195909290678"
     },
     "user_tz": 180
    },
    "id": "vX2MkLsbOoV5",
    "outputId": "604a5fcc-b442-4e49-aef8-deaa15cceb62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in domain A (trainA): 1072\n",
      "Number of images in domain B (trainB): 6287\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of images in domain A (trainA):\", len(train_dataset.files_A))\n",
    "print(\"Number of images in domain B (trainB):\", len(train_dataset.files_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dataset(train_dataset, denormalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifBDSfeYxda6"
   },
   "source": [
    "########################################\n",
    "# 2. MODEL ARCHITECTURES\n",
    "########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xlVoOGcOxk_-"
   },
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 221,
     "status": "ok",
     "timestamp": 1738520682247,
     "user": {
      "displayName": "Renato Assunção",
      "userId": "09374091195909290678"
     },
     "user_tz": 180
    },
    "id": "joDTAGvyxW03"
   },
   "outputs": [],
   "source": [
    "# Generator\n",
    "\n",
    "# --- Residual Block for the Generator ---\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(dim, dim, kernel_size=3),\n",
    "            nn.InstanceNorm2d(dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(dim, dim, kernel_size=3),\n",
    "            nn.InstanceNorm2d(dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "# --- Generator: ResNet-based ---\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, n_residual_blocks=9):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # Initial convolution block\n",
    "        model = [\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(input_nc, 64, kernel_size=7),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        ]\n",
    "\n",
    "        # Downsampling\n",
    "        in_features = 64\n",
    "        out_features = in_features * 2\n",
    "        for _ in range(2):\n",
    "            model += [\n",
    "                nn.Conv2d(in_features, out_features, kernel_size=3, stride=2, padding=1),\n",
    "                nn.InstanceNorm2d(out_features),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features * 2\n",
    "\n",
    "        # Residual blocks\n",
    "        for _ in range(n_residual_blocks):\n",
    "            model += [ResidualBlock(in_features)]\n",
    "\n",
    "        # Upsampling\n",
    "        out_features = in_features // 2\n",
    "        for _ in range(2):\n",
    "            model += [\n",
    "                nn.ConvTranspose2d(in_features, out_features, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                nn.InstanceNorm2d(out_features),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features // 2\n",
    "\n",
    "        # Output layer\n",
    "        model += [\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(64, output_nc, kernel_size=7),\n",
    "            nn.Tanh()\n",
    "        ]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_h8JXXIxoih"
   },
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1738520688457,
     "user": {
      "displayName": "Renato Assunção",
      "userId": "09374091195909290678"
     },
     "user_tz": 180
    },
    "id": "UIBfJCOTxqg5"
   },
   "outputs": [],
   "source": [
    "# --- Discriminator: PatchGAN ---\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_nc):\n",
    "        super(Discriminator, self).__init__()\n",
    "        model = [\n",
    "            nn.Conv2d(input_nc, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        ]\n",
    "        model += [\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        ]\n",
    "        model += [\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        ]\n",
    "        model += [\n",
    "            nn.Conv2d(256, 512, kernel_size=4, stride=1, padding=1),\n",
    "            nn.InstanceNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        ]\n",
    "        model += [\n",
    "            nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=1)\n",
    "        ]\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0gzgcJgvxvJ1"
   },
   "source": [
    "########################################\n",
    "# 3. INSTANTIATE MODELS & LOSS FUNCTIONS\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 800,
     "status": "ok",
     "timestamp": 1738520693690,
     "user": {
      "displayName": "Renato Assunção",
      "userId": "09374091195909290678"
     },
     "user_tz": 180
    },
    "id": "QK-oDLuRx_4n"
   },
   "outputs": [],
   "source": [
    "# 3. INSTANTIATE MODELS & LOSS FUNCTIONS\n",
    "\n",
    "# For Monet2Photo, let’s assume domain A is 'photo' and domain B is 'Monet'.\n",
    "# (Depending on your interpretation, you may swap the labels.)\n",
    "G_A2B = Generator(input_nc=3, output_nc=3).to(device)  # Translates Photo -> Monet\n",
    "G_B2A = Generator(input_nc=3, output_nc=3).to(device)  # Translates Monet -> Photo\n",
    "D_A = Discriminator(input_nc=3).to(device)  # Discriminator for domain A (Photo)\n",
    "D_B = Discriminator(input_nc=3).to(device)  # Discriminator for domain B (Monet)\n",
    "\n",
    "# Losses\n",
    "criterion_GAN = nn.MSELoss().to(device)\n",
    "criterion_cycle = nn.L1Loss().to(device)\n",
    "criterion_identity = nn.L1Loss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cv3ZCDsyCKF"
   },
   "source": [
    "########################################\n",
    "# 4. OPTIMIZERS & LEARNING RATE SCHEDULERS\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 206,
     "status": "ok",
     "timestamp": 1738520697710,
     "user": {
      "displayName": "Renato Assunção",
      "userId": "09374091195909290678"
     },
     "user_tz": 180
    },
    "id": "kWgldm_ByGYS"
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# 4. OPTIMIZERS & LEARNING RATE SCHEDULERS\n",
    "########################################\n",
    "\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "optimizer_G = optim.Adam(itertools.chain(G_A2B.parameters(), G_B2A.parameters()),\n",
    "                         lr=lr, betas=(beta1, 0.999))\n",
    "optimizer_D_A = optim.Adam(D_A.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizer_D_B = optim.Adam(D_B.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BiqdNi-NyI_V"
   },
   "source": [
    "########################################\n",
    "# 5. TRAINING LOOP (simplified for demonstration)\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 77371,
     "status": "ok",
     "timestamp": 1738523777880,
     "user": {
      "displayName": "Renato Assunção",
      "userId": "09374091195909290678"
     },
     "user_tz": 180
    },
    "id": "hlt81RtfyPlQ",
    "outputId": "13666c65-6748-420e-b17b-07045f8dc449"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4c75bb81524695857433a3f82120e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/393 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################################\n",
    "# 5. TRAINING LOOP (simplified for demonstration)\n",
    "########################################\n",
    "\n",
    "num_epochs = 20  # For demonstration; increase for better results\n",
    "lambda_cycle = 10.0\n",
    "lambda_identity = 5.0\n",
    "\n",
    "# For target labels in GAN loss\n",
    "# Real label = 1.0, Fake label = 0.0\n",
    "real_label = 1.0\n",
    "fake_label = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, batch in (\n",
    "        pbar := tqdm(enumerate(train_dataloader), total=len(train_dataloader), unit='batch')\n",
    "    ):\n",
    "        # Set model inputs\n",
    "        real_A = batch['A'].to(device)  # Photo\n",
    "        real_B = batch['B'].to(device)  # Monet\n",
    "\n",
    "        #### Train Generators G_A2B and G_B2A ####\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Identity loss\n",
    "        # G_B2A(real_A) should be close to real_A if real_A is already from domain A\n",
    "        loss_id_A = criterion_identity(G_B2A(real_A), real_A)\n",
    "        loss_id_B = criterion_identity(G_A2B(real_B), real_B)\n",
    "        loss_identity = (loss_id_A + loss_id_B) * lambda_identity\n",
    "\n",
    "        # GAN loss\n",
    "        fake_B = G_A2B(real_A)\n",
    "        pred_fake_B = D_B(fake_B)\n",
    "        loss_GAN_A2B = criterion_GAN(pred_fake_B, torch.full(pred_fake_B.shape, real_label, device=device))\n",
    "\n",
    "        fake_A = G_B2A(real_B)\n",
    "        pred_fake_A = D_A(fake_A)\n",
    "        loss_GAN_B2A = criterion_GAN(pred_fake_A, torch.full(pred_fake_A.shape, real_label, device=device))\n",
    "        loss_GAN = loss_GAN_A2B + loss_GAN_B2A\n",
    "\n",
    "        # Cycle consistency loss\n",
    "        rec_A = G_B2A(fake_B)\n",
    "        loss_cycle_A = criterion_cycle(rec_A, real_A)\n",
    "        rec_B = G_A2B(fake_A)\n",
    "        loss_cycle_B = criterion_cycle(rec_B, real_B)\n",
    "        loss_cycle = (loss_cycle_A + loss_cycle_B) * lambda_cycle\n",
    "\n",
    "        # Total generator loss\n",
    "        loss_G = loss_identity + loss_GAN + loss_cycle\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        #### Train Discriminator D_A ####\n",
    "        optimizer_D_A.zero_grad()\n",
    "        # Real loss for D_A\n",
    "        pred_real_A = D_A(real_A)\n",
    "        loss_D_A_real = criterion_GAN(pred_real_A, torch.full(pred_real_A.shape, real_label, device=device))\n",
    "        # Fake loss for D_A\n",
    "        pred_fake_A = D_A(fake_A.detach())\n",
    "        loss_D_A_fake = criterion_GAN(pred_fake_A, torch.full(pred_fake_A.shape, fake_label, device=device))\n",
    "        loss_D_A = (loss_D_A_real + loss_D_A_fake) * 0.5\n",
    "        loss_D_A.backward()\n",
    "        optimizer_D_A.step()\n",
    "\n",
    "        #### Train Discriminator D_B ####\n",
    "        optimizer_D_B.zero_grad()\n",
    "        # Real loss for D_B\n",
    "        pred_real_B = D_B(real_B)\n",
    "        loss_D_B_real = criterion_GAN(pred_real_B, torch.full(pred_real_B.shape, real_label, device=device))\n",
    "        # Fake loss for D_B\n",
    "        pred_fake_B = D_B(fake_B.detach())\n",
    "        loss_D_B_fake = criterion_GAN(pred_fake_B, torch.full(pred_fake_B.shape, fake_label, device=device))\n",
    "        loss_D_B = (loss_D_B_real + loss_D_B_fake) * 0.5\n",
    "        loss_D_B.backward()\n",
    "        optimizer_D_B.step()\n",
    "\n",
    "        pbar.set_description(f'[epoch {epoch+1}/{num_epochs}] G_loss: {loss_G.item():.4f} DA_loss: {loss_D_A.item():.4f} DB_loss: {loss_D_B.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qpk0Hu_qyUIi"
   },
   "source": [
    "########################################\n",
    "# 6. VISUALIZATION FUNCTION\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 208,
     "status": "ok",
     "timestamp": 1738524427698,
     "user": {
      "displayName": "Renato Assunção",
      "userId": "09374091195909290678"
     },
     "user_tz": 180
    },
    "id": "DvuBo45xegVg"
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# 6. VISUALIZATION FUNCTION\n",
    "########################################\n",
    "\n",
    "def visualize_cycle(generator_AB, generator_BA, dataset, num_samples=3):\n",
    "    \"\"\"\n",
    "    Visualizes a few examples of cycle translation.\n",
    "    For each sample:\n",
    "      - Translate A -> B, then back to A.\n",
    "      - Translate B -> A, then back to B.\n",
    "    \"\"\"\n",
    "    generator_AB.eval()\n",
    "    generator_BA.eval()\n",
    "\n",
    "    plt.figure(figsize=(num_samples*6, 8))\n",
    "\n",
    "    # Unnormalize: reverse the normalization from [-1,1] to [0,1]\n",
    "    def unnormalize(img):\n",
    "        return img * 0.5 + 0.5\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        sample = dataset[i]\n",
    "        real_A = sample['A'].unsqueeze(0).to(device)\n",
    "        real_B = sample['B'].unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            fake_B = generator_AB(real_A)\n",
    "            rec_A = generator_BA(fake_B)\n",
    "            fake_A = generator_BA(real_B)\n",
    "            rec_B = generator_AB(fake_A)\n",
    "\n",
    "        # Unnormalize images for display and move channels to last dimension\n",
    "        real_A_disp = unnormalize(real_A.squeeze(0)).permute(1,2,0).cpu().numpy()\n",
    "        fake_B_disp = unnormalize(fake_B.squeeze(0)).permute(1,2,0).cpu().numpy()\n",
    "        rec_A_disp = unnormalize(rec_A.squeeze(0)).permute(1,2,0).cpu().numpy()\n",
    "        real_B_disp = unnormalize(real_B.squeeze(0)).permute(1,2,0).cpu().numpy()\n",
    "        fake_A_disp = unnormalize(fake_A.squeeze(0)).permute(1,2,0).cpu().numpy()\n",
    "        rec_B_disp = unnormalize(rec_B.squeeze(0)).permute(1,2,0).cpu().numpy()\n",
    "\n",
    "        # Plot row for domain A: real A, fake B, reconstructed A\n",
    "        plt.subplot(num_samples, 6, i*6 + 1)\n",
    "        plt.imshow(real_A_disp)\n",
    "        plt.title(\"Real A\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(num_samples, 6, i*6 + 2)\n",
    "        plt.imshow(fake_B_disp)\n",
    "        plt.title(\"Fake B\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(num_samples, 6, i*6 + 3)\n",
    "        plt.imshow(rec_A_disp)\n",
    "        plt.title(\"Rec A\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # Plot row for domain B: real B, fake A, reconstructed B\n",
    "        plt.subplot(num_samples, 6, i*6 + 4)\n",
    "        plt.imshow(real_B_disp)\n",
    "        plt.title(\"Real B\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(num_samples, 6, i*6 + 5)\n",
    "        plt.imshow(fake_A_disp)\n",
    "        plt.title(\"Fake A\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(num_samples, 6, i*6 + 6)\n",
    "        plt.imshow(rec_B_disp)\n",
    "        plt.title(\"Rec B\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 603,
     "output_embedded_package_id": "1BA4p0qsfSXHzrki-zJGVAZGeVPc0L5TI"
    },
    "executionInfo": {
     "elapsed": 3004,
     "status": "ok",
     "timestamp": 1738525879057,
     "user": {
      "displayName": "Renato Assunção",
      "userId": "09374091195909290678"
     },
     "user_tz": 180
    },
    "id": "uvdySeeUyYqd",
    "outputId": "7cadcc8d-7d9a-4e45-874e-b37666afc901"
   },
   "outputs": [],
   "source": [
    "# Example: Visualize 3 samples after training\n",
    "visualize_cycle(G_A2B, G_B2A, train_dataset, num_samples=3)\n",
    "\n",
    "# A:Monet  B:photos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m07BOrkJPV7J"
   },
   "source": [
    "# Randomly selecting examples\n",
    "\n",
    "We redefine the previous function by adding added the parameter random_sample (defaulting to False). When random_sample is True, we choose a random index for each sample using Python's random.randint.\n",
    "\n",
    "Index Selection:\n",
    "In each iteration, if random_sample is True, the index idx is chosen randomly from [0, len(dataset)-1]; otherwise, it is set to the loop counter i.\n",
    "\n",
    "Remaining Code:\n",
    "The rest of the function remains the same, generating cycle translation outputs and plotting them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 246,
     "status": "ok",
     "timestamp": 1738526362817,
     "user": {
      "displayName": "Renato Assunção",
      "userId": "09374091195909290678"
     },
     "user_tz": 180
    },
    "id": "_UZADkxPPUcZ"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def visualize_cycle(generator_AB, generator_BA, dataset, num_samples=3, random_sample=False):\n",
    "    \"\"\"\n",
    "    Visualizes a few examples of cycle translation.\n",
    "    For each sample:\n",
    "      - Translate A -> B, then back to A.\n",
    "      - Translate B -> A, then back to B.\n",
    "\n",
    "    Args:\n",
    "        generator_AB (nn.Module): Generator for translating from A to B.\n",
    "        generator_BA (nn.Module): Generator for translating from B to A.\n",
    "        dataset (Dataset): Dataset containing paired images with keys 'A' and 'B'.\n",
    "        num_samples (int): Number of samples to visualize.\n",
    "        random_sample (bool): If True, select samples randomly from the dataset.\n",
    "                              If False, select the first num_samples images.\n",
    "    \"\"\"\n",
    "    generator_AB.eval()\n",
    "    generator_BA.eval()\n",
    "\n",
    "    plt.figure(figsize=(num_samples*6, 8))\n",
    "\n",
    "    # Unnormalize: reverse the normalization from [-1,1] to [0,1]\n",
    "    def unnormalize(img):\n",
    "        return img * 0.5 + 0.5\n",
    "\n",
    "    dataset_length = len(dataset)\n",
    "    for i in range(num_samples):\n",
    "        # Choose index either sequentially or at random\n",
    "        if random_sample:\n",
    "            idx = random.randint(0, dataset_length - 1)\n",
    "        else:\n",
    "            idx = i\n",
    "\n",
    "        sample = dataset[idx]\n",
    "        real_A = sample['A'].unsqueeze(0).to(device)\n",
    "        real_B = sample['B'].unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            fake_B = generator_AB(real_A)\n",
    "            rec_A = generator_BA(fake_B)\n",
    "            fake_A = generator_BA(real_B)\n",
    "            rec_B = generator_AB(fake_A)\n",
    "\n",
    "        # Unnormalize images for display and move channels to last dimension\n",
    "        real_A_disp = unnormalize(real_A.squeeze(0)).permute(1,2,0).cpu().numpy()\n",
    "        fake_B_disp = unnormalize(fake_B.squeeze(0)).permute(1,2,0).cpu().numpy()\n",
    "        rec_A_disp = unnormalize(rec_A.squeeze(0)).permute(1,2,0).cpu().numpy()\n",
    "        real_B_disp = unnormalize(real_B.squeeze(0)).permute(1,2,0).cpu().numpy()\n",
    "        fake_A_disp = unnormalize(fake_A.squeeze(0)).permute(1,2,0).cpu().numpy()\n",
    "        rec_B_disp = unnormalize(rec_B.squeeze(0)).permute(1,2,0).cpu().numpy()\n",
    "\n",
    "        # Plot row for domain A: real A, fake B, reconstructed A\n",
    "        plt.subplot(num_samples, 6, i*6 + 1)\n",
    "        plt.imshow(real_A_disp)\n",
    "        plt.title(\"Real A\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(num_samples, 6, i*6 + 2)\n",
    "        plt.imshow(fake_B_disp)\n",
    "        plt.title(\"Fake B\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(num_samples, 6, i*6 + 3)\n",
    "        plt.imshow(rec_A_disp)\n",
    "        plt.title(\"Rec A\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # Plot row for domain B: real B, fake A, reconstructed B\n",
    "        plt.subplot(num_samples, 6, i*6 + 4)\n",
    "        plt.imshow(real_B_disp)\n",
    "        plt.title(\"Real B\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(num_samples, 6, i*6 + 5)\n",
    "        plt.imshow(fake_A_disp)\n",
    "        plt.title(\"Fake A\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(num_samples, 6, i*6 + 6)\n",
    "        plt.imshow(rec_B_disp)\n",
    "        plt.title(\"Rec B\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 603,
     "output_embedded_package_id": "1Zm6SQypV3kzVmgSKRQu4s1iTDdc35-2M"
    },
    "executionInfo": {
     "elapsed": 2840,
     "status": "ok",
     "timestamp": 1738526447573,
     "user": {
      "displayName": "Renato Assunção",
      "userId": "09374091195909290678"
     },
     "user_tz": 180
    },
    "id": "EbIhcz8lPudH",
    "outputId": "aa6e0ddd-0ae0-448a-c54a-bdb009232586"
   },
   "outputs": [],
   "source": [
    "# For sequential sampling:\n",
    "# visualize_cycle(generator_AB, generator_BA, dataset, num_samples=3, random_sample=False)\n",
    "\n",
    "# For random sampling:\n",
    "visualize_cycle(G_A2B, G_B2A, train_dataset, num_samples=3, random_sample=True)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyML+GdQZQMJWVJwOwsmQhDD",
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
